
@inproceedings{moura_clouding_2020,
	address = {Virtual Event USA},
	title = {Clouding up the {Internet}: how centralized is {DNS} traffic becoming?},
	isbn = {978-1-4503-8138-3},
	shorttitle = {Clouding up the {Internet}},
	url = {https://dl.acm.org/doi/10.1145/3419394.3423625},
	doi = {10.1145/3419394.3423625},
	abstract = {Concern has been mounting about Internet centralization over the few last years – consolidation of traﬃc/users/infrastructure into the hands of a few market players. We measure DNS and computing centralization by analyzing DNS traﬃc collected at a DNS root server and two country-code top-level domains (ccTLDs) – one in Europe and the other in Oceania – and show evidence of concentration. More than 30\% of all queries to both ccTLDs are sent from 5 large cloud providers. We compare the clouds’ resolver infrastructure and highlight a discrepancy in behavior: some cloud providers heavily employ IPv6, DNSSEC, and DNS over TCP, while others simply use unsecured DNS over UDP over IPv4. We show one positive side to centralization: once a cloud provider deploys a security feature – such as QNAME minimization – it quickly beneﬁts a large number of users.},
	language = {en},
	urldate = {2021-08-31},
	booktitle = {Proceedings of the {ACM} {Internet} {Measurement} {Conference}},
	publisher = {ACM},
	author = {Moura, Giovane C. M. and Castro, Sebastian and Hardaker, Wes and Wullink, Maarten and Hesselman, Cristian},
	month = oct,
	year = {2020},
	pages = {42--49},
	file = {Moura et al. - 2020 - Clouding up the Internet how centralized is DNS t.pdf:/home/tobi/programms/Zotero/storage/ZTRWY8ZX/Moura et al. - 2020 - Clouding up the Internet how centralized is DNS t.pdf:application/pdf},
}

@article{nygren_akamai_2010,
	title = {The {Akamai} network: a platform for high-performance internet applications},
	volume = {44},
	issn = {0163-5980},
	shorttitle = {The {Akamai} network},
	url = {https://dl.acm.org/doi/10.1145/1842733.1842736},
	doi = {10.1145/1842733.1842736},
	abstract = {Comprising more than 61,000 servers located across nearly 1,000 networks in 70 countries worldwide, the Akamai platform delivers hundreds of billions of Internet interactions daily, helping thousands of enterprises boost the performance and reliability of their Internet applications. In this paper, we give an overview of the components and capabilities of this large-scale distributed computing platform, and offer some insight into its architecture, design principles, operation, and management.},
	language = {en},
	number = {3},
	urldate = {2021-07-17},
	journal = {ACM SIGOPS Operating Systems Review},
	author = {Nygren, Erik and Sitaraman, Ramesh K. and Sun, Jennifer},
	month = aug,
	year = {2010},
	pages = {2--19},
	file = {Nygren et al. - 2010 - The Akamai network a platform for high-performanc.pdf:/home/tobi/programms/Zotero/storage/776PAJCY/Nygren et al. - 2010 - The Akamai network a platform for high-performanc.pdf:application/pdf},
}

@inproceedings{dellamico_lean_2017,
	address = {Orlando FL USA},
	title = {Lean {On} {Me}: {Mining} {Internet} {Service} {Dependencies} {From} {Large}-{Scale} {DNS} {Data}},
	isbn = {978-1-4503-5345-8},
	shorttitle = {Lean {On} {Me}},
	url = {https://dl.acm.org/doi/10.1145/3134600.3134637},
	doi = {10.1145/3134600.3134637},
	abstract = {Most websites, services, and applications have come to rely on Internet services (e.g., DNS, CDN, email, WWW, etc.) o ered by third parties. Although employing such services generally improves reliability and cost-e ectiveness, it also creates dependencies on service providers, which may expose websites to additional risks, such as DDoS attacks or cascading failures. As cloud services are becoming more popular, an increasing percentage of the overall Internet ecosystem relies on a decreasing number of highly popular services. In our general e ort to assess the security risk for a given entity, and motivated by the e ects of recent service disruptions, we perform a large-scale analysis of passive and active DNS datasets including more than 2.5 trillion queries in order to discover the dependencies between websites and Internet services.},
	language = {en},
	urldate = {2021-08-31},
	booktitle = {Proceedings of the 33rd {Annual} {Computer} {Security} {Applications} {Conference}},
	publisher = {ACM},
	author = {Dell'Amico, Matteo and Bilge, Leyla and Kayyoor, Ashwin and Efstathopoulos, Petros and Vervier, Pierre-Antoine},
	month = dec,
	year = {2017},
	pages = {449--460},
	file = {Dell'Amico et al. - 2017 - Lean On Me Mining Internet Service Dependencies F.pdf:/home/tobi/programms/Zotero/storage/RCVV9PDR/Dell'Amico et al. - 2017 - Lean On Me Mining Internet Service Dependencies F.pdf:application/pdf},
}

@inproceedings{kashaf_analyzing_2020,
	address = {Virtual Event USA},
	title = {Analyzing {Third} {Party} {Service} {Dependencies} in {Modern} {Web} {Services}: {Have} {We} {Learned} from the {Mirai}-{Dyn} {Incident}?},
	isbn = {978-1-4503-8138-3},
	shorttitle = {Analyzing {Third} {Party} {Service} {Dependencies} in {Modern} {Web} {Services}},
	url = {https://dl.acm.org/doi/10.1145/3419394.3423664},
	doi = {10.1145/3419394.3423664},
	abstract = {Many websites rely on third parties for services (e.g., DNS, CDN, etc.). However, it also exposes them to shared risks from attacks (e.g., Mirai DDoS attack [24]) or cascading failures (e.g., GlobalSign revocation error [21]). Motivated by such incidents, we analyze the prevalence and impact of third-party dependencies, focusing on three critical infrastructure services: DNS, CDN, and certificate revocation checking by CA. We analyze both direct (e.g., Twitter uses Dyn) and indirect (e.g., Netflix uses Symantec as CA which uses Verisign for DNS) dependencies. We also take two snapshots in 2016 and 2020 to understand how the dependencies evolved. Our key findings are: (1) 89\% of the Alexa top-100K websites critically depend on third-party DNS, CDN, or CA providers i.e., if these providers go down, these websites could suffer service disruption; (2) the use of third-party services is concentrated, and the top-3 providers of CDN, DNS, or CA services can affect 50\%-70\% of the top-100K websites; (3) indirect dependencies amplify the impact of popular CDN and DNS providers by up to 25X; and (4) some third-party dependencies and concentration increased marginally between 2016 to 2020. Based on our findings, we derive key implications for different stakeholders in the web ecosystem.},
	language = {en},
	urldate = {2021-07-22},
	booktitle = {Proceedings of the {ACM} {Internet} {Measurement} {Conference}},
	publisher = {ACM},
	author = {Kashaf, Aqsa and Sekar, Vyas and Agarwal, Yuvraj},
	month = oct,
	year = {2020},
	pages = {634--647},
	file = {Kashaf et al. - 2020 - Analyzing Third Party Service Dependencies in Mode.pdf:/home/tobi/programms/Zotero/storage/CRCCCEG2/Kashaf et al. - 2020 - Analyzing Third Party Service Dependencies in Mode.pdf:application/pdf},
}

@inproceedings{natarajan_nsdminer_2012,
	title = {{NSDMiner}: {Automated} discovery of {Network} {Service} {Dependencies}},
	shorttitle = {{NSDMiner}},
	doi = {10.1109/INFCOM.2012.6195642},
	abstract = {Enterprise networks today host a wide variety of network services, which often depend on each other to provide and support network-based services and applications. Understanding such dependencies is essential for maintaining the well-being of an enterprise network and its applications, particularly in the presence of network attacks and failures. In a typical enterprise network, which is complex and dynamic in configuration, it is non-trivial to identify all these services and their dependencies. Several techniques have been developed to learn such dependencies automatically. However, they are either too complex to fine tune or cluttered with false positives and/or false negatives. In this paper, we propose a suite of novel techniques and develop a new tool named NSDMiner (which stands for Mining for Network Service Dependencies) to automatically discover the dependencies between network services from passively collected network traffic. NSDMiner is non-intrusive; it does not require any modification of existing software, or injection of network packets. More importantly, NSDMiner achieves higher accuracy than previous network-based approaches. Our experimental evaluation, which uses network traffic collected from our campus network, shows that NSDMiner outperforms the two best existing solutions significantly.},
	booktitle = {2012 {Proceedings} {IEEE} {INFOCOM}},
	author = {Natarajan, Arun and Ning, Peng and Liu, Yao and Jajodia, Sushil and Hutchinson, Steve E.},
	month = mar,
	year = {2012},
	note = {ISSN: 0743-166X},
	keywords = {Databases, Electronic mail, Monitoring, Protocols, Web servers},
	pages = {2507--2515},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/NEJDD7V9/6195642.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/QW32BQWL/Natarajan et al. - 2012 - NSDMiner Automated discovery of Network Service D.pdf:application/pdf},
}

@inproceedings{tajalizadehkhoob_apples_2016,
	title = {Apples, oranges and hosting providers: {Heterogeneity} and security in the hosting market},
	shorttitle = {Apples, oranges and hosting providers},
	doi = {10.1109/NOMS.2016.7502824},
	abstract = {Hosting services are associated with various security threats, yet the market has barely been studied empirically. Most security research has relied on routing data and equates providers with Autonomous Systems, ignoring the complexity and heterogeneity of the market. To overcome these limitations, we combined passive DNS data with WHOIS data to identify providers and some of their properties. We found 45,434 hosting providers, spread around a median address space size of 1,517 IP addresses. There is surprisingly little consolidation in the market, even though its services seem amenable to economies of scale. We applied cluster analysis on several measurable characteristics of providers. This uncovered a diverse set of business profiles and an indication of what fraction of the market fits each profile. The profiles are associated with significant differences in security performance, as measured by the uptime of phishing sites. This suggests the approach provides an effective way for security researchers to take the heterogeneity of the market into account.},
	booktitle = {{NOMS} 2016 - 2016 {IEEE}/{IFIP} {Network} {Operations} and {Management} {Symposium}},
	author = {Tajalizadehkhoob, Samaneh and Korczyński, Maciej and Noroozian, Arman and Gañán, Carlos and van Eeten, Michel},
	month = apr,
	year = {2016},
	note = {ISSN: 2374-9709},
	keywords = {Complexity theory, Education, IP networks, Organizations, Security, Sociology, Statistics},
	pages = {289--297},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/LBENNLWL/7502824.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/A9TTECRC/Tajalizadehkhoob et al. - 2016 - Apples, oranges and hosting providers Heterogenei.pdf:application/pdf},
}

@inproceedings{cangialosi_measurement_2016,
	address = {Vienna Austria},
	title = {Measurement and {Analysis} of {Private} {Key} {Sharing} in the {HTTPS} {Ecosystem}},
	isbn = {978-1-4503-4139-4},
	url = {https://dl.acm.org/doi/10.1145/2976749.2978301},
	doi = {10.1145/2976749.2978301},
	abstract = {The semantics of online authentication in the web are rather straightforward: if Alice has a certiﬁcate binding Bob’s name to a public key, and if a remote entity can prove knowledge of Bob’s private key, then (barring key compromise) that remote entity must be Bob. However, in reality, many websites—and the majority of the most popular ones—are hosted at least in part by third parties such as Content Delivery Networks (CDNs) or web hosting providers. Put simply: administrators of websites who deal with (extremely) sensitive user data are giving their private keys to third parties. Importantly, this sharing of keys is undetectable by most users, and widely unknown even among researchers.},
	language = {en},
	urldate = {2021-08-31},
	booktitle = {Proceedings of the 2016 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Cangialosi, Frank and Chung, Taejoong and Choffnes, David and Levin, Dave and Maggs, Bruce M. and Mislove, Alan and Wilson, Christo},
	month = oct,
	year = {2016},
	pages = {628--640},
	file = {Cangialosi et al. - 2016 - Measurement and Analysis of Private Key Sharing in.pdf:/home/tobi/programms/Zotero/storage/5G6WHK6E/Cangialosi et al. - 2016 - Measurement and Analysis of Private Key Sharing in.pdf:application/pdf},
}

@inproceedings{kumar_security_2017,
	address = {Perth Australia},
	title = {Security {Challenges} in an {Increasingly} {Tangled} {Web}},
	isbn = {978-1-4503-4913-0},
	url = {https://dl.acm.org/doi/10.1145/3038912.3052686},
	doi = {10.1145/3038912.3052686},
	abstract = {Over the past 20 years, websites have grown increasingly complex and interconnected. In 2016, only a negligible number of sites are dependency free, and over 90\% of sites rely on external content. In this paper, we investigate the current state of web dependencies and explore two security challenges associated with the increasing reliance on external services: (1) the expanded attack surface associated with serving unknown, implicitly trusted third-party content, and (2) how the increased set of external dependencies impacts HTTPS adoption. We hope that by shedding light on these issues, we can encourage developers to consider the security risks associated with serving third-party content and prompt service providers to more widely deploy HTTPS.},
	language = {en},
	urldate = {2021-08-31},
	booktitle = {Proceedings of the 26th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Kumar, Deepak and Ma, Zane and Durumeric, Zakir and Mirian, Ariana and Mason, Joshua and Halderman, J. Alex and Bailey, Michael},
	month = apr,
	year = {2017},
	pages = {677--684},
	file = {Kumar et al. - 2017 - Security Challenges in an Increasingly Tangled Web.pdf:/home/tobi/programms/Zotero/storage/E579I34Z/Kumar et al. - 2017 - Security Challenges in an Increasingly Tangled Web.pdf:application/pdf},
}

@inproceedings{liang_when_2014,
	title = {When {HTTPS} {Meets} {CDN}: {A} {Case} of {Authentication} in {Delegated} {Service}},
	shorttitle = {When {HTTPS} {Meets} {CDN}},
	doi = {10.1109/SP.2014.12},
	abstract = {Content Delivery Network (CDN) and Hypertext Transfer Protocol Secure (HTTPS) are two popular but independent web technologies, each of which has been well studied individually and independently. This paper provides a systematic study on how these two work together. We examined 20 popular CDN providers and 10,721 of their customer web sites using HTTPS. Our study reveals various problems with the current HTTPS practice adopted by CDN providers, such as widespread use of invalid certificates, private key sharing, neglected revocation of stale certificates, and insecure back-end communication. While some of those problems are operational issues only, others are rooted in the fundamental semantic conflict between the end-to-end nature of HTTPS and the man-in-the-middle nature of CDN involving multiple parties in a delegated service. To address the delegation problem when HTTPS meets CDN, we proposed and implemented a lightweight solution based on DANE (DNS-based Authentication of Named Entities), an emerging IETF protocol complementing the current Web PKI model. Our implementation demonstrates that it is feasible for HTTPS to work with CDN securely and efficiently. This paper intends to provide a context for future discussion within security and CDN community on more preferable solutions.},
	booktitle = {2014 {IEEE} {Symposium} on {Security} and {Privacy}},
	author = {Liang, Jinjin and Jiang, Jian and Duan, Haixin and Li, Kang and Wan, Tao and Wu, Jianping},
	month = may,
	year = {2014},
	note = {ISSN: 2375-1207},
	keywords = {Protocols, Authentication, Browsers, Servers, Uniform resource locators},
	pages = {67--82},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/BF7I9AJP/6956557.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/7YS4R6GG/Liang et al. - 2014 - When HTTPS Meets CDN A Case of Authentication in .pdf:application/pdf},
}

@inproceedings{vissers_maneuvering_2015,
	address = {Denver Colorado USA},
	title = {Maneuvering {Around} {Clouds}: {Bypassing} {Cloud}-based {Security} {Providers}},
	isbn = {978-1-4503-3832-5},
	shorttitle = {Maneuvering {Around} {Clouds}},
	url = {https://dl.acm.org/doi/10.1145/2810103.2813633},
	doi = {10.1145/2810103.2813633},
	abstract = {The increase of Distributed Denial-of-Service (DDoS) attacks in volume, frequency, and complexity, combined with the constant required alertness for mitigating web application threats, has caused many website owners to turn to Cloud-based Security Providers (CBSPs) to protect their infrastructure. These solutions typically involve the rerouting of tra c from the original website through the CBSP’s network, where malicious tra c can be detected and absorbed before it ever reaches the servers of the protected website. The most popular Cloud-based Security Providers do not require the purchase of dedicated tra c-rerouting hardware, but rely solely on changing the DNS settings of a domain name to reroute a website’s tra c through their security infrastructure. Consequently, this rerouting mechanism can be completely circumvented by directly attacking the website’s hosting IP address. Therefore, it is crucial for the security and availability of these websites that their real IP address remains hidden from potential attackers.},
	language = {en},
	urldate = {2021-08-05},
	booktitle = {Proceedings of the 22nd {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Vissers, Thomas and Van Goethem, Tom and Joosen, Wouter and Nikiforakis, Nick},
	month = oct,
	year = {2015},
	pages = {1530--1541},
	file = {Vissers et al. - 2015 - Maneuvering Around Clouds Bypassing Cloud-based S.pdf:/home/tobi/programms/Zotero/storage/LYZG8QDJ/Vissers et al. - 2015 - Maneuvering Around Clouds Bypassing Cloud-based S.pdf:application/pdf},
}

@article{jonas_cloud_2019,
	title = {Cloud {Programming} {Simplified}: {A} {Berkeley} {View} on {Serverless} {Computing}},
	shorttitle = {Cloud {Programming} {Simplified}},
	url = {http://arxiv.org/abs/1902.03383},
	abstract = {Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.},
	urldate = {2021-08-31},
	journal = {arXiv:1902.03383 [cs]},
	author = {Jonas, Eric and Schleier-Smith, Johann and Sreekanti, Vikram and Tsai, Chia-Che and Khandelwal, Anurag and Pu, Qifan and Shankar, Vaishaal and Carreira, Joao and Krauth, Karl and Yadwadkar, Neeraja and Gonzalez, Joseph E. and Popa, Raluca Ada and Stoica, Ion and Patterson, David A.},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.03383},
	keywords = {Computer Science - Operating Systems},
	file = {arXiv Fulltext PDF:/home/tobi/programms/Zotero/storage/4CNB83PQ/Jonas et al. - 2019 - Cloud Programming Simplified A Berkeley View on S.pdf:application/pdf;arXiv.org Snapshot:/home/tobi/programms/Zotero/storage/LQK8WGKQ/1902.html:text/html},
}

@article{scheuner_function-as--service_2020,
	title = {Function-as-a-{Service} performance evaluation: {A} multivocal literature review},
	volume = {170},
	issn = {0164-1212},
	shorttitle = {Function-as-a-{Service} performance evaluation},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301527},
	doi = {10.1016/j.jss.2020.110708},
	abstract = {Function-as-a-Service (FaaS) is one form of the serverless cloud computing paradigm and is defined through FaaS platforms (e.g., AWS Lambda) executing event-triggered code snippets (i.e., functions). Many studies that empirically evaluate the performance of such FaaS platforms have started to appear but we are currently lacking a comprehensive understanding of the overall domain. To address this gap, we conducted a multivocal literature review (MLR) covering 112 studies from academic (51) and grey (61) literature. We find that existing work mainly studies the AWS Lambda platform and focuses on micro-benchmarks using simple functions to measure CPU speed and FaaS platform overhead (i.e., container cold starts). Further, we discover a mismatch between academic and industrial sources on tested platform configurations, find that function triggers remain insufficiently studied, and identify HTTP API gateways and cloud storages as the most used external service integrations. Following existing guidelines on experimentation in cloud systems, we discover many flaws threatening the reproducibility of experiments presented in the surveyed studies. We conclude with a discussion of gaps in literature and highlight methodological suggestions that may serve to improve future FaaS performance evaluation studies.},
	language = {en},
	urldate = {2021-08-31},
	journal = {Journal of Systems and Software},
	author = {Scheuner, Joel and Leitner, Philipp},
	month = dec,
	year = {2020},
	keywords = {Benchmarking, Cloud computing, Function-as-a-Service, Multivocal literature review, Performance, Serverless},
	pages = {110708},
	file = {Submitted Version:/home/tobi/programms/Zotero/storage/RAHSEQPL/Scheuner and Leitner - 2020 - Function-as-a-Service performance evaluation A mu.pdf:application/pdf;ScienceDirect Snapshot:/home/tobi/programms/Zotero/storage/DBPEZZRF/S0164121220301527.html:text/html},
}

@inproceedings{wang_peeking_2018,
	title = {Peeking {Behind} the {Curtains} of {Serverless} {Platforms}},
	isbn = {978-1-939133-01-4},
	url = {https://www.usenix.org/conference/atc18/presentation/wang-liang},
	language = {en},
	urldate = {2021-08-31},
	author = {Wang, Liang and Li, Mengyuan and Zhang, Yinqian and Ristenpart, Thomas and Swift, Michael},
	year = {2018},
	pages = {133--146},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/YNLSZC75/Wang et al. - 2018 - Peeking Behind the Curtains of Serverless Platform.pdf:application/pdf;Snapshot:/home/tobi/programms/Zotero/storage/LLGCA29C/wang-liang.html:text/html},
}

@article{eismann_serverless_2021,
	title = {Serverless {Applications}: {Why}, {When}, and {How}?},
	volume = {38},
	issn = {0740-7459, 1937-4194},
	shorttitle = {Serverless {Applications}},
	url = {http://arxiv.org/abs/2009.08173},
	doi = {10.1109/MS.2020.3023302},
	abstract = {Serverless computing shows good promise for efficiency and ease-of-use. Yet, there are only a few, scattered and sometimes conflicting reports on questions such as 'Why do so many companies adopt serverless?', 'When are serverless applications well suited?', and 'How are serverless applications currently implemented?' To address these questions, we analyze 89 serverless applications from open-source projects, industrial sources, academic literature, and scientific computing - the most extensive study to date.},
	number = {1},
	urldate = {2021-08-31},
	journal = {IEEE Software},
	author = {Eismann, Simon and Scheuner, Joel and van Eyk, Erwin and Schwinger, Maximilian and Grohmann, Johannes and Abad, Cristina L. and Iosup, Alexandru},
	month = jan,
	year = {2021},
	note = {arXiv: 2009.08173},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Software Engineering, D.2.0, D.2.1, D.2.11},
	pages = {32--39},
	file = {arXiv Fulltext PDF:/home/tobi/programms/Zotero/storage/R72PBZTM/Eismann et al. - 2021 - Serverless Applications Why, When, and How.pdf:application/pdf;arXiv.org Snapshot:/home/tobi/programms/Zotero/storage/VVNJIYV8/2009.html:text/html},
}

@article{castro_rise_2019,
	title = {The rise of serverless computing},
	volume = {62},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/3368454},
	doi = {10.1145/3368454},
	abstract = {The server is dead, long live the server.},
	number = {12},
	urldate = {2021-08-31},
	journal = {Communications of the ACM},
	author = {Castro, Paul and Ishakian, Vatche and Muthusamy, Vinod and Slominski, Aleksander},
	month = nov,
	year = {2019},
	pages = {44--54},
}

@inproceedings{mahgoub_sonic_2021,
	title = {\{{SONIC}\}: {Application}-aware {Data} {Passing} for {Chained} {Serverless} {Applications}},
	isbn = {978-1-939133-23-6},
	shorttitle = {\{{SONIC}\}},
	url = {https://www.usenix.org/conference/atc21/presentation/mahgoub},
	language = {en},
	urldate = {2021-08-31},
	author = {Mahgoub, Ashraf and Shankar, Karthick and Mitra, Subrata and Klimovic, Ana and Chaterji, Somali and Bagchi, Saurabh},
	year = {2021},
	pages = {285--301},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/KQ98X748/mahgoub.html:text/html},
}

@inproceedings{thomas_particle_2020,
	address = {New York, NY, USA},
	series = {{SoCC} '20},
	title = {Particle: ephemeral endpoints for serverless networking},
	isbn = {978-1-4503-8137-6},
	shorttitle = {Particle},
	url = {https://doi.org/10.1145/3419111.3421275},
	doi = {10.1145/3419111.3421275},
	abstract = {Burst-parallel serverless applications invoke thousands of short-lived distributed functions to complete complex jobs such as data analytics, video encoding, or compilation. While these tasks execute in seconds, starting and configuring the virtual network they rely on is a major bottleneck that can consume up to 84\% of total startup time. In this paper we characterize the magnitude of this network cold start problem in three popular overlay networks, Docker Swarm, Weave, and Linux Overlay. We focus on end-to-end startup time that encompasses both the time to boot a group of containers as well as interconnecting them. Our primary observation is that existing overlay approaches for serverless networking scale poorly in short-lived serverless environments. Based on our findings we develop Particle, a network stack tailored for multi-node serverless overlay networks that optimizes network creation without sacrificing multi-tenancy, generality, or throughput. When integrated into a serverless burst-parallel video processing pipeline, Particle improves application runtime by 2.4--3X over existing overlays.},
	urldate = {2021-08-31},
	booktitle = {Proceedings of the 11th {ACM} {Symposium} on {Cloud} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Thomas, Shelby and Ao, Lixiang and Voelker, Geoffrey M. and Porter, George},
	month = oct,
	year = {2020},
	keywords = {burst parallel, lambda, networking, serverless},
	pages = {16--29},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/FCNH94JS/Thomas et al. - 2020 - Particle ephemeral endpoints for serverless netwo.pdf:application/pdf},
}

@article{wang_galleon_2021,
	title = {Galleon: {Reshaping} the {Square} {Peg} of {NFV}},
	shorttitle = {Galleon},
	url = {http://arxiv.org/abs/2101.06466},
	abstract = {Software is often used for Network Functions (NFs) -- such as firewalls, NAT, deep packet inspection, and encryption -- that are applied to traffic in the network. The community has hoped that NFV would enable rapid development of new NFs and leverage commodity computing infrastructure. However, the challenge for researchers and operators has been to align the square peg of high-speed packet processing with the round hole of cloud computing infrastructures and abstractions, all while delivering performance, scalability, and isolation. Past work has led to the belief that NFV is different enough that it requires novel, custom approaches that deviate from today's norms. To the contrary, we show that we can achieve performance, scalability, and isolation in NFV judiciously using mechanisms and abstractions of FaaS, the Linux kernel, NIC hardware, and OpenFlow switches. As such, with our system Galleon, NFV can be practically-deployable today in conventional cloud environments while delivering up to double the performance per core compared to the state of the art.},
	urldate = {2021-08-31},
	journal = {arXiv:2101.06466 [cs]},
	author = {Wang, Jianfeng and Lévai, Tamás and Li, Zhuojin and Vieira, Marcos A. M. and Govindan, Ramesh and Raghavan, Barath},
	month = jan,
	year = {2021},
	note = {arXiv: 2101.06466},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture},
	file = {arXiv Fulltext PDF:/home/tobi/programms/Zotero/storage/IMTPGRTW/Wang et al. - 2021 - Galleon Reshaping the Square Peg of NFV.pdf:application/pdf;arXiv.org Snapshot:/home/tobi/programms/Zotero/storage/P2KNKB7E/2101.html:text/html},
}

@misc{noauthor_granular_nodate,
	title = {Granular {Computing} and {Network} {Intensive} {Applications} {\textbar} {Proceedings} of the 16th {ACM} {Workshop} on {Hot} {Topics} in {Networks}},
	url = {https://dl.acm.org/doi/10.1145/3152434.3152450},
	urldate = {2021-08-31},
	file = {Granular Computing and Network Intensive Applications | Proceedings of the 16th ACM Workshop on Hot Topics in Networks:/home/tobi/programms/Zotero/storage/ZBLS7WXR/3152434.html:text/html},
}

@misc{noauthor_snf_nodate,
	title = {{SNF} {\textbar} {Proceedings} of the 11th {ACM} {Symposium} on {Cloud} {Computing}},
	url = {https://dl.acm.org/doi/10.1145/3419111.3421295},
	urldate = {2021-08-31},
}

@inproceedings{herwig_achieving_2020,
	title = {Achieving {Keyless} {CDNs} with {Conclaves}},
	isbn = {978-1-939133-17-5},
	url = {https://www.usenix.org/conference/usenixsecurity20/presentation/herwig},
	language = {en},
	urldate = {2021-08-31},
	author = {Herwig, Stephen and Garman, Christina and Levin, Dave},
	year = {2020},
	pages = {735--751},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/W5C3M9SY/Herwig et al. - 2020 - Achieving Keyless CDNs with Conclaves.pdf:application/pdf;Snapshot:/home/tobi/programms/Zotero/storage/BWBD34E6/herwig.html:text/html},
}

@book{guo_cdn_2020,
	title = {{CDN} {Judo}: {Breaking} the {CDN} {DoS} {Protection} with {Itself}},
	shorttitle = {{CDN} {Judo}},
	abstract = {A content delivery network (CDN) improves the accessing performance and availability of websites via its globally distributed network infrastructures, which contributes to the thriving of CDN-powered websites on the Internet. Because CDN-powered websites normally operate important businesses or critical services, attackers are mostly interested in taking down these high-value websites, to achieve severe damage with maximum influence. Because the CDN absorbs distributed attacking traffic with its massive bandwidth resources, it is commonly believed that CDN vendors provide effective DoS protection for the CDN-powered websites.

{\textbackslash}{\textbackslash}

However, we reveal that implementation or protocol weaknesses in the forwarding mechanisms of the CDN can be exploited to break this CDN protection. By sending crafted but legal requests, an attacker can launch an efficient DoS attack against the website origin behind it. In particular, we present three CDN threats in this study. By abusing the HTTP/2 request-converting behavior and HTTP pre-POST behavior of a CDN, an attacker can saturate the CDN-origin bandwidth and exhaust the connection limits of the origin. What is more concerning is that some CDN vendors use only a small set of traffic forwarding IPs with lower IP-churning rates to establish connections with the origin. This characteristic provides a great opportunity for an attacker to effectively degrade the global availability of a website just by cutting off specific CDN--origin connections.

{\textbackslash}{\textbackslash}

In this work, we examine the CDN request-forwarding behaviors across six well-known CDN vendors and perform real-world experiments to evaluate the severity of the threats. Because the threats are caused by flawed trade-offs made by the CDN vendors between usability and security, we discuss possible mitigation and received positive feedback after responsible disclosure to the aforementioned CDN vendors.},
	author = {Guo, Run and Li, Weizhong and Liu, Baojun and Hao, Shuang and Zhang, Jia and Duan, Haixin and Shen, Kaiwen and Chen, Jianjun and Liu, Ying},
	month = jan,
	year = {2020},
	doi = {10.14722/ndss.2020.24411},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/I28IYRQ9/Guo et al. - 2020 - CDN Judo Breaking the CDN DoS Protection with Its.pdf:application/pdf},
}

@book{gilad_cdn--demand_2016,
	title = {{CDN}-on-{Demand}: {An} {Affordable} {DDoS} {Defense} via {Untrusted} {Clouds}},
	shorttitle = {{CDN}-on-{Demand}},
	abstract = {We present CDN-on-Demand, a software-based defense that administrators of small to medium websites install to resist powerful DDoS attacks, with a fraction of the cost of comparable commercial CDN services. Upon excessive load, CDN-on-Demand serves clients from a scalable set of proxies that it automatically deploys on multiple IaaS cloud providers. CDN-on-Demand can use less expensive, and less trusted, clouds
to minimize costs. This is facilitated by the clientless secureobjects, which is a new mechanism we present. The clientless secure-objects mechanism avoids trusting the hosts with private keys or user-data, yet does not require installing new client programs. CDN-on-Demand also introduces an origin-connectivity mechanism, which ensures that essential communication with the content-origin is possible, even in case of severe DoS attacks.
A critical feature of CDN-on-Demand is in facilitating easy deployment. We introduce the origin-gateway module, which deploys CDN-on-Demand automatically and transparently, i.e., without introducing changes to web-server configuration or website content. We provide an open-source implementation of CDNon-Demand, which we use to evaluate each component separately as well as the complete system.},
	author = {Gilad, Yossi and Goberman, Michael and Herzberg, Amir and Sudkovitch, Michael},
	month = feb,
	year = {2016},
	doi = {10.14722/ndss.2016.23109},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/49CVLYQA/Gilad et al. - 2016 - CDN-on-Demand An Affordable DDoS Defense via Untr.pdf:application/pdf},
}

@inproceedings{liang_when_2014-1,
	address = {San Jose, CA},
	title = {When {HTTPS} {Meets} {CDN}: {A} {Case} of {Authentication} in {Delegated} {Service}},
	isbn = {978-1-4799-4686-0},
	shorttitle = {When {HTTPS} {Meets} {CDN}},
	url = {http://ieeexplore.ieee.org/document/6956557/},
	doi = {10.1109/SP.2014.12},
	abstract = {Content Delivery Network (CDN) and Hypertext Transfer Protocol Secure (HTTPS) are two popular but independent web technologies, each of which has been well studied individually and independently. This paper provides a systematic study on how these two work together. We examined 20 popular CDN providers and 10,721 of their customer web sites using HTTPS. Our study reveals various problems with the current HTTPS practice adopted by CDN providers, such as widespread use of invalid certiﬁcates, private key sharing, neglected revocation of stale certiﬁcates, and insecure back-end communication. While some of those problems are operational issues only, others are rooted in the fundamental semantic conﬂict between the end-to-end nature of HTTPS and the man-in-the-middle nature of CDN involving multiple parties in a delegated service. To address the delegation problem when HTTPS meets CDN, we proposed and implemented a lightweight solution based on DANE (DNSbased Authentication of Named Entities), an emerging IETF protocol complementing the current Web PKI model. Our implementation demonstrates that it is feasible for HTTPS to work with CDN securely and efﬁciently. This paper intends to provide a context for future discussion within security and CDN community on more preferable solutions.},
	language = {en},
	urldate = {2021-08-31},
	booktitle = {2014 {IEEE} {Symposium} on {Security} and {Privacy}},
	publisher = {IEEE},
	author = {Liang, Jinjin and Jiang, Jian and Duan, Haixin and Li, Kang and Wan, Tao and Wu, Jianping},
	month = may,
	year = {2014},
	pages = {67--82},
	file = {Liang et al. - 2014 - When HTTPS Meets CDN A Case of Authentication in .pdf:/home/tobi/programms/Zotero/storage/FX2MWPZJ/Liang et al. - 2014 - When HTTPS Meets CDN A Case of Authentication in .pdf:application/pdf},
}

@misc{noauthor_maneuvering_nodate,
	title = {Maneuvering {Around} {Clouds} {\textbar} {Proceedings} of the 22nd {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	url = {https://dl.acm.org/doi/10.1145/2810103.2813633},
	urldate = {2021-08-31},
}

@phdthesis{moyer_punching_2021,
	type = {Thesis},
	title = {Punching {Holes} in the {Cloud}: {Direct} {Communication} between {Serverless} {Functions} {Using} {NAT} {Traversal}},
	copyright = {In Copyright},
	shorttitle = {Punching {Holes} in the {Cloud}},
	url = {https://vtechworks.lib.vt.edu/handle/10919/103627},
	abstract = {A growing use for serverless computing is large parallel data processing applications that take advantage of its on-demand scalability. Because individual serverless compute nodes, which are called functions, run in isolated containers, a major challenge with this paradigm is transferring temporary computation data between functions. Previous works have performed inter-function communication using object storage, which is slow, or in-memory databases, which are expensive. We evaluate the use of direct network connections between functions to overcome these limitations. Although function containers block incoming connections, we are able to bypass this restriction using standard NAT traversal techniques. By using an external server, we implement TCP hole punching to establish direct TCP connections between functions. In addition, we develop a communications framework to manage NAT traversal and data flow for applications using direct network connections. We evaluate this framework with a reduce-by-key application compared to an equivalent version that uses object storage for communication. For a job with 100+ functions, our TCP implementation runs 4.7 times faster at almost half the cost.},
	language = {en},
	urldate = {2021-08-31},
	school = {Virginia Tech},
	author = {Moyer, Daniel William},
	month = jun,
	year = {2021},
	note = {Accepted: 2021-06-05T08:02:21Z
Artwork Medium: ETD
Interview Medium: ETD},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/3NJ4MUKE/Moyer - 2021 - Punching Holes in the Cloud Direct Communication .pdf:application/pdf;Snapshot:/home/tobi/programms/Zotero/storage/62LNV68L/103627.html:text/html},
}

@book{tajalizadehkhoob_apples_2016-1,
	title = {Apples, oranges and hosting providers: {Heterogeneity} and security in the hosting market},
	shorttitle = {Apples, oranges and hosting providers},
	author = {Tajalizadehkhoob, Samaneh and Korczynski, Maciej and Noroozian, Arman and H. Ganan, Carlos and Eeten, Michel},
	month = apr,
	year = {2016},
	doi = {10.1109/NOMS.2016.7502824},
	note = {Pages: 297},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/F2PJX3GK/Tajalizadehkhoob et al. - 2016 - Apples, oranges and hosting providers Heterogenei.pdf:application/pdf},
}

@inproceedings{cangialosi_measurement_2016-1,
	address = {Vienna Austria},
	title = {Measurement and {Analysis} of {Private} {Key} {Sharing} in the {HTTPS} {Ecosystem}},
	isbn = {978-1-4503-4139-4},
	url = {https://dl.acm.org/doi/10.1145/2976749.2978301},
	doi = {10.1145/2976749.2978301},
	abstract = {The semantics of online authentication in the web are rather straightforward: if Alice has a certiﬁcate binding Bob’s name to a public key, and if a remote entity can prove knowledge of Bob’s private key, then (barring key compromise) that remote entity must be Bob. However, in reality, many websites—and the majority of the most popular ones—are hosted at least in part by third parties such as Content Delivery Networks (CDNs) or web hosting providers. Put simply: administrators of websites who deal with (extremely) sensitive user data are giving their private keys to third parties. Importantly, this sharing of keys is undetectable by most users, and widely unknown even among researchers.},
	language = {en},
	urldate = {2021-08-31},
	booktitle = {Proceedings of the 2016 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Cangialosi, Frank and Chung, Taejoong and Choffnes, David and Levin, Dave and Maggs, Bruce M. and Mislove, Alan and Wilson, Christo},
	month = oct,
	year = {2016},
	pages = {628--640},
	file = {Cangialosi et al. - 2016 - Measurement and Analysis of Private Key Sharing in.pdf:/home/tobi/programms/Zotero/storage/CXSQEHIH/Cangialosi et al. - 2016 - Measurement and Analysis of Private Key Sharing in.pdf:application/pdf},
}

@article{natarajan_nsdminer_2012-1,
	title = {{NSDMiner}: {Automated} {Discovery} of {Network} {Service} {Dependencies}},
	shorttitle = {{NSDMiner}},
	doi = {10.1109/INFCOM.2012.6195642},
	abstract = {Enterprise networks today host a wide variety of network services, which often depend on each other to provide and support network-based services and applications. Understanding such dependencies is essential for maintaining the well-being of an enterprise network and its applications, particularly in the presence of network attacks and failures. In a typical enterprise network, which is complex and dynamic in configuration, it is non-trivial to identify all these services and their dependencies. Several techniques have been developed to learn such dependencies automatically. However, they are either too complex to fine tune or cluttered with false positives and/or false negatives. In this paper, we propose a suite of novel techniques and develop a new tool named NSDMiner (which stands for Mining for Network Service Dependencies) to automatically discover the dependencies between network services from passively collected network traffic. NSDMiner is non-intrusive; it does not require any modification of existing software, or injection of network packets. More importantly, NSDMiner achieves higher accuracy than previous network-based approaches. Our experimental eval-uation, which uses network traffic collected from our campus network, shows that NSDMiner outperforms the two best existing solutions significantly.},
	journal = {Proceedings - IEEE INFOCOM},
	author = {Natarajan, Arun and Ning, Peng and Liu, Yao and Jajodia, Sushil and Hutchinson, Steve},
	month = mar,
	year = {2012},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/89NF3Z2D/Natarajan et al. - 2012 - NSDMiner Automated Discovery of Network Service D.pdf:application/pdf},
}

@inproceedings{kumar_security_2017-1,
	address = {Perth Australia},
	title = {Security {Challenges} in an {Increasingly} {Tangled} {Web}},
	isbn = {978-1-4503-4913-0},
	url = {https://dl.acm.org/doi/10.1145/3038912.3052686},
	doi = {10.1145/3038912.3052686},
	abstract = {Over the past 20 years, websites have grown increasingly complex and interconnected. In 2016, only a negligible number of sites are dependency free, and over 90\% of sites rely on external content. In this paper, we investigate the current state of web dependencies and explore two security challenges associated with the increasing reliance on external services: (1) the expanded attack surface associated with serving unknown, implicitly trusted third-party content, and (2) how the increased set of external dependencies impacts HTTPS adoption. We hope that by shedding light on these issues, we can encourage developers to consider the security risks associated with serving third-party content and prompt service providers to more widely deploy HTTPS.},
	language = {en},
	urldate = {2021-08-31},
	booktitle = {Proceedings of the 26th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Kumar, Deepak and Ma, Zane and Durumeric, Zakir and Mirian, Ariana and Mason, Joshua and Halderman, J. Alex and Bailey, Michael},
	month = apr,
	year = {2017},
	pages = {677--684},
	file = {Kumar et al. - 2017 - Security Challenges in an Increasingly Tangled Web.pdf:/home/tobi/programms/Zotero/storage/WYEQJUIE/Kumar et al. - 2017 - Security Challenges in an Increasingly Tangled Web.pdf:application/pdf},
}

@article{maeser_analyzing_2020,
	title = {Analyzing {CSP} {Trustworthiness} and {Predicting} {Cloud} {Service} {Performance}},
	volume = {PP},
	doi = {10.1109/OJCS.2020.2994095},
	abstract = {Analytics firm Cyence estimated Amazon's four-hour cloud computing outage in 2017 “cost S\&P 500 companies at least \$150 million” and traffic monitoring firm Apica claimed “54 of the top 100 online retailers saw site performance slump by at least 20 percent”. According to Ponemon, 2015 data center outages cost Fortune 1000 companies between \$1.25 and \$2.5 billion. Despite potential risks, the cloud computing industry continues to grow. For example, Internet of Things, which is projected to grow 266\% between 2013 and 2020, will drive increased demand on cloud computing as data across multiple industries is collected and sent back to cloud data centers for processing. RightScale estimates enterprises will continue to increase cloud demand with 85\% having multi-cloud strategies. This growth and dependency will influence risk exposure and potential for impact (e.g. availability, performance, security, financial). The research in this paper and proposed solution calculates cloud service provider (CSP) trustworthiness levels and predicts cloud service and cloud service level agreement (SLA) availability performance. Evolving industry standards (e.g. NIST, ISO/IEC) for cloud SLAs and existing work regarding CSP trustworthiness will be leveraged as regression-based predictive models are constructed to analyze CSP cloud computing services, SLA performance and CSP trustworthiness.},
	journal = {IEEE Computer Graphics and Applications},
	author = {Maeser, Robert},
	month = may,
	year = {2020},
	pages = {1--1},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/W2Q6SMTV/Maeser - 2020 - Analyzing CSP Trustworthiness and Predicting Cloud.pdf:application/pdf},
}

@inproceedings{liu_what_2019,
	address = {New York, NY, USA},
	series = {{HotOS} '19},
	title = {What bugs cause production cloud incidents?},
	isbn = {978-1-4503-6727-1},
	url = {https://doi.org/10.1145/3317550.3321438},
	doi = {10.1145/3317550.3321438},
	abstract = {Cloud services have become the backbone of today's computing world. Runtime incidents, which adversely affect the expected service operations, are extremely costly in terms of user impacts and engineering efforts required to resolve them. Hence, such incidents are the target of much research effort. Unfortunately, there is limited understanding about cloud service incidents that actually happen during production runs: what cause them and how they are resolved. In this work, we carefully study hundreds of high-severity incidents that occurred recently during the production runs of many Microsoft Azure services. We find software bugs to be a major cause behind these incidents, and make interesting observations about the types of software bugs that cause cloud incidents and how these bug-related incidents are resolved, providing motivation and guidance to future research in tackling cloud bugs and improving the cloud-service availability.},
	urldate = {2021-09-06},
	booktitle = {Proceedings of the {Workshop} on {Hot} {Topics} in {Operating} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Haopeng and Lu, Shan and Musuvathi, Madan and Nath, Suman},
	month = may,
	year = {2019},
	keywords = {bug characteristics, Cloud system, production incident, reliability},
	pages = {155--162},
}

@inproceedings{gunawi_why_2016,
	address = {New York, NY, USA},
	series = {{SoCC} '16},
	title = {Why {Does} the {Cloud} {Stop} {Computing}? {Lessons} from {Hundreds} of {Service} {Outages}},
	isbn = {978-1-4503-4525-5},
	shorttitle = {Why {Does} the {Cloud} {Stop} {Computing}?},
	url = {https://doi.org/10.1145/2987550.2987583},
	doi = {10.1145/2987550.2987583},
	abstract = {We conducted a cloud outage study (COS) of 32 popular Internet services. We analyzed 1247 headline news and public post-mortem reports that detail 597 unplanned outages that occurred within a 7-year span from 2009 to 2015. We analyzed outage duration, root causes, impacts, and fix procedures. This study reveals the broader availability landscape of modern cloud services and provides answers to why outages still take place even with pervasive redundancies.},
	urldate = {2021-09-06},
	booktitle = {Proceedings of the {Seventh} {ACM} {Symposium} on {Cloud} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Gunawi, Haryadi S. and Hao, Mingzhe and Suminto, Riza O. and Laksono, Agung and Satria, Anang D. and Adityatama, Jeffry and Eliazar, Kurnia J.},
	month = oct,
	year = {2016},
	pages = {1--16},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/E54I643N/Gunawi et al. - 2016 - Why Does the Cloud Stop Computing Lessons from Hu.pdf:application/pdf},
}

@inproceedings{muzayan_haq_effect_2021,
	address = {Virtual Event},
	title = {The effect of consumer portfolio on the risk profile of cloud provider},
	isbn = {978-1-4503-8629-6},
	url = {https://dl.acm.org/doi/10.1145/3472716.3472851},
	doi = {10.1145/3472716.3472851},
	abstract = {The economies-of-scale model of Cloud services has brought many financial and technical benefits for organizations. However, recent events like the attack on Dyn and GitHub have shown that successful attacks on big Cloud providers can cause a massive impact on a major portion of the Internet ecosystem. In this project, we will study how the consumer portfolio of a Cloud provider may affect its risk profile. We will use the result to develop a recommender system for choosing a Cloud provider based on consumer security and business requirements. Insights from our research can be used to simulate an alternative more secure market structure for the Cloud ecosystem. We invite fellow researchers to further discuss this idea and possible collaboration.},
	language = {en},
	urldate = {2021-09-06},
	booktitle = {Proceedings of the {SIGCOMM} '21 {Poster} and {Demo} {Sessions}},
	publisher = {ACM},
	author = {Muzayan Haq, Muhammad Yasir and Abhishta, Abhishta and Nieuwenhuis, Lambert J. M.},
	month = aug,
	year = {2021},
	pages = {18--20},
	file = {Muzayan Haq et al. - 2021 - The effect of consumer portfolio on the risk profi.pdf:/home/tobi/programms/Zotero/storage/QKGILGCR/Muzayan Haq et al. - 2021 - The effect of consumer portfolio on the risk profi.pdf:application/pdf},
}

@article{sommese_characterization_nodate,
	title = {Characterization of {Anycast} {Adoption} in the {DNS} {Authoritative} {Infrastructure}},
	abstract = {Anycast has proven to be an effective mechanism to enhance resilience in the DNS ecosystem and for scaling DNS nameserver capacity, both in authoritative and the recursive resolver infrastructure. Since its adoption for root servers, anycast has mitigated the impact of failures and DDoS attacks on the DNS ecosystem. In this work, we quantify the adoption of anycast to support authoritative domain name service for toplevel and second-level domains (TLDs and SLDs). Comparing two comprehensive anycast census datasets in 2017 and 2021, with DNS measurements captured over the same period, reveals that anycast adoption is increasing, driven by a few large operators. While anycast offers compelling resilience advantage, it also shifts some resilience risk to other aspects of the infrastructure. We discuss these aspects, and how the pervasive use of anycast merits a re-evaluation of how to measure DNS resilience.},
	language = {en},
	author = {Sommese, Raffaele and Akiwate, Gautam and Jonker, Mattijs and Moura, Giovane C M and Davids, Marco and van Rijswijk-Deij, Roland and Voelker, Geoffrey M and Savage, Stefan and Claffy, K C and Sperotto, Anna},
	pages = {9},
	file = {Sommese et al. - Characterization of Anycast Adoption in the DNS Au.pdf:/home/tobi/programms/Zotero/storage/3IRWBYKI/Sommese et al. - Characterization of Anycast Adoption in the DNS Au.pdf:application/pdf},
}

@incollection{barolli__2020,
	address = {Cham},
	title = {: {Measuring} {Centralization} of {DNS} {Infrastructure} in the {Wild}},
	volume = {1151},
	isbn = {978-3-030-44040-4 978-3-030-44041-1},
	url = {http://link.springer.com/10.1007/978-3-030-44041-1_76},
	abstract = {The Internet Domain Naming System (DNS) is one of the pillars for the Internet and has been the subject of various Distributed Denial-of-Service (DDoS) attacks over the years. As a countermeasure, the DNS infrastructure has been engineered with a series of replication measures, such as relying on multiple authoritative name servers and using IP anycast. Even though these measures have been in place, we have seen that, when servers rely on third-party DNS providers for reliable services, there may be certain levels of infrastructure centralization. In this case, an attack against a DNS target might aﬀect other authoritative DNS servers sharing part of the infrastructure with the intended victim. However, measuring such levels of infrastructure sharing is a daunting task, given that researchers typically do not have access to DNS provider internals. In this paper, we introduce a methodology and associated tool dnstracker that allows measuring, to various degrees, the level of both concentration and shared infrastructure using active DNS measurements. As a case study, we analyze the authoritative name servers of all domains of the Alexa Top 1 Million most visited websites. Our results show that, in some cases, up to 12.000 authoritative name servers share the same underlying infrastructure of a third-party DNS provider. As such, in the event of an attack, those authoritative DNS servers have increased the probability of suﬀering from collateral damage.},
	language = {en},
	urldate = {2021-09-06},
	booktitle = {Advanced {Information} {Networking} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Zembruzki, Luciano and Jacobs, Arthur Selle and Landtreter, Gustavo Spier and Granville, Lisandro Zambenedetti and Moura, Giovane C. M.},
	editor = {Barolli, Leonard and Amato, Flora and Moscato, Francesco and Enokido, Tomoya and Takizawa, Makoto},
	year = {2020},
	doi = {10.1007/978-3-030-44041-1_76},
	note = {Series Title: Advances in Intelligent Systems and Computing},
	pages = {871--882},
	file = {Zembruzki et al. - 2020 -  Measuring Centralization of DNS Infrastructure i.pdf:/home/tobi/programms/Zotero/storage/HDBSR45F/Zembruzki et al. - 2020 -  Measuring Centralization of DNS Infrastructure i.pdf:application/pdf},
}

@inproceedings{doan_longitudinal_2020,
	title = {A {Longitudinal} {View} of {Netflix}: {Content} {Delivery} over {IPv6} and {Content} {Cache} {Deployments}},
	shorttitle = {A {Longitudinal} {View} of {Netflix}},
	doi = {10.1109/INFOCOM41043.2020.9155367},
	abstract = {We present an active measurement test (netflix) that downloads content from the Netflix content delivery network. The test measures latency and achievable throughput as key performance indicators when downloading the content from Netflix. We deployed the test on 100 SamKnows probes connected to dual-stacked networks representing 74 different origin ASes. Using a 2.75 year-long (Jul 2016-Apr 2019) dataset, we observe Netflix Open Connect Appliance (OCA) infrastructure to be highly available, although some vantage points experience low success rates connecting over IPv6. We witness that clients prefer connecting to Netflix OCAs over IPv6, although the preference over IPv6 tends to drop over certain peak hours during the day. The TCP connect times toward the OCAs have reduced by 40\% and the achievable throughput has increased by 20\% over the measurement duration. We also provision scamper right after the netflix test to capture the forwarding path toward the Netflix OCAs. We observe that the Netflix OCA caches deployed inside the ISP are reachable within six IP hops and can reduce IP path lengths by 40\% over IPv4 and by half over IPv6. Consequently, TCP connect times are reduced by 64\% over both address families. The achieved throughput can also increase by a factor of three when such ISP caches are used to stream content. This is the first study to measure Netflix content delivery from residential networks, since the inception of the Netflix CDN infrastructure in 2011. To encourage reproducibility of our work, an anonymized version of the entire longitudinal dataset is publicly released.},
	booktitle = {{IEEE} {INFOCOM} 2020 - {IEEE} {Conference} on {Computer} {Communications}},
	author = {Doan, Trinh Viet and Bajpai, Vaibhav and Crawford, Sam},
	month = jul,
	year = {2020},
	note = {ISSN: 2641-9874},
	keywords = {IP networks, Servers, Bandwidth, Google, Probes, Streaming media, Throughput},
	pages = {1073--1082},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/SIB8N3UR/9155367.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/DCTYJ6TV/Doan et al. - 2020 - A Longitudinal View of Netflix Content Delivery o.pdf:application/pdf},
}

@article{abhishta_measuring_2018,
	title = {Measuring the {Impact} of a {Successful} {DDoS} {Attack} on the {Customer} {Behaviour} of {Managed} {DNS} {Service} {Providers}[1]},
	volume = {48},
	abstract = {Distributed Denial-of-Service (DDoS) attacks continue to pose a serious threat to the availability of Internet services. The Domain Name System (DNS) is part of the core of the Internet and a crucial factor in the successful delivery of Internet services. Because of the importance of DNS, specialist service providers have sprung up in the market, that provide managed DNS services. One of their key selling points is that they protect DNS for a domain against DDoS attacks. But what if such a service becomes the target of a DDoS attack, and that attack succeeds? In this paper we analyse two such events, an attack on NS1 in May 2016, and an attack on Dyn in October 2016. We do this by analysing the change in the behaviour of the service’s customers. For our analysis we leverage data from the OpenINTEL active DNS measurement system, which covers large parts of the global DNS over time. Our results show an almost immediate and statistically significant change in the behaviour of domains that use NS1 or Dyn as a DNS service provider. We observe a decline in the number of domains that exclusively use NS1 or Dyn as a managed DNS service provider, and see a shift toward risk spreading by using multiple providers. While a large managed DNS provider may be better equipped to protect against attacks, these two case studies show they are not impervious to them. This calls into question the wisdom of using a single provider for managed DNS. Our results show that spreading risk by using multiple providers is an effective countermeasure, albeit probably at a higher cost.},
	language = {en},
	number = {5},
	journal = {ACM SIGCOMM Computer Communication Review},
	author = {Abhishta, Abhishta},
	year = {2018},
	pages = {7},
	file = {Abhishta - 2018 - Measuring the Impact of a Successful DDoS Attack o.pdf:/home/tobi/programms/Zotero/storage/3A37L6XF/Abhishta - 2018 - Measuring the Impact of a Successful DDoS Attack o.pdf:application/pdf},
}

@article{demirbas_does_2018,
	title = {Does {The} {Cloud} {Need} {Stabilizing}?},
	abstract = {The last decade has witnessed rapid proliferation of cloud computing. While even the smallest distributed programs (with 3-5 actions) produce many unanticipated error cases due to concurrency involved, it seems short of a miracle these web-services are able to operate at those vast scales. In this paper, we explore the factors that contribute most to the high-availability of cloud computing services and examine where self-stabilization could fit in that picture.},
	journal = {ArXiv},
	author = {Demirbas, M. and Charapko, Aleksey and Ailijiang, Ailidani},
	year = {2018},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/J23XYXWM/Demirbas et al. - 2018 - Does The Cloud Need Stabilizing.pdf:application/pdf},
}

@article{huang_gray_2017,
	title = {Gray {Failure}: {The} {Achilles}' {Heel} of {Cloud}-{Scale} {Systems}},
	shorttitle = {Gray {Failure}},
	doi = {10.1145/3102980.3103005},
	abstract = {Cloud scale provides the vast resources necessary to replace failed components, but this is useful only if those failures can be detected. For this reason, the major availability breakdowns and performance anomalies we see in cloud environments tend to be caused by subtle underlying faults, i.e., gray failure rather than fail-stop failure. In this paper, we discuss our experiences with gray failure in production cloud-scale systems to show its broad scope and consequences. We also argue that a key feature of gray failure is differential observability: that the system's failure detectors may not notice problems even when applications are afflicted by them. This realization leads us to believe that, to best deal with them, we should focus on bridging the gap between different components' perceptions of what constitutes failure.},
	journal = {HotOS},
	author = {Huang, Peng and Guo, Chuanxiong and Zhou, Lidong and Lorch, Jacob R. and Dang, Yingnong and Chintalapati, Murali and Yao, Randolph},
	year = {2017},
}

@article{meza_large_2018,
	title = {A {Large} {Scale} {Study} of {Data} {Center} {Network} {Reliability}},
	doi = {10.1145/3278532.3278566},
	abstract = {The ability to tolerate, remediate, and recover from network incidents (caused by device failures and fiber cuts, for example) is critical for building and operating highly-available web services. Achieving fault tolerance and failure preparedness requires system architects, software developers, and site operators to have a deep understanding of network reliability at scale, along with its implications on the software systems that run in data centers. Unfortunately, little has been reported on the reliability characteristics of large scale data center network infrastructure, let alone its impact on the availability of services powered by software running on that network infrastructure. This paper fills the gap by presenting a large scale, longitudinal study of data center network reliability based on operational data collected from the production network infrastructure at Facebook, one of the largest web service providers in the world. Our study covers reliability characteristics of both intra and inter data center networks. For intra data center networks, we study seven years of operation data comprising thousands of network incidents across two different data center network designs, a cluster network design and a state-of-the-art fabric network design. For inter data center networks, we study eighteen months of recent repair tickets from the field to understand reliability of Wide Area Network (WAN) backbones. In contrast to prior work, we study the effects of network reliability on software systems, and how these reliability characteristics evolve over time. We discuss the implications of network reliability on the design, implementation, and operation of large scale data center systems and how it affects highly-available web services. We hope our study forms a foundation for understanding the reliability of large scale network infrastructure, and inspires new reliability solutions to network incidents.},
	journal = {Internet Measurement Conference},
	author = {Meza, Justin and Xu, Tianyin and Veeraraghavan, K. and Mutlu, O.},
	year = {2018},
	file = {Full Text:/home/tobi/programms/Zotero/storage/4MPG3DM5/Meza et al. - 2018 - A Large Scale Study of Data Center Network Reliabi.pdf:application/pdf},
}

@inproceedings{alquraan_analysis_2018,
	title = {An {Analysis} of {Network}-{Partitioning} {Failures} in {Cloud} {Systems}},
	abstract = {We present a comprehensive study of 136 system failures attributed to network-partitioning faults from 25 widely used distributed systems. We found that the majority of the failures led to catastrophic effects, such as data loss, reappearance of deleted data, broken locks, and system crashes. The majority of the failures can easily manifest once a network partition occurs: They require little to no client input, can be triggered by isolating a single node, and are deterministic. However, the number of test cases that one must consider is extremely large. Fortunately, we identify ordering, timing, and network fault characteristics that significantly simplify testing. Furthermore, we found that a significant number of the failures are due to design flaws in core system mechanisms. We found that the majority of the failures could have been avoided by design reviews, and could have been discovered by testing with network-partitioning fault injection. We built NEAT, a testing framework that simplifies the coordination of multiple clients and can inject different types of network-partitioning faults. We used NEAT to test seven popular systems and found and reported 32 failures.},
	booktitle = {{OSDI}},
	author = {Alquraan, Ahmed and Takruri, Hatem and Alfatafta, M. and Al-Kiswany, S.},
	year = {2018},
}

@article{bhardwaj_comprehensive_2021,
	title = {A {Comprehensive} {Study} of {Bugs} in {Software} {Defined} {Networks}},
	doi = {10.1109/DSN48987.2021.00026},
	abstract = {Software-defined networking (SDN) enables innovative and impressive solutions in the networking domain by decoupling the control plane from the data plane. In an SDN environment, the network control logic for load balancing, routing, and access control is written in software running on a decoupled control plane. As with any software development cycle, the SDN control plane is prone to bugs that impact the network’s performance and availability. Yet, as a community, we lack holistic, in-depth studies of bugs within the SDN ecosystem. A bug taxonomy is one of the most promising ways to lay the foundations required for (1) evaluating and directing emerging research directions on fault detection and recovery, and (2) informing operational practices of network administrators. This paper takes the first step towards laying this foundation by providing a comprehensive study and analysis of over 500 ‘critical’ bugs (including \${\textbackslash}sim 150\$ with manual analysis) in three of the most widely-used SDN controllers, i.e., FAUCET, ONOS, and CORD. We create a taxonomy of these SDN bugs, analyze their operational impact, and implications for the developers. We use our taxonomy to analyze the effectiveness and coverage of several prominent SDN fault tolerance and diagnosis techniques. This study is the first of its kind in scale and coverage to the best of our knowledge.},
	journal = {2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)},
	author = {Bhardwaj, Ayushi and Zhou, Zhenyu and Benson, Theophilus A.},
	year = {2021},
}

@article{chen_understanding_2020,
	title = {Understanding and discovering software configuration dependencies in cloud and datacenter systems},
	doi = {10.1145/3368089.3409727},
	abstract = {A large percentage of real-world software configuration issues, such as misconfigurations, involve multiple interdependent configuration parameters. However, existing techniques and tools either do not consider dependencies among configuration parameters— termed configuration dependencies—or rely on one or two dependency types and code patterns as input. Without rigorous understanding of configuration dependencies, it is hard to deal with many resulting configuration issues. This paper presents our study of software configuration dependencies in 16 widely-used cloud and datacenter systems, including dependencies within and across software components. To understand types of configuration dependencies, we conduct an exhaustive search of descriptions in structured configuration metadata and unstructured user manuals. We find and manually analyze 521 configuration dependencies. We define five types of configuration dependencies and identify their common code patterns. We report on consequences of not satisfying these dependencies and current software engineering practices for handling the consequences. We mechanize the knowledge gained from our study in a tool, cDep, which detects configuration dependencies. cDep automatically discovers five types of configuration dependencies from bytecode using static program analysis. We apply cDep to the eight Java and Scala software systems in our study. cDep finds 87.9\% (275/313) of the related subset of dependencies from our study. cDep also finds 448 previously undocumented dependencies, with a 6.0\% average false positive rate. Overall, our results show that configuration dependencies are more prevalent and diverse than previously reported and should henceforth be considered a first-class issue in software configuration engineering.},
	journal = {ESEC/SIGSOFT FSE},
	author = {Chen, Qingrong and Wang, Teng and Legunsen, Owolabi and Li, Shanshan and Xu, Tianyin},
	year = {2020},
	file = {Submitted Version:/home/tobi/programms/Zotero/storage/IPDLFYMQ/Chen et al. - 2020 - Understanding and discovering software configurati.pdf:application/pdf},
}

@article{jagadeesan_when_2020,
	title = {When {Failure} is ({Not}) an {Option}: {Reliability} {Models} for {Microservices} {Architectures}},
	shorttitle = {When {Failure} is ({Not}) an {Option}},
	doi = {10.1109/ISSREW51248.2020.00031},
	abstract = {Modern application development and deployment is rapidly evolving to microservices based architectures, in which thousands of microservices communicate with one another and can be independently scaled and updated. While these architectures enable flexibility of deployment and frequency of upgrades, the naive use of thousands of communicating and frequently updated microservices can significantly impact the reliability of applications. To address these challenges, service meshes are used to rapidly detect and respond to microservices failures without necessitating changes to the microservices themselves. However, there are inherent tradeoffs that service meshes must make with regards to how quickly they assume a microservice has failed and the subsequent impact on overall application reliability. We present in this paper a modeling framework for microservices and service mesh reliability that takes these tradeoffs into account. Index Terms–microservices, service mesh, sidecars, circuit breakers, reliability, availability, resilience, reliability models, probabilistic model checking, PRISM.},
	journal = {2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)},
	author = {Jagadeesan, L. and Mendiratta, V.},
	year = {2020},
}

@phdthesis{abhishta_blind_2019,
	title = {The {Blind} {Man} and {The} {Elephant}: {Measuring} {Economic} {Impacts} of {DDoS} {Attacks}},
	shorttitle = {The {Blind} {Man} and {The} {Elephant}},
	abstract = {Internet has become an important part of our everyday life. We use services like Netflix, Skype, online banking and Scopus etc. daily. We even use Internet for filing our tax returns and communicating with municipalities. This dependency on network-based technologies provides an opportunity to malicious actors in our society to remotely attack IT infrastructure. One type of cyberattack that may lead to unavailability of network resources is known as distributed denial of service (DDoS) attack. A DDoS attack leverages many computers to launch a coordinated Denial of Service attack against one or more targets. These attacks cause damages to victim businesses. According to reports published by several consultancies and security companies these attacks lead to millions of dollars in losses every year. One might ponder: are the damages caused by temporary unavailability of network services really this large? One of the points of criticism for these reports has been that they often base their findings on victim surveys and expert opinions. Now, as cost accounting/book keeping methods are not focused on measuring the impact of cyber security incidents, it is highly likely that surveys are unable to capture the true impact of an attack. A troubling fact is that most C-level managers make budgetary decisions for security based on the losses reported in these surveys. Several inputs for security investment decision models such as return on security investment (ROSI) also depend on these figures. This makes the situation very similar to the parable of the blind men and the elephant, in which several blind men try to conceptualise how the elephant looks like by touching it. Hence, it is important to develop methodologies that capture the true impact of DDoS attacks. In this thesis, we study the economic impact of DDoS attacks on public/private organisations by using an empirical approach. In Chapter 1 we explain the motivation for our work and illustrate the problems associated with measuring the economic impacts of DDoS attacks. We then formulate our main research question and break it down into sub-questions that we investigate in later chapters. We state our main research question as follows: What are the economic impacts of DDoS attacks on public/private organisations? Our first contribution is identifying the main stakeholders in a DDoS attack. In Chapter 2, we discuss the evolution of DDoS attacks in the last decade and briefly describe the strategies adopted by attackers and defenders. By studying the business model of a botnet, we also analyse how DDoS attacks can be used by attackers for monetary gains. Our second contribution is to develop methodologies to capture the direct impact of DDoS attacks. In Chapters 3 and 4 we measure the direct consequences of DDoS attacks on large managed domain name service (DNS) providers and a cryptocurrency exchange respectively. We find that a successful DDoS attack on a managed DNS service provider, changes the security behaviour of its customers. In the case of cryptocurrency exchange we find that the losses are recovered very quickly, on most instances even within a single day. We show how longitudinal datasets can be used to asses the impacts. The third contribution of this thesis is to develop methodologies to measure the indirect consequences of DDoS attacks. In Chapter 5, we propose a more robust event study approach and use it to analyse the impact of DDoS attack announcements on victims' stock prices. We find that in most cases this impact is short lived (5-10 days). In Chapter 6, we introduce a dataset based on web articles on DDoS attacks which captures the social context of an attack. We show how machine learning algorithms can be used to filter news articles that are reporting a DDoS attack from the dataset. We recognise that it is not possible to measure the true impact of DDoS attacks on the victim without learning about the aims of attackers. In Chapter 7, we propose a model based on Routine Activity Theory (RAT) to study attacker's aims by using the information about the attack reported in the news articles. Later in Chapter 8, we show how postulates of RAT may be used to explain DDoS attack trends on educational institutions. Our results show that DDoS attacks are not a random phenomenon and attackers are instigated by the circumstances surrounding them. We observe that measuring the true economic impact of these attacks is complex and requires us to consider the context of an attack. Some of the consequences of short duration IT unavailability are temporary and they are recovered rather quickly. Hence, to take this work forward we propose to give economic meaning to the empirical data that is presently available and collect more data at employee level to measure the resilience of firms towards IT unavailability.},
	author = {Abhishta, Abhishta},
	month = dec,
	year = {2019},
	doi = {10.3990/1.9789036549127},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/9TS75PQS/Abhishta - 2019 - The Blind Man and The Elephant Measuring Economic.pdf:application/pdf},
}

@inproceedings{jonker_millions_2017,
	address = {New York, NY, USA},
	series = {{IMC} '17},
	title = {Millions of targets under attack: a macroscopic characterization of the {DoS} ecosystem},
	isbn = {978-1-4503-5118-8},
	shorttitle = {Millions of targets under attack},
	url = {https://doi.org/10.1145/3131365.3131383},
	doi = {10.1145/3131365.3131383},
	abstract = {Denial-of-Service attacks have rapidly increased in terms of frequency and intensity, steadily becoming one of the biggest threats to Internet stability and reliability. However, a rigorous comprehensive characterization of this phenomenon, and of countermeasures to mitigate the associated risks, faces many infrastructure and analytic challenges. We make progress toward this goal, by introducing and applying a new framework to enable a macroscopic characterization of attacks, attack targets, and DDoS Protection Services (DPSs). Our analysis leverages data from four independent global Internet measurement infrastructures over the last two years: backscatter traffic to a large network telescope; logs from amplification honeypots; a DNS measurement platform covering 60\% of the current namespace; and a DNS-based data set focusing on DPS adoption. Our results reveal the massive scale of the DoS problem, including an eye-opening statistic that one-third of all / 24 networks recently estimated to be active on the Internet have suffered at least one DoS attack over the last two years. We also discovered that often targets are simultaneously hit by different types of attacks. In our data, Web servers were the most prominent attack target; an average of 3\% of the Web sites in .com, .net, and .org were involved with attacks, daily. Finally, we shed light on factors influencing migration to a DPS.},
	urldate = {2021-09-09},
	booktitle = {Proceedings of the 2017 {Internet} {Measurement} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Jonker, Mattijs and King, Alistair and Krupp, Johannes and Rossow, Christian and Sperotto, Anna and Dainotti, Alberto},
	month = nov,
	year = {2017},
	keywords = {DDoS, cloud-based mitigation, reflection attacks, spoofed attacks},
	pages = {100--113},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/9AWT8YDD/Jonker et al. - 2017 - Millions of targets under attack a macroscopic ch.pdf:application/pdf},
}

@misc{noauthor_measuring_nodate,
	title = {Measuring the impact of a successful {DDoS} attack on the customer behaviour of managed {DNS} service providers {\textbar} {ACM} {SIGCOMM} {Computer} {Communication} {Review}},
	url = {https://dl.acm.org/doi/10.1145/3310165.3310175},
	urldate = {2021-09-09},
	file = {Measuring the impact of a successful DDoS attack on the customer behaviour of managed DNS service providers | ACM SIGCOMM Computer Communication Review:/home/tobi/programms/Zotero/storage/6J2FJJAB/3310165.html:text/html},
}

@book{carroll_secure_2011,
	title = {Secure cloud computing: {Benefits}, risks and controls},
	volume = {1-9},
	shorttitle = {Secure cloud computing},
	abstract = {Cloud computing presents a new model for IT service delivery and it typically involves over-a-network, on-demand, self-service access, which is dynamically scalable and elastic, utilising pools of often virtualized resources. Through these features, cloud computing has the potential to improve the way businesses and IT operate by offering fast start-up, flexibility, scalability and cost efficiency. Even though cloud computing provides compelling benefits and cost-effective options for IT hosting and expansion, new risks and opportunities for security exploits are introduced. Standards, policies and controls are therefore of the essence to assist management in protecting and safeguarding systems and data. Management should understand and analyse cloud computing risks in order to protect systems and data from security exploits. The focus of this paper is on mitigation for cloud computing security risks as a fundamental step towards ensuring secure cloud computing environments.},
	author = {Carroll, Mariana and Van der Merwe, Alta and Kotzé, Paula},
	month = sep,
	year = {2011},
	doi = {10.1109/ISSA.2011.6027519},
	note = {Pages: 9},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/CKW3AYZI/Carroll et al. - 2011 - Secure cloud computing Benefits, risks and contro.pdf:application/pdf},
}

@article{liu_nist_nodate,
	title = {{NIST} {Cloud} {Computing} {Reference} {Architecture}},
	language = {en},
	author = {Liu, Fang and Tong, Jin and Mao, Jian and Bohn, Robert and Messina, John and Badger, Lee and Leaf, Dawn},
	pages = {35},
	file = {Liu et al. - NIST Cloud Computing Reference Architecture.pdf:/home/tobi/programms/Zotero/storage/HGQTWIAE/Liu et al. - NIST Cloud Computing Reference Architecture.pdf:application/pdf},
}

@inproceedings{matic_identifying_2020,
	address = {New York, NY, USA},
	series = {{IMC} '20},
	title = {Identifying {Sensitive} {URLs} at {Web}-{Scale}},
	isbn = {978-1-4503-8138-3},
	url = {https://doi.org/10.1145/3419394.3423653},
	doi = {10.1145/3419394.3423653},
	abstract = {Several data protection laws include special provisions for protecting personal data relating to religion, health, sexual orientation, and other sensitive categories. Having a well-defined list of sensitive categories is sufficient for filing complaints manually, conducting investigations, and prosecuting cases in courts of law. Data protection laws, however, do not define explicitly what type of content falls under each sensitive category. Therefore, it is unclear how to implement proactive measures such as informing users, blocking trackers, and filing complaints automatically when users visit sensitive domains. To empower such use cases we turn to the Curlie.org crowdsourced taxonomy project for drawing training data to build a text classifier for sensitive URLs. We demonstrate that our classifier can identify sensitive URLs with accuracy above 88\%, and even recognize specific sensitive categories with accuracy above 90\%. We then use our classifier to search for sensitive URLs in a corpus of 1 Billion URLs collected by the Common Crawl project. We identify more than 155 millions sensitive URLs in more than 4 million domains. Despite their sensitive nature, more than 30\% of these URLs belong to domains that fail to use HTTPS. Also, in sensitive web pages with third-party cookies, 87\% of the third-parties set at least one persistent cookie.},
	urldate = {2021-09-09},
	booktitle = {Proceedings of the {ACM} {Internet} {Measurement} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Matic, Srdjan and Iordanou, Costas and Smaragdakis, Georgios and Laoutaris, Nikolaos},
	month = oct,
	year = {2020},
	pages = {619--633},
	file = {Accepted Version:/home/tobi/programms/Zotero/storage/C9Y6TSKB/Matic et al. - 2020 - Identifying Sensitive URLs at Web-Scale.pdf:application/pdf},
}

@article{van_rijswijk-deij_high-performance_2016,
	title = {A {High}-{Performance}, {Scalable} {Infrastructure} for {Large}-{Scale} {Active} {DNS} {Measurements}},
	volume = {34},
	issn = {1558-0008},
	doi = {10.1109/JSAC.2016.2558918},
	abstract = {The domain name system (DNS) is a core component of the Internet. It performs the vital task of mapping human readable names into machine readable data (such as IP addresses, which hosts handle e-mail, and so on). The content of the DNS reveals a lot about the technical operations of a domain. Thus, studying the state of large parts of the DNS over time reveals valuable information about the evolution of the Internet. We collect a unique long-term data set with daily DNS measurements for all the domains under the main top-level domains (TLDs) on the Internet (including .com, .net, and .org, comprising 50\% of the global DNS name space). This paper discusses the challenges of performing such a large-scale active measurement. These challenges include scaling the daily measurement to collect data for the largest TLD (.com, with 123M names) and ensuring that a measurement of this scale does not impose an unacceptable burden on the global DNS infrastructure. The paper discusses the design choices we have made to meet these challenges and documents the design of the measurement system we implemented based on these choices. Two case studies related to cloud e-mail services illustrate the value of measuring the DNS at this scale. The data this system collects is valuable to the network research community. Therefore, we end this paper by discussing how we make the data accessible to other researchers.},
	number = {6},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {van Rijswijk-Deij, Roland and Jonker, Mattijs and Sperotto, Anna and Pras, Aiko},
	month = jun,
	year = {2016},
	note = {Conference Name: IEEE Journal on Selected Areas in Communications},
	keywords = {DNS, Cloud computing, Servers, active measurements, Area measurement, cloud, Internet evolution, Metals, Postal services},
	pages = {1877--1888},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/3MSIL92F/7460220.html:text/html},
}

@article{abhishta_why_2020,
	title = {Why would we get attacked? {An} analysis of attacker's aims behind {DDoS} attacks},
	volume = {11},
	shorttitle = {Why would we get attacked?},
	doi = {10.22667/JOWUA.2020.06.30.003},
	abstract = {Reliable availability to the internet and internet-based services is crucial in today's world. DDoS attacks pose a severe threat to the availability of such online resources-especially owing to booters-virtually everyone can execute them nowadays. In order to appropriately protect oneself against such attacks, it is essential to have a good insight into the threats that exist. This paper proposes a novel hybrid model that combines postulates from various models on crime opportunity, analyzing the targeted victim and the targeted infrastructure in conjunction. We apply this model to analyze 27 distinct attack events that occurred in 2016. To construct this dataset, we utilize a longitudinal news database specific to DDoS-related events, aiding to select relevant attack events. We outline the procedure to replicate the dataset construction process. Looking at DDoS attacks solely as a technical issue is not enough, news articles can be an important resource in providing contextual relevance to this problem. Our analysis reveals several motives underlying DDoS attacks; economic reasons are but one of the possible aims. For this reason, we advise companies to also monitor the socio-cultural and political environment. In terms of infrastructure, visibility and accessibility are the main instiga-tors for an attack. A holistic perspective is imperative to accurately map the threats that companies face and to take appropriate protective measures.},
	journal = {Journal of Wireless Mobile Networks},
	author = {Abhishta, Abhishta and van Heeswijk, Wouter and Junger, Marianne and Nieuwenhuis, Bart and Joosten, Reinoud},
	month = jun,
	year = {2020},
	pages = {3--22},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/V3SU4NB7/Abhishta et al. - 2020 - Why would we get attacked An analysis of attacker.pdf:application/pdf},
}

@misc{suminto_database-backed_2021,
	title = {Database-{Backed} {Program} {Analysis} for {Finding} {Cascading} {Outage} {Bugs} in {Distributed} {Systems}},
	url = {https://www.semanticscholar.org/paper/Database-Backed-Program-Analysis-for-Finding-Outage-Suminto-Lu/a20892fe2460f10a182614ae147f3e120b905e01},
	abstract = {Modern distributed systems (“cloud systems”) have emerged as a dominant backbone for many of today’s applications. As these systems collectively become the “cloud operating system”, users expect high dependability including performance stability and availability. Small jitters in system performance or minutes of service downtimes can have a huge impact on company and user satisfaction. We try to improve cloud system availability by detecting and eliminating cascading outage bugs (CO bugs). CO bug is a bug that can cause simultaneous or cascades of failures to each of the individual nodes in the system, which eventually leads to a major outage. While hardware arguably is no longer a single point of failure, our large-scale studies of cloud bugs and outages reveal that CO bugs have emerged as a new class of outage-causing bugs and single point of failure in the software. We address the CO bug problem with the Cascading Outage Bugs Elimination (COBE) project. In this project, we: (1) study the anatomy of CO bugs, (2) develop CO-bug detection tools to unearth CO bugs.},
	language = {en},
	urldate = {2021-09-10},
	author = {Suminto, Riza O. and Lu, Shan and Rubio-González, Cindy and Gunawi, Haryadi S.},
	year = {2021},
}

@article{li_challenges_2021,
	title = {Challenges and opportunities: an in-depth empirical study on configuration error injection testing},
	shorttitle = {Challenges and opportunities},
	doi = {10.1145/3460319.3464799},
	abstract = {Configuration error injection testing (CEIT) could systematically evaluate software reliability and diagnosability to runtime configuration errors. This paper explores the challenges and opportunities of applying CEIT technique. We build an extensible, highly-modularized CEIT framework named CeitInspector to experiment with various CEIT techniques. Using CeitInspector, we quantitatively measure the effectiveness and efficiency of CEIT using six mature and widely-used server applications. During this process, we find a fair number of test cases are left unstudied by the prior research work. The injected configuration errors in these cases often indicate latent misconfigurations, which might be ticking time bombs in the system and lead to severe damage. We conduct an in-depth study regarding these cases to reveal the root causes, and explore possible remedies. Finally, we come up with actionable suggestions guided by our study to improve the effectiveness and efficiency of the existing CEIT techniques.},
	journal = {ISSTA},
	author = {Li, Wang and Jia, Zhouyang and Li, Shanshan and Zhang, Yuanliang and Wang, Teng and Xu, Erci and Wang, Ji and Liao, Xiangke},
	year = {2021},
}

@inproceedings{sun_testing_2020,
	title = {Testing {Configuration} {Changes} in {Context} to {Prevent} {Production} {Failures}},
	abstract = {Large-scale cloud services deploy hundreds of configuration changes to production systems daily. At such velocity, configuration changes have inevitably become prevalent causes of production failures. Existing misconfiguration detection and configuration validation techniques only check configuration values. These techniques cannot detect common types of failure-inducing configuration changes, such as those that cause code to fail or those that violate hidden constraints. We present ctests, a new type of tests for detecting failureinducing configuration changes to prevent production failures. The idea behind ctests is simple—connecting production system configurations to software tests so that configuration changes can be tested in the context of code affected by the changes. So, ctests can detect configuration changes that expose dormant software bugs and diverse misconfigurations. We show how to generate ctests by transforming the many existing tests in mature systems. The key challenge that we address is the automated identification of test logic and oracles that can be reused in ctests. We generated thousands of ctests from the existing tests in five cloud systems. Our results show that ctests are effective in detecting failure-inducing configuration changes before deployment. We evaluate ctests on real-world failure-inducing configuration changes, injected misconfigurations, and deployed configuration files from public Docker images. Ctests effectively detect real-world failure-inducing configuration changes, diverse injected misconfigurations and misconfigurations in the deployed files.},
	booktitle = {{OSDI}},
	author = {Sun, Xudong and Cheng, Runxiang and Chen, Jianyan and Ang, Elaine and Legunsen, Owolabi and Xu, Tianyin},
	year = {2020},
}

@inproceedings{pujol_back-office_2014,
	address = {Vancouver BC Canada},
	title = {Back-{Office} {Web} {Traffic} on {The} {Internet}},
	isbn = {978-1-4503-3213-2},
	url = {https://dl.acm.org/doi/10.1145/2663716.2663756},
	doi = {10.1145/2663716.2663756},
	abstract = {Although trafﬁc between Web servers and Web browsers is readily apparent to many knowledgeable end users, fewer are aware of the extent of server-to-server Web trafﬁc carried over the public Internet. We refer to the former class of trafﬁc as front-ofﬁce Internet Web trafﬁc and the latter as back-ofﬁce Internet Web trafﬁc (or just front-ofﬁce and back-ofﬁce trafﬁc, for short). Back-ofﬁce trafﬁc, which may or may not be triggered by end-user activity, is essential for today’s Web as it supports a number of popular but complex Web services including large-scale content delivery, social networking, indexing, searching, advertising, and proxy services. This paper takes a ﬁrst look at back-ofﬁce trafﬁc, measuring it from various vantage points, including from within ISPs, IXPs, and CDNs. We describe techniques for identifying back-ofﬁce trafﬁc based on the roles that this trafﬁc plays in the Web ecosystem. Our measurements show that back-ofﬁce trafﬁc accounts for a signiﬁcant fraction not only of core Internet trafﬁc, but also of Web transactions in the terms of requests and responses. Finally, we discuss the implications and opportunities that the presence of backofﬁce trafﬁc presents for the evolution of the Internet ecosystem.},
	language = {en},
	urldate = {2021-07-17},
	booktitle = {Proceedings of the 2014 {Conference} on {Internet} {Measurement} {Conference}},
	publisher = {ACM},
	author = {Pujol, Enric and Richter, Philipp and Chandrasekaran, Balakrishnan and Smaragdakis, Georgios and Feldmann, Anja and Maggs, Bruce MacDowell and Ng, Keung-Chi},
	month = nov,
	year = {2014},
	pages = {257--270},
	file = {Pujol et al. - 2014 - Back-Office Web Traffic on The Internet.pdf:/home/tobi/programms/Zotero/storage/9YHNG7E8/Pujol et al. - 2014 - Back-Office Web Traffic on The Internet.pdf:application/pdf},
}

@inproceedings{schomp_akamai_2020,
	address = {Virtual Event USA},
	title = {Akamai {DNS}: {Providing} {Authoritative} {Answers} to the {World}'s {Queries}},
	isbn = {978-1-4503-7955-7},
	shorttitle = {Akamai {DNS}},
	url = {https://dl.acm.org/doi/10.1145/3387514.3405881},
	doi = {10.1145/3387514.3405881},
	abstract = {We present Akamai DNS, one of the largest authoritative DNS infrastructures in the world, that supports the Akamai content delivery network (CDN) as well as authoritative DNS hosting and DNS-based load balancing services for many enterprises. As the starting point for a significant fraction of the world’s Internet interactions, Akamai DNS serves millions of queries each second and must be resilient to avoid disrupting myriad online services, scalable to meet the ever increasing volume of DNS queries, performant to prevent user-perceivable performance degradation, and reconfigurable to react quickly to shifts in network conditions and attacks. We outline the design principles and architecture used to achieve Akamai DNS’s goals, relating the design choices to the system workload and quantifying the effectiveness of those designs. Further, we convey insights from operating the production system that are of value to the broader research community.},
	language = {en},
	urldate = {2021-07-17},
	booktitle = {Proceedings of the {Annual} conference of the {ACM} {Special} {Interest} {Group} on {Data} {Communication} on the applications, technologies, architectures, and protocols for computer communication},
	publisher = {ACM},
	author = {Schomp, Kyle and Bhardwaj, Onkar and Kurdoglu, Eymen and Muhaimen, Mashooq and Sitaraman, Ramesh K.},
	month = jul,
	year = {2020},
	pages = {465--478},
	file = {Schomp et al. - 2020 - Akamai DNS Providing Authoritative Answers to the.pdf:/home/tobi/programms/Zotero/storage/KCHPQ8HN/Schomp et al. - 2020 - Akamai DNS Providing Authoritative Answers to the.pdf:application/pdf},
}

@book{corneo_surrounded_2021,
	title = {Surrounded by the {Clouds}: {A} {Comprehensive} {Cloud} {Reachability} {Study}},
	shorttitle = {Surrounded by the {Clouds}},
	abstract = {In the early days of cloud computing, datacenters were sparsely deployed at distant locations far from end-users with high end-to-end communication latency. However, today's cloud datacenters have become more geographically spread, the bandwidth of the networks keeps increasing, pushing the end-users latency down. In this paper, we provide a comprehensive cloud reachability study as we perform extensive global client-to-cloud latency measurements towards 189 datacenters from all major cloud providers. We leverage the well-known measurement platform RIPE Atlas, involving up to 8500 probes deployed in heterogeneous environments, e.g., home and offices. Our goal is to evaluate the suitability of modern cloud environments for various current and predicted applications. We achieve this by comparing our latency measurements against known human perception thresholds and are able to draw inferences on the suitability of current clouds for novel applications, such as augmented reality. Our results indicate that the current cloud coverage can easily support several latency-critical applications , like cloud gaming, for the majority of the world's population.},
	author = {Corneo, Lorenzo and Eder, Maximilian and Mohan, Nitinder and Zavodovski, Aleksandr and Bayhan, Suzan and Wong, Walter and Gunningberg, Per and Kangasharju, Jussi and Ott, Jörg},
	month = feb,
	year = {2021},
	doi = {10.1145/3442381.3449854},
}

@inproceedings{jalaparti_dynamic_2016,
	address = {Florianopolis Brazil},
	title = {Dynamic {Pricing} and {Traffic} {Engineering} for {Timely} {Inter}-{Datacenter} {Transfers}},
	isbn = {978-1-4503-4193-6},
	url = {https://dl.acm.org/doi/10.1145/2934872.2934893},
	doi = {10.1145/2934872.2934893},
	abstract = {As more business moves to the cloud, inter-datacenter bandwidth becomes an ever more valuable and congested resource. This bandwidth is typically sold using a ﬁxed price per GB, and transfers are scheduled using trafﬁc engineering mechanisms. However, this separation between the economic and engineering aspects of the problem makes it difﬁcult to steer customer demand to lightly loaded paths and times, which is important for managing costs (typically proportional to peak usage) and providing service guarantees.},
	language = {en},
	urldate = {2021-09-27},
	booktitle = {Proceedings of the 2016 {ACM} {SIGCOMM} {Conference}},
	publisher = {ACM},
	author = {Jalaparti, Virajith and Bliznets, Ivan and Kandula, Srikanth and Lucier, Brendan and Menache, Ishai},
	month = aug,
	year = {2016},
	pages = {73--86},
	file = {Jalaparti et al. - 2016 - Dynamic Pricing and Traffic Engineering for Timely.pdf:/home/tobi/programms/Zotero/storage/GCC87FLD/Jalaparti et al. - 2016 - Dynamic Pricing and Traffic Engineering for Timely.pdf:application/pdf},
}

@inproceedings{wohlfart_leveraging_2018,
	address = {Budapest Hungary},
	title = {Leveraging interconnections for performance: the serving infrastructure of a large {CDN}},
	isbn = {978-1-4503-5567-4},
	shorttitle = {Leveraging interconnections for performance},
	url = {https://dl.acm.org/doi/10.1145/3230543.3230576},
	doi = {10.1145/3230543.3230576},
	abstract = {Today’s large content providers (CP) are busy building out their service infrastructures or łpeering edgesž to satisfy the insatiable demand for content created by an ever-expanding Internet edge. One component of these serving infrastructures that features prominently in this build-out is their connectivity fabric; i.e., the set of all Internet interconnections that content has to traverse en route from the CP’s various łdeploymentsž or łserving sitesž to end users. However, these connectivity fabrics have received little attention in the past and remain largely ill-understood.},
	language = {en},
	urldate = {2021-09-27},
	booktitle = {Proceedings of the 2018 {Conference} of the {ACM} {Special} {Interest} {Group} on {Data} {Communication}},
	publisher = {ACM},
	author = {Wohlfart, Florian and Chatzis, Nikolaos and Dabanoglu, Caglar and Carle, Georg and Willinger, Walter},
	month = aug,
	year = {2018},
	pages = {206--220},
	file = {Wohlfart et al. - 2018 - Leveraging interconnections for performance the s.pdf:/home/tobi/programms/Zotero/storage/JNPYTIXB/Wohlfart et al. - 2018 - Leveraging interconnections for performance the s.pdf:application/pdf},
}

@article{reda_path_2020,
	title = {Path persistence in the cloud: {A} study of the effects of inter-region traffic engineering in a large cloud provider's network},
	volume = {50},
	issn = {0146-4833},
	shorttitle = {Path persistence in the cloud},
	url = {https://dl.acm.org/doi/10.1145/3402413.3402416},
	doi = {10.1145/3402413.3402416},
	abstract = {A commonly held belief is that traffic engineering and routing changes are infrequent. However, based on our measurements over a number of years of traffic between data centers in one of the largest cloud provider's networks, we found that it is common for flows to change paths at ten-second intervals or even faster. These frequent path and, consequently, latency variations can negatively impact the performance of cloud applications, specifically, latency-sensitive and geo-distributed applications.
            Our recent measurements and analysis focused on observing path changes and latency variations between different Amazon aws regions. To this end, we devised a path change detector that we validated using both ad hoc experiments and feedback from cloud networking experts. The results provide three main insights: (1) Traffic Engineering (TE) frequently moves (TCP and UDP) flows among network paths of different latency, (2) Flows experience unfair performance, where a subset of flows between two machines can suffer large latency penalties (up to 32\% at the 95th percentile) or excessive number of latency changes, and (3) Tenants may have incentives to selfishly move traffic to low latency classes (to boost the performance of their applications). We showcase this third insight with an example using rsync synchronization.
            To the best of our knowledge, this is the first paper to reveal the high frequency of TE activity within a large cloud provider's network. Based on these observations, we expect our paper to spur discussions and future research on how cloud providers and their tenants can ultimately reconcile their independent and possibly conflicting objectives. Our data is publicly available for reproducibility and further analysis at http://goo.gl/25BKte.},
	language = {en},
	number = {2},
	urldate = {2021-09-27},
	journal = {ACM SIGCOMM Computer Communication Review},
	author = {Reda, Waleed and Bogdanov, Kirill and Milolidakis, Alexandros and Ghasemirahni, Hamid and Chiesa, Marco and Maguire, Gerald Q. and Kostić, Dejan},
	month = may,
	year = {2020},
	pages = {11--23},
	file = {Reda et al. - 2020 - Path persistence in the cloud A study of the effe.pdf:/home/tobi/programms/Zotero/storage/GRJ3UAFH/Reda et al. - 2020 - Path persistence in the cloud A study of the effe.pdf:application/pdf},
}

@inproceedings{wu_spanstore_2013,
	address = {Farminton Pennsylvania},
	title = {\textit{{SPANStore}}: cost-effective geo-replicated storage spanning multiple cloud services},
	isbn = {978-1-4503-2388-8},
	shorttitle = {\textit{{SPANStore}}},
	url = {https://dl.acm.org/doi/10.1145/2517349.2522730},
	doi = {10.1145/2517349.2522730},
	abstract = {By offering storage services in several geographically distributed data centers, cloud computing platforms enable applications to offer low latency access to user data. However, application developers are left to deal with the complexities associated with choosing the storage services at which any object is replicated and maintaining consistency across these replicas.},
	language = {en},
	urldate = {2021-09-27},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Wu, Zhe and Butkiewicz, Michael and Perkins, Dorian and Katz-Bassett, Ethan and Madhyastha, Harsha V.},
	month = nov,
	year = {2013},
	pages = {292--308},
	file = {Wu et al. - 2013 - SPANStore cost-effective geo-replicated st.pdf:/home/tobi/programms/Zotero/storage/BJW8M3TD/Wu et al. - 2013 - SPANStore cost-effective geo-replicated st.pdf:application/pdf},
}

@article{wu_costlo_nodate,
	title = {{CosTLO}: {Cost}-{Effective} {Redundancy} for {Lower} {Latency} {Variance} on {Cloud} {Storage} {Services}},
	abstract = {We present CosTLO, a system that reduces the high latency variance associated with cloud storage services by augmenting GET/PUT requests issued by end-hosts with redundant requests, so that the earliest response can be considered. To reduce the cost overhead imposed by redundancy, unlike prior efforts that have used this approach, CosTLO combines the use of multiple forms of redundancy. Since this results in a large number of conﬁgurations in which CosTLO can issue redundant requests, we conduct a comprehensive measurement study on S3 and Azure to identify the conﬁgurations that are viable in practice. Informed by this study, we design CosTLO to satisfy any application’s goals for latency variance by 1) estimating the latency variance offered by any particular conﬁguration, 2) efﬁciently searching through the conﬁguration space to select a cost-effective conﬁguration among the ones that can offer the desired latency variance, and 3) preserving data consistency despite CosTLO’s use of redundant requests. We show that, for the median PlanetLab node, CosTLO can halve the latency variance associated with fetching content from Amazon S3, with only a 25\% increase in cost.},
	language = {en},
	author = {Wu, Zhe and Yu, Curtis and Madhyastha, Harsha V},
	pages = {16},
	file = {Wu et al. - CosTLO Cost-Effective Redundancy for Lower Latenc.pdf:/home/tobi/programms/Zotero/storage/XXT8KLPA/Wu et al. - CosTLO Cost-Effective Redundancy for Lower Latenc.pdf:application/pdf},
}

@inproceedings{shu_cost-effective_2021,
	address = {Virtual Event},
	title = {Cost-effective data analytics across multiple cloud regions},
	isbn = {978-1-4503-8629-6},
	url = {https://dl.acm.org/doi/10.1145/3472716.3472842},
	doi = {10.1145/3472716.3472842},
	abstract = {We propose a cloud-native data analytics engine for processing data stored among geographically distributed cloud regions with reduced cost. A job is split into subtasks and placed across regions based on factors including prices of compute resources and data transmission. We present its architecture which leverages existing cloud infrastructures and discuss major challenges of its system design. Preliminary experiments show that the cost is reduced by 15.1\% for a decision support query on a four-region public cloud setup.},
	language = {en},
	urldate = {2021-09-27},
	booktitle = {Proceedings of the {SIGCOMM} '21 {Poster} and {Demo} {Sessions}},
	publisher = {ACM},
	author = {Shu, Junyi and Jin, Xin and Ma, Yun and Liu, Xuanzhe and Huang, Gang},
	month = aug,
	year = {2021},
	pages = {1--3},
	file = {Shu et al. - 2021 - Cost-effective data analytics across multiple clou.pdf:/home/tobi/programms/Zotero/storage/WVF6V232/Shu et al. - 2021 - Cost-effective data analytics across multiple clou.pdf:application/pdf},
}

@inproceedings{bogdanov_fast_2018,
	address = {Carlsbad CA USA},
	title = {Fast and {Accurate} {Load} {Balancing} for {Geo}-{Distributed} {Storage} {Systems}},
	isbn = {978-1-4503-6011-1},
	url = {https://dl.acm.org/doi/10.1145/3267809.3267820},
	doi = {10.1145/3267809.3267820},
	abstract = {The increasing density of globally distributed datacenters reduces the network latency between neighboring datacenters and allows replicated services deployed across neighboring locations to share workload when necessary, without violating strict Service Level Objectives (SLOs).},
	language = {en},
	urldate = {2021-09-27},
	booktitle = {Proceedings of the {ACM} {Symposium} on {Cloud} {Computing}},
	publisher = {ACM},
	author = {Bogdanov, Kirill L. and Reda, Waleed and Maguire, Gerald Q. and Kostić, Dejan and Canini, Marco},
	month = oct,
	year = {2018},
	pages = {386--400},
	file = {Bogdanov et al. - 2018 - Fast and Accurate Load Balancing for Geo-Distribut.pdf:/home/tobi/programms/Zotero/storage/WAASJSYX/Bogdanov et al. - 2018 - Fast and Accurate Load Balancing for Geo-Distribut.pdf:application/pdf},
}

@article{trivedi_sharing_nodate,
	title = {Sharing and {Caring} of {Data} at the {Edge}},
	abstract = {Edge computing is an emerging computing paradigm where data is generated and processed in the ﬁeld using distributed computing devices. Many applications such as real-time video processing, augmented/virtual reality gaming, environment sensing, beneﬁt from such decentralized, close-to-user deployments where low-latency, real-time results are expected. As with any distributed application, one of the key challenges in the development of collaborative applications is how to efﬁciently share data and state among multiple edge clients. The dynamic and heterogeneous environment together with diverse application’s requirements make data sharing at the edge a challenging problem. Although there have been prior efforts, a systematic understanding of the area is missing. In this paper, we conduct a methodological study of different edge applications, their data sharing needs, and designs of state-of-the-art systems. In the process, we identify design options, under-explored opportunities, and associated challenges. We then present Grifﬁn, our edge data sharing service, and seek feedback on its design.},
	language = {en},
	author = {Trivedi, Animesh and Wang, Lin and Bal, Henri and Iosup, Alexandru},
	pages = {12},
	file = {Trivedi et al. - Sharing and Caring of Data at the Edge.pdf:/home/tobi/programms/Zotero/storage/E5K3RPJV/Trivedi et al. - Sharing and Caring of Data at the Edge.pdf:application/pdf},
}

@article{wang_using_2017,
	title = {Using {Burstable} {Instances} in the {Public} {Cloud}: {Why}, {When} and {How}?},
	volume = {1},
	issn = {2476-1249},
	shorttitle = {Using {Burstable} {Instances} in the {Public} {Cloud}},
	url = {https://dl.acm.org/doi/10.1145/3084448},
	doi = {10.1145/3084448},
	abstract = {Amazon EC2 and Google Compute Engine (GCE) have recently introduced a new class of virtual machines called "burstable" instances that are cheaper than even the smallest traditional/regular instances. These lower prices come with reduced average capacity and increased variance. Using measurements from both EC2 and GCE, we identify key idiosyncrasies of resource capacity dynamism for burstable instances that set them apart from other instance types. Most importantly, certain resources for these instances appear to be regulated by deterministic token bucket like mechanisms. We find widely different types of disclosures by providers of the parameters governing these regulation mechanisms: full disclosure (e.g., CPU capacity for EC2 t2 instances), partial disclosure (e.g., CPU capacity and remote disk IO bandwidth for GCE shared-core instances), or no disclosure (network bandwidth for EC2 t2 instances). A tenant modeling these variations as random phenomena (as some recent work suggests) might make sub-optimal procurement and operation decisions. We present modeling techniques for a tenant to infer the properties of these regulation mechanisms via simple offline measurements. We also present two case studies of how certain memcached workloads might benefit from our modeling when operating on EC2 by: (i) augmenting cheap but low availability in-memory storage offered by spot instances with backup of popular content on burstable instances, and (ii) temporal multiplexing of multiple burstable instances to achieve the CPU or network bandwidth (and thereby throughput) equivalent of a more expensive regular EC2 instance.},
	language = {en},
	number = {1},
	urldate = {2021-09-27},
	journal = {Proceedings of the ACM on Measurement and Analysis of Computing Systems},
	author = {Wang, Cheng and Urgaonkar, Bhuvan and Nasiriani, Neda and Kesidis, George},
	month = jun,
	year = {2017},
	pages = {1--28},
	file = {Wang et al. - 2017 - Using Burstable Instances in the Public Cloud Why.pdf:/home/tobi/programms/Zotero/storage/CUT2PEQJ/Wang et al. - 2017 - Using Burstable Instances in the Public Cloud Why.pdf:application/pdf},
}

@article{klimovic_pocket_nodate,
	title = {Pocket: {Elastic} {Ephemeral} {Storage} for {Serverless} {Analytics}},
	abstract = {Serverless computing is becoming increasingly popular, enabling users to quickly launch thousands of shortlived tasks in the cloud with high elasticity and ﬁnegrain billing. These properties make serverless computing appealing for interactive data analytics. However exchanging intermediate data between execution stages in an analytics job is a key challenge as direct communication between serverless tasks is difﬁcult. The natural approach is to store such ephemeral data in a remote data store. However, existing storage systems are not designed to meet the demands of serverless applications in terms of elasticity, performance, and cost. We present Pocket, an elastic, distributed data store that automatically scales to provide applications with desired performance at low cost. Pocket dynamically rightsizes resources across multiple dimensions (CPU cores, network bandwidth, storage capacity) and leverages multiple storage technologies to minimize cost while ensuring applications are not bottlenecked on I/O. We show that Pocket achieves similar performance to ElastiCache Redis for serverless analytics applications while reducing cost by almost 60\%.},
	language = {en},
	author = {Klimovic, Ana and Trivedi, Animesh and Wang, Yawen and Pfefferle, Jonas and Stuedi, Patrick and Kozyrakis, Christos},
	pages = {18},
	file = {Klimovic et al. - Pocket Elastic Ephemeral Storage for Serverless A.pdf:/home/tobi/programms/Zotero/storage/IIPKQNWL/Klimovic et al. - Pocket Elastic Ephemeral Storage for Serverless A.pdf:application/pdf},
}

@inproceedings{wang_infinicache_2020,
	title = {{InfiniCache}: {Exploiting} {Ephemeral} {Serverless} {Functions} to {Build} a {Cost}-{Effective} {Memory} {Cache}},
	isbn = {978-1-939133-12-0},
	shorttitle = {{InfiniCache}},
	url = {https://www.usenix.org/conference/fast20/presentation/wang-ao},
	language = {en},
	urldate = {2021-10-05},
	author = {Wang, Ao and Zhang, Jingyuan and Ma, Xiaolong and Anwar, Ali and Rupprecht, Lukas and Skourtis, Dimitrios and Tarasov, Vasily and Yan, Feng and Cheng, Yue},
	year = {2020},
	pages = {267--281},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/S3HNCFM6/Wang et al. - 2020 - InfiniCache Exploiting Ephemeral Serverless Funct.pdf:application/pdf;Snapshot:/home/tobi/programms/Zotero/storage/BER7MVYT/wang-ao.html:text/html},
}

@inproceedings{shahrad_serverless_2020,
	title = {Serverless in the {Wild}: {Characterizing} and {Optimizing} the {Serverless} {Workload} at a {Large} {Cloud} {Provider}},
	isbn = {978-1-939133-14-4},
	shorttitle = {Serverless in the {Wild}},
	url = {https://www.usenix.org/conference/atc20/presentation/shahrad},
	language = {en},
	urldate = {2021-10-05},
	author = {Shahrad, Mohammad and Fonseca, Rodrigo and Goiri, Inigo and Chaudhry, Gohar and Batum, Paul and Cooke, Jason and Laureano, Eduardo and Tresness, Colby and Russinovich, Mark and Bianchini, Ricardo},
	year = {2020},
	pages = {205--218},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/X82D8NQN/Shahrad et al. - 2020 - Serverless in the Wild Characterizing and Optimiz.pdf:application/pdf;Snapshot:/home/tobi/programms/Zotero/storage/6AZHMBC4/shahrad.html:text/html},
}

@inproceedings{barcelona-pons_faas_2019,
	address = {New York, NY, USA},
	series = {Middleware '19},
	title = {On the {FaaS} {Track}: {Building} {Stateful} {Distributed} {Applications} with {Serverless} {Architectures}},
	isbn = {978-1-4503-7009-7},
	shorttitle = {On the {FaaS} {Track}},
	url = {https://doi.org/10.1145/3361525.3361535},
	doi = {10.1145/3361525.3361535},
	abstract = {Serverless computing is an emerging paradigm that greatly simplifies the usage of cloud resources and suits well to many tasks. Most notably, Function-as-a-Service (FaaS) enables programmers to develop cloud applications as individual functions that can run and scale independently. Yet, due to the disaggregation of storage and compute resources in FaaS, applications that require fine-grained support for mutable state and synchronization, such as machine learning and scientific computing, are hard to build. In this work, we present Crucial, a system to program highly-concurrent stateful applications with serverless architectures. Its programming model keeps the simplicity of FaaS and allows to port effortlessly multi-threaded algorithms to this new environment. Crucial is built upon the key insight that FaaS resembles to concurrent programming at the scale of a data center. As a consequence, a distributed shared memory layer is the right answer to the need for fine-grained state management and coordination in serverless. We validate our system with the help of micro-benchmarks and various applications. In particular, we implement two common machine learning algorithms: k-means clustering and logistic regression. For both cases, Crucial obtains superior or comparable performance to an equivalent Spark cluster.},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 20th {International} {Middleware} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Barcelona-Pons, Daniel and Sánchez-Artigas, Marc and París, Gerard and Sutra, Pierre and García-López, Pedro},
	month = dec,
	year = {2019},
	keywords = {Serverless, FaaS, in-memory, stateful, synchronization},
	pages = {41--54},
}

@misc{noauthor_lambada_nodate,
	title = {Lambada: {Interactive} {Data} {Analytics} on {Cold} {Data} {Using} {Serverless} {Cloud} {Infrastructure} {\textbar} {Proceedings} of the 2020 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	url = {https://dl.acm.org/doi/10.1145/3318464.3389758},
	urldate = {2021-10-07},
	file = {Lambada\: Interactive Data Analytics on Cold Data Using Serverless Cloud Infrastructure | Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data:/home/tobi/programms/Zotero/storage/JNJIDS6W/3318464.html:text/html},
}

@misc{noauthor_cloudburst_nodate,
	title = {Cloudburst: stateful functions-as-a-service: {Proceedings} of the {VLDB} {Endowment}: {Vol} 13, {No} 12},
	url = {https://dl.acm.org/doi/10.14778/3407790.3407836},
	urldate = {2021-10-07},
}

@misc{noauthor_characterizing_nodate,
	title = {Characterizing serverless platforms with serverlessbench {\textbar} {Proceedings} of the 11th {ACM} {Symposium} on {Cloud} {Computing}},
	url = {https://dl.acm.org/doi/10.1145/3419111.3421280},
	urldate = {2021-10-07},
}

@inproceedings{fuerst_faascache_2021,
	address = {New York, NY, USA},
	series = {{ASPLOS} 2021},
	title = {{FaasCache}: keeping serverless computing alive with greedy-dual caching},
	isbn = {978-1-4503-8317-2},
	shorttitle = {{FaasCache}},
	url = {https://doi.org/10.1145/3445814.3446757},
	doi = {10.1145/3445814.3446757},
	abstract = {Functions as a Service (also called serverless computing) promises to revolutionize how applications use cloud resources. However, functions suffer from cold-start problems due to the overhead of initializing their code and data dependencies before they can start executing. Keeping functions alive and warm after they have finished execution can alleviate the cold-start overhead. Keep-alive policies must keep functions alive based on their resource and usage characteristics, which is challenging due to the diversity in FaaS workloads. Our insight is that keep-alive is analogous to caching. Our caching-inspired Greedy-Dual keep-alive policy can be effective in reducing the cold-start overhead by more than 3× compared to current approaches. Caching concepts such as reuse distances and hit-ratio curves can also be used for auto-scaled server resource provisioning, which can reduce the resource requirement of FaaS providers by 30\% for real-world dynamic workloads. We implement caching-based keep-alive and resource provisioning policies in our FaasCache system, which is based on OpenWhisk. We hope that our caching analogy opens the door to more principled and optimized keep-alive and resource provisioning techniques for future FaaS workloads and platforms.},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 26th {ACM} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Fuerst, Alexander and Sharma, Prateek},
	month = apr,
	year = {2021},
	keywords = {Caching, Cloud Computing, Functions as a Service, Serverless Computing},
	pages = {386--400},
}

@inproceedings{mvondo_ofc_2021,
	address = {New York, NY, USA},
	series = {{EuroSys} '21},
	title = {{OFC}: an opportunistic caching system for {FaaS} platforms},
	isbn = {978-1-4503-8334-9},
	shorttitle = {{OFC}},
	url = {https://doi.org/10.1145/3447786.3456239},
	doi = {10.1145/3447786.3456239},
	abstract = {Cloud applications based on the "Functions as a Service" (FaaS) paradigm have become very popular. Yet, due to their stateless nature, they must frequently interact with an external data store, which limits their performance. To mitigate this issue, we introduce OFC, a transparent, vertically and horizontally elastic in-memory caching system for FaaS platforms, distributed over the worker nodes. OFC provides these benefits cost-effectively by exploiting two common sources of resource waste: (i) most cloud tenants overprovision the memory resources reserved for their functions because their footprint is non-trivially input-dependent and (ii) FaaS providers keep function sandboxes alive for several minutes to avoid cold starts. Using machine learning models adjusted for typical function input data categories (e.g., multimedia formats), OFC estimates the actual memory resources required by each function invocation and hoards the remaining capacity to feed the cache. We build our OFC prototype based on enhancements to the OpenWhisk FaaS platform, the Swift persistent object store, and the RAM-Cloud in-memory store. Using a diverse set of workloads, we show that OFC improves by up to 82 \% and 60 \% respectively the execution time of single-stage and pipelined functions.},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {Sixteenth} {European} {Conference} on {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mvondo, Djob and Bacou, Mathieu and Nguetchouang, Kevin and Ngale, Lucien and Pouget, Stéphane and Kouam, Josiane and Lachaize, Renaud and Hwang, Jinho and Wood, Tim and Hagimont, Daniel and De Palma, Noël and Batchakui, Bernabé and Tchana, Alain},
	month = apr,
	year = {2021},
	keywords = {serverless, cache, cloud computing, functions as a service (FaaS), latency},
	pages = {228--244},
	file = {Full Text:/home/tobi/programms/Zotero/storage/36MDIA2Y/Mvondo et al. - 2021 - OFC an opportunistic caching system for FaaS plat.pdf:application/pdf},
}

@article{wawrzoniak_boxer_2021,
	title = {Boxer: {Data} {Analytics} on {Network}-enabled {Serverless} {Platforms}},
	copyright = {Creative Commons Attribution 3.0 Unported, info:eu-repo/semantics/openAccess},
	shorttitle = {Boxer},
	url = {http://hdl.handle.net/20.500.11850/456492},
	doi = {10.3929/ETHZ-B-000456492},
	abstract = {Serverless is an attractive platform for a variety of applications in the cloud due to its promise of elasticity, low cost, and fast deployment. Instead of using traditional virtual machine services and a ﬁxed infrastructure, which incurs considerable costs to operate and run, Function-as-a-Service allows triggering short computations on demand with the cost proportional to the time the functions are running. As appealing as the idea is, recent work has shown that for data processing applications (regardless of whether it is OLTP, OLAP, or ML) existing serverless platforms are inadequate and additional services are needed in practice, often to address the lack of communication capabilities between functions. In this paper, we demonstrate how to enable function-to-function communication using conventional TCP/IP and show how the ability to communicate can be used to implement data processing on serverless platforms in a more eﬃcient manner than it was possible until now. Our benchmarks show a speedup as high as 11 × in TPC-H queries over systems that use cloud storage to communicate across functions, sustained function-to-function throughput of 621 Mbit/s, and a round-trip latency of less than 1 ms.},
	language = {en},
	urldate = {2021-10-25},
	author = {Wawrzoniak, Mike and Müller, Ingo and Fraga Barcelos Paulus Bruno, Rodrigo and Alonso, Gustavo},
	year = {2021},
	note = {Medium: application/pdf,8 p. accepted version
Publisher: ETH Zurich},
	file = {Wawrzoniak et al. - 2021 - Boxer Data Analytics on Network-enabled Serverles.pdf:/home/tobi/programms/Zotero/storage/R34MUJYA/Wawrzoniak et al. - 2021 - Boxer Data Analytics on Network-enabled Serverles.pdf:application/pdf},
}

@inproceedings{pu_shuffling_2019,
	title = {Shuffling, {Fast} and {Slow}: {Scalable} {Analytics} on {Serverless} {Infrastructure}},
	isbn = {978-1-931971-49-2},
	shorttitle = {Shuffling, {Fast} and {Slow}},
	url = {https://www.usenix.org/conference/nsdi19/presentation/pu},
	language = {en},
	urldate = {2021-11-05},
	author = {Pu, Qifan and Venkataraman, Shivaram and Stoica, Ion},
	year = {2019},
	pages = {193--206},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/3SFXGDX5/Pu et al. - 2019 - Shuffling, Fast and Slow Scalable Analytics on Se.pdf:application/pdf;Snapshot:/home/tobi/programms/Zotero/storage/HRSZ49K5/pu.html:text/html},
}

@article{wu_autoscaling_2019,
	title = {Autoscaling tiered cloud storage in {Anna}},
	volume = {12},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3311880.3311881},
	doi = {10.14778/3311880.3311881},
	abstract = {In this paper, we describe how we extended a distributed key-value store called Anna into an autoscaling, multi-tier service for the cloud. In its extended form, Anna is designed to overcome the narrow cost-performance limitations typical of current cloud storage systems. We describe three key aspects of Anna’s new design: multi-master selective replication of hot keys, a vertical tiering of storage layers with diﬀerent cost-performance tradeoﬀs, and horizontal elasticity of each tier to add and remove nodes in response to load dynamics. Anna’s policy engine uses these mechanisms to balance service-level objectives around cost, latency and fault tolerance. Experimental results explore the behavior of Anna’s mechanisms and policy, exhibiting orders of magnitude eﬃciency improvements over both commodity cloud KVS services and research systems.},
	language = {en},
	number = {6},
	urldate = {2021-11-05},
	journal = {Proceedings of the VLDB Endowment},
	author = {Wu, Chenggang and Sreekanti, Vikram and Hellerstein, Joseph M.},
	month = feb,
	year = {2019},
	pages = {624--638},
	file = {Wu et al. - 2019 - Autoscaling tiered cloud storage in Anna.pdf:/home/tobi/programms/Zotero/storage/F488BY8F/Wu et al. - 2019 - Autoscaling tiered cloud storage in Anna.pdf:application/pdf},
}

@inproceedings{klimovic_pocket_2018,
	title = {Pocket: {Elastic} {Ephemeral} {Storage} for {Serverless} {Analytics}},
	isbn = {978-1-939133-08-3},
	shorttitle = {Pocket},
	url = {https://www.usenix.org/conference/osdi18/presentation/klimovic},
	language = {en},
	urldate = {2021-11-05},
	author = {Klimovic, Ana and Wang, Yawen and Stuedi, Patrick and Trivedi, Animesh and Pfefferle, Jonas and Kozyrakis, Christos},
	year = {2018},
	pages = {427--444},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/GEPKNZJI/Klimovic et al. - 2018 - Pocket Elastic Ephemeral Storage for Serverless A.pdf:application/pdf;Snapshot:/home/tobi/programms/Zotero/storage/QE2HHCB8/klimovic.html:text/html},
}

@article{chatfield_holt-winters_1978,
	title = {The {Holt}-{Winters} {Forecasting} {Procedure}},
	volume = {27},
	issn = {0035-9254},
	url = {https://www.jstor.org/stable/2347162},
	doi = {10.2307/2347162},
	abstract = {The Holt-Winters forecasting procedure is a simple widely used projection method which can cope with trend and seasonal variation. However, empirical studies have tended to show that the method is not as accurate on average as the more complicated Box-Jenkins procedure. This paper points out that these empirical studies have used the automatic version of the method, whereas a non-automatic version is also possible in which subjective judgement is employed, for example, to choose the correct model for seasonality. The paper re-analyses seven series from the Newbold-Granger study for which Box-Jenkins forecasts were reported to be much superior to the (automatic) Holt-Winters forecasts. The series do not appear to have any common properties, but it is shown that the automatic Holt-Winters forecasts can often be improved by subjective modifications. It is argued that a fairer comparison would be that between Box-Jenkins and a non-automatic version of Holt-Winters. Some general recommendations are made concerning the choice of a univariate forecasting procedure. The paper also makes suggestions regarding the implementation of the Holt-Winters procedure, including a choice of starting values.},
	number = {3},
	urldate = {2021-11-05},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Chatfield, C.},
	year = {1978},
	note = {Publisher: [Wiley, Royal Statistical Society]},
	pages = {264--279},
	file = {JSTOR Full Text PDF:/home/tobi/programms/Zotero/storage/RL89TXZY/Chatfield - 1978 - The Holt-Winters Forecasting Procedure.pdf:application/pdf},
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	note = {Conference Name: Neural Computation},
	pages = {1735--1780},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/4D3BSKBX/6795963.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/XQ6QTWPI/Hochreiter and Schmidhuber - 1997 - Long Short-Term Memory.pdf:application/pdf},
}

@inproceedings{higginson_database_2020,
	address = {Portland OR USA},
	title = {Database {Workload} {Capacity} {Planning} using {Time} {Series} {Analysis} and {Machine} {Learning}},
	isbn = {978-1-4503-6735-6},
	url = {https://dl.acm.org/doi/10.1145/3318464.3386140},
	doi = {10.1145/3318464.3386140},
	abstract = {When procuring or administering any I.T. system or a component of an I.T. system, it is crucial to understand the computational resources required to run the critical business functions that are governed by any Service Level Agreements. Predicting the resources needed for future consumption is like looking into the proverbial crystal ball. In this paper we look at the forecasting techniques in use today and evaluate if those techniques are applicable to the deeper layers of the technological stack such as clustered database instances, applications and groups of transactions that make up the database workload. The approach has been implemented to use supervised machine learning to identify traits such as reoccurring patterns, shocks and trends that the workloads exhibit and account for those traits in the forecast. An experimental evaluation shows that the approach we propose reduces the complexity of performing a forecast, and accurate predictions have been produced for complex workloads.},
	language = {en},
	urldate = {2021-11-05},
	booktitle = {Proceedings of the 2020 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Higginson, Antony S. and Dediu, Mihaela and Arsene, Octavian and Paton, Norman W. and Embury, Suzanne M.},
	month = jun,
	year = {2020},
	pages = {769--783},
	file = {Higginson et al. - 2020 - Database Workload Capacity Planning using Time Ser.pdf:/home/tobi/programms/Zotero/storage/L9L8I74S/Higginson et al. - 2020 - Database Workload Capacity Planning using Time Ser.pdf:application/pdf},
}

@inproceedings{kilcioglu_usage_2017,
	address = {Perth Australia},
	title = {Usage {Patterns} and the {Economics} of the {Public} {Cloud}},
	isbn = {978-1-4503-4913-0},
	url = {https://dl.acm.org/doi/10.1145/3038912.3052707},
	doi = {10.1145/3038912.3052707},
	abstract = {We examine the economics of demand and supply in cloud computing. The public cloud oﬀers three main beneﬁts to ﬁrms: 1) utilization can be scaled up or down easily; 2) capital expenditure (on-premises servers) can be converted to operating expenses, with the capital incurred by a specialist; 3) software can be “pay-as-you-go.” These beneﬁts increase with the ﬁrm’s ability to dynamically scale resource utilization and thus point to the need for dynamic prices to shape demand to the (short-run) ﬁxed datacenter supply. Detailed utilization analysis reveals the large swings in utilization at the hourly, daily or weekly level are very rare at the customer level and non-existent at the datacenter level. Furthermore, few customers show volatility patterns that are excessively correlated with the market. These results explain why ﬁxed prices currently prevail despite the seeming need for timevarying dynamics. Examining the actual CPU utilization provides a lens into the future. Here utilization varies by order half the datacenter capacity, but most ﬁrms are not dynamically scaling their assigned resources at-present to take advantage of these changes. If these gains are realized, demand ﬂuctuations would be on par with the three classic industries where dynamic pricing is important (hotels, electricity, airlines) and dynamic prices would be essential for eﬃciency.},
	language = {en},
	urldate = {2021-11-05},
	booktitle = {Proceedings of the 26th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Kilcioglu, Cinar and Rao, Justin M. and Kannan, Aadharsh and McAfee, R. Preston},
	month = apr,
	year = {2017},
	pages = {83--91},
	file = {Kilcioglu et al. - 2017 - Usage Patterns and the Economics of the Public Clo.pdf:/home/tobi/programms/Zotero/storage/GDQAMUM6/Kilcioglu et al. - 2017 - Usage Patterns and the Economics of the Public Clo.pdf:application/pdf},
}

@inproceedings{cortez_resource_2017,
	address = {Shanghai China},
	title = {Resource {Central}: {Understanding} and {Predicting} {Workloads} for {Improved} {Resource} {Management} in {Large} {Cloud} {Platforms}},
	isbn = {978-1-4503-5085-3},
	shorttitle = {Resource {Central}},
	url = {https://dl.acm.org/doi/10.1145/3132747.3132772},
	doi = {10.1145/3132747.3132772},
	abstract = {Cloud research to date has lacked data on the characteristics of the production virtual machine (VM) workloads of large cloud providers. A thorough understanding of these characteristics can inform the providers’ resource management systems, e.g. VM scheduler, power manager, server health manager. In this paper, we first introduce an extensive characterization of Microsoft Azure’s VM workload, including distributions of the VMs’ lifetime, deployment size, and resource consumption. We then show that certain VM behaviors are fairly consistent over multiple lifetimes, i.e. history is an accurate predictor of future behavior. Based on this observation, we next introduce Resource Central (RC), a system that collects VM telemetry, learns these behaviors offline, and provides predictions online to various resource managers via a general client-side library. As an example of RC’s online use, we modify Azure’s VM scheduler to leverage predictions in oversubscribing servers (with oversubscribable VM types), while retaining high VM performance. Using real VM traces, we then show that the prediction-informed schedules increase utilization and prevent physical resource exhaustion. We conclude that providers can exploit their workloads’ characteristics and machine learning to improve resource management substantially.},
	language = {en},
	urldate = {2021-11-05},
	booktitle = {Proceedings of the 26th {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Cortez, Eli and Bonde, Anand and Muzio, Alexandre and Russinovich, Mark and Fontoura, Marcus and Bianchini, Ricardo},
	month = oct,
	year = {2017},
	pages = {153--167},
	file = {Cortez et al. - 2017 - Resource Central Understanding and Predicting Wor.pdf:/home/tobi/programms/Zotero/storage/AEI7X92J/Cortez et al. - 2017 - Resource Central Understanding and Predicting Wor.pdf:application/pdf},
}

@inproceedings{khan_workload_2012,
	title = {Workload characterization and prediction in the cloud: {A} multiple time series approach},
	shorttitle = {Workload characterization and prediction in the cloud},
	doi = {10.1109/NOMS.2012.6212065},
	abstract = {Cloud computing promises high scalability, flexibility and cost-effectiveness to satisfy emerging computing requirements. To efficiently provision computing resources in the cloud, system administrators need the capabilities of characterizing and predicting workload on the Virtual Machines (VMs). In this paper, we use data traces obtained from a real data center to develop such capabilities. First, we search for repeatable workload patterns by exploring cross-VM workload correlations resulted from the dependencies among applications running on different VMs. Treating workload data samples as time series, we develop a co-clustering technique to identify groups of VMs that frequently exhibit correlated workload patterns, and also the time periods in which these VM groups are active. Then, we introduce a method based on Hidden Markov Modeling (HMM) to characterize the temporal correlations in the discovered VM clusters and to predict variations of workload patterns. The experimental results show that our method can not only help better understand group-level workload characteristics, but also make more accurate predictions on workload changes in a cloud.},
	booktitle = {2012 {IEEE} {Network} {Operations} and {Management} {Symposium}},
	author = {Khan, Arijit and Yan, Xifeng and Tao, Shu and Anerousis, Nikos},
	month = apr,
	year = {2012},
	note = {ISSN: 2374-9709},
	keywords = {Servers, Business, Conferences, Correlation, Hidden Markov models, Predictive models, Time series analysis},
	pages = {1287--1294},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/XPR5WP2D/6212065.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/6NFNWT8N/Khan et al. - 2012 - Workload characterization and prediction in the cl.pdf:application/pdf},
}

@article{reiss_heterogeneity_nodate,
	title = {Heterogeneity and dynamicity of clouds at scale: {Google} trace analysis},
	abstract = {To better understand the challenges in developing effective cloudbased resource schedulers, we analyze the ﬁrst publicly available trace data from a sizable multi-purpose cluster. The most notable workload characteristic is heterogeneity: in resource types (e.g., cores:RAM per machine) and their usage (e.g., duration and resources needed). Such heterogeneity reduces the effectiveness of traditional slot- and core-based scheduling. Furthermore, some tasks are constrained as to the kind of machine types they can use, increasing the complexity of resource assignment and complicating task migration. The workload is also highly dynamic, varying over time and most workload features, and is driven by many short jobs that demand quick scheduling decisions. While few simplifying assumptions apply, we ﬁnd that many longer-running jobs have relatively stable resource utilizations, which can help adaptive resource schedulers.},
	language = {en},
	author = {Reiss, Charles and Tumanov, Alexey and Ganger, Gregory R and Katz, Randy H and Kozuch, Michael A},
	pages = {13},
	file = {Reiss et al. - Heterogeneity and dynamicity of clouds at scale G.pdf:/home/tobi/programms/Zotero/storage/X9ULENA4/Reiss et al. - Heterogeneity and dynamicity of clouds at scale G.pdf:application/pdf},
}

@inproceedings{poggi_characterization_2010,
	title = {Characterization of workload and resource consumption for an online travel and booking site},
	doi = {10.1109/IISWC.2010.5649408},
	abstract = {Online travel and ticket booking is one of the top E-Commerce industries. As they present a mix of products: flights, hotels, tickets, restaurants, activities and vacational packages, they rely on a wide range of technologies to support them: Javascript, AJAX, XML, B2B Web services, Caching, Search Algorithms and Affiliation; resulting in a very rich and heterogeneous workload. Moreover, visits to travel sites present a great variability depending on time of the day, season, promotions, events, and linking; creating bursty traffic, making capacity planning a challenge. It is therefore of great importance to understand how users and crawlers interact on travel sites and their effect on server resources, for devising cost effective infrastructures and improving the Quality of Service for users. In this paper we present a detailed workload and resource consumption characterization of the web site of a top national Online Travel Agency. Characterization is performed on server logs, including both HTTP data and resource consumption of the requests, as well as the server load status during the execution. From the dataset we characterize user sessions, their patterns and how response time is affected as load on Web servers increases. We provide a fine grain analysis by performing experiments differentiating: types of request, time of the day, products, and resource requirements for each. Results show that the workload is bursty, as expected, that exhibit different properties between day and night traffic in terms of request type mix, that user session length cover a wide range of durations, which response time grows proportionally to server load, and that response time of external data providers also increase on peak hours, amongst other results. Such results can be useful for optimizing infrastructure costs, improving QoS for users, and development of realistic workload generators for similar applications.},
	booktitle = {{IEEE} {International} {Symposium} on {Workload} {Characterization} ({IISWC}'10)},
	author = {Poggi, Nicolas and Carrera, David and Gavaldà, Ricard and Torres, Jordi and Ayguadé, Eduard},
	month = dec,
	year = {2010},
	keywords = {Databases, Browsers, Crawlers, Time factors, Web server},
	pages = {1--10},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/DRYPU7R4/5649408.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/GFKN2M36/Poggi et al. - 2010 - Characterization of workload and resource consumpt.pdf:application/pdf},
}

@inproceedings{bodik_characterizing_2010,
	address = {Indianapolis, Indiana, USA},
	title = {Characterizing, modeling, and generating workload spikes for stateful services},
	isbn = {978-1-4503-0036-0},
	url = {http://portal.acm.org/citation.cfm?doid=1807128.1807166},
	doi = {10.1145/1807128.1807166},
	abstract = {Evaluating the resiliency of stateful Internet services to signiﬁcant workload spikes and data hotspots requires realistic workload traces that are usually very diﬃcult to obtain. A popular approach is to create a workload model and generate synthetic workload, however, there exists no characterization and model of stateful spikes. In this paper we analyze ﬁve workload and data spikes and ﬁnd that they vary signiﬁcantly in many important aspects such as steepness, magnitude, duration, and spatial locality. We propose and validate a model of stateful spikes that allows us to synthesize volume and data spikes and could thus be used by both cloud computing users and providers to stress-test their infrastructure.},
	language = {en},
	urldate = {2021-11-05},
	booktitle = {Proceedings of the 1st {ACM} symposium on {Cloud} computing - {SoCC} '10},
	publisher = {ACM Press},
	author = {Bodik, Peter and Fox, Armando and Franklin, Michael J. and Jordan, Michael I. and Patterson, David A.},
	year = {2010},
	pages = {241},
	file = {Bodik et al. - 2010 - Characterizing, modeling, and generating workload .pdf:/home/tobi/programms/Zotero/storage/LQBM9SNG/Bodik et al. - 2010 - Characterizing, modeling, and generating workload .pdf:application/pdf},
}

@inproceedings{narayanan_deepcache_2018,
	address = {Budapest, Hungary},
	title = {{DeepCache}: {A} {Deep} {Learning} {Based} {Framework} {For} {Content} {Caching}},
	isbn = {978-1-4503-5911-5},
	shorttitle = {{DeepCache}},
	url = {http://dl.acm.org/citation.cfm?doid=3229543.3229555},
	doi = {10.1145/3229543.3229555},
	abstract = {In this paper, we present D���C���� a novel Framework for content caching, which can signi�cantly boost cache performance. Our Framework is based on powerful deep recurrent neural network models. It comprises of two main components: i) Object Characteristics Predictor, which builds upon deep LSTM Encoder-Decoder model to predict the future characteristics of an object (such as object popularity) – to the best of our knowledge, we are the �rst to propose LSTM Encoder-Decoder model for content caching; ii) a caching policy component, which accounts for predicted information of objects to make smart caching decisions. In our thorough experiments, we show that applying D���C���� Framework to existing cache policies, such as LRU and k-LRU, signi�cantly boosts the number of cache hits.},
	language = {en},
	urldate = {2021-11-07},
	booktitle = {Proceedings of the 2018 {Workshop} on {Network} {Meets} {AI} \& {ML}  - {NetAI}'18},
	publisher = {ACM Press},
	author = {Narayanan, Arvind and Verma, Saurabh and Ramadan, Eman and Babaie, Pariya and Zhang, Zhi-Li},
	year = {2018},
	pages = {48--53},
	file = {Narayanan et al. - 2018 - DeepCache A Deep Learning Based Framework For Con.pdf:/home/tobi/programms/Zotero/storage/B6EAQ55N/Narayanan et al. - 2018 - DeepCache A Deep Learning Based Framework For Con.pdf:application/pdf},
}

@inproceedings{shi_applying_2019,
	address = {Columbus OH USA},
	title = {Applying {Deep} {Learning} to the {Cache} {Replacement} {Problem}},
	isbn = {978-1-4503-6938-1},
	url = {https://dl.acm.org/doi/10.1145/3352460.3358319},
	doi = {10.1145/3352460.3358319},
	abstract = {Despite its success in many areas, deep learning is a poor fit for use in hardware predictors because these models are impractically large and slow, but this paper shows how we can use deep learning to help design a new cache replacement policy. We first show that for cache replacement, a powerful LSTM learning model can in an offline setting provide better accuracy than current hardware predictors. We then perform analysis to interpret this LSTM model, deriving a key insight that allows us to design a simple online model that matches the offline model’s accuracy with orders of magnitude lower cost.},
	language = {en},
	urldate = {2021-11-07},
	booktitle = {Proceedings of the 52nd {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	publisher = {ACM},
	author = {Shi, Zhan and Huang, Xiangru and Jain, Akanksha and Lin, Calvin},
	month = oct,
	year = {2019},
	pages = {413--425},
	file = {Shi et al. - 2019 - Applying Deep Learning to the Cache Replacement Pr.pdf:/home/tobi/programms/Zotero/storage/KXSQ6GT3/Shi et al. - 2019 - Applying Deep Learning to the Cache Replacement Pr.pdf:application/pdf},
}

@article{braga_data-driven_2021,
	title = {Data-{Driven} {Characterization} and {Modeling} of {Web} {Map} {System} {Workload}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3058622},
	abstract = {Every month, billions of users access Web Map Systems (WMSs), such as Google Maps, to visualize geospatial data. A large number of users and the huge amount of data demanded by these applications make the design and development of WMSs a challenging task, especially in terms of performance and scalability. In this context, workload generators become crucial tools, as they help system administrators to plan the capacity of WMSs and design provisioning strategies for peak load scenarios. However, little is known about the workload patterns generated by WMS users. In this work, we use data anonymously collected from sessions of a client application of Google Maps to devise a model that describes how users of desktop terminals navigate in a Web map. Based on this model, we implement a workload generator called MUSeGen. We compare the workload patterns generated by MUSeGen against the workload patterns found in real data. Results show that MUSeGen generates synthetic traces whose navigation patterns closely match those found in real data. We also compare MUSeGen against HELP, a workload generator built upon previous findings on empirical knowledge on the usage of WMSs. Results show that the number of issued operations per session in HELP is, on average, four times lower than that in MUSeGen and the number of tiles requested is, on average, twice lower than that in our tool. In addition, navigation patterns in HELP are much simpler than in MUSeGen. These findings support the conclusion that MUSeGen produces more realistic workloads than HELP. To illustrate how such differences affect performance evaluation in practice, we carry out a performance evaluation of a real WMS under workloads generated by HELP and MUSeGen. Our evaluation shows that the system capacity under HELP is three times less than that obtained under MUSeGen, highlighting the value of MUSeGen.},
	journal = {IEEE Access},
	author = {Braga, Vinícius Gonçalves and Correa, Sand Luz and Cardoso, Kleber Vieira and Viana, Aline Carneiro},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {Browsers, Servers, Generators, Internet, Navigation, performance evaluation, Performance evaluation, tile-based systems, Tools, Web map user, workload generation, workload model},
	pages = {26983--27002},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/F6J3HQTI/9351933.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/FGWY3E9C/Braga et al. - 2021 - Data-Driven Characterization and Modeling of Web M.pdf:application/pdf},
}

@inproceedings{sabnis_tragen_2021,
	address = {Virtual Event},
	title = {{TRAGEN}: a synthetic trace generator for realistic cache simulations},
	isbn = {978-1-4503-9129-0},
	shorttitle = {{TRAGEN}},
	url = {https://dl.acm.org/doi/10.1145/3487552.3487845},
	doi = {10.1145/3487552.3487845},
	abstract = {Traces from production caching systems of users accessing content are seldom made available to the public as they are considered private and proprietary. The dearth of realistic trace data makes it difficult for system designers and researchers to test and validate new caching algorithms and architectures. To address this key problem, we present TRAGEN, a tool that can generate a synthetic trace that is “similar” to an original trace from the production system in the sense that the two traces would result in similar hit rates in a cache simulation. We validate TRAGEN by first proving that the synthetic trace is similar to the original trace for caches of arbitrary size when the Least-Recently-Used (LRU) policy is used. Next, we empirically validate the similarity of the synthetic trace and original trace for caches that use a broad set of commonly-used caching policies that include LRU, SLRU, FIFO, RANDOM, MARKERS, CLOCK and PLRU. For our empirical validation, we use original request traces drawn from four different traffic classes from the world’s largest CDN, each trace consisting of hundreds of millions of requests for tens of millions of objects. TRAGEN is publicly available and can be used to generate synthetic traces that are similar to actual production traces for a number of traffic classes such as videos, social media, web, and software downloads. Since the synthetic traces are similar to the original production ones, cache simulations performed using the synthetic traces will yield similar results to what might be attained in a production setting, making TRAGEN a key tool for cache system developers and researchers.},
	language = {en},
	urldate = {2021-11-11},
	booktitle = {Proceedings of the 21st {ACM} {Internet} {Measurement} {Conference}},
	publisher = {ACM},
	author = {Sabnis, Anirudh and Sitaraman, Ramesh K.},
	month = nov,
	year = {2021},
	pages = {366--379},
	file = {Sabnis and Sitaraman - 2021 - TRAGEN a synthetic trace generator for realistic .pdf:/home/tobi/programms/Zotero/storage/TYG76M3B/Sabnis and Sitaraman - 2021 - TRAGEN a synthetic trace generator for realistic .pdf:application/pdf},
}

@incollection{gaston_towards_2019,
	address = {Cham},
	title = {Towards an {Efficient} {Performance} {Testing} {Through} {Dynamic} {Workload} {Adaptation}},
	volume = {11812},
	isbn = {978-3-030-31279-4 978-3-030-31280-0},
	url = {http://link.springer.com/10.1007/978-3-030-31280-0_13},
	abstract = {Performance testing is a critical task to ensure an acceptable user experience with software systems, especially when there are high numbers of concurrent users. Selecting an appropriate test workload is a challenging and time-consuming process that relies heavily on the testers’ expertise. Not only are workloads application-dependent, but also it is usually unclear how large a workload must be to expose any performance issues that exist in an application. Previous research has proposed to dynamically adapt the test workloads in real-time based on the application behavior. By reducing the need for the trial-and-error test cycles required when using static workloads, dynamic workload adaptation can reduce the eﬀort and expertise needed to carry out performance testing. However, such approaches usually require testers to properly conﬁgure several parameters in order to be eﬀective in identifying workloaddependent performance bugs, which may hinder their usability among practitioners. To address this issue, this paper examines the diﬀerent criteria needed to conduct performance testing eﬃciently using dynamic workload adaptation. We present the results of comprehensively evaluating one such approach, providing insights into how to tune it properly in order to obtain better outcomes based on diﬀerent scenarios. We also study the eﬀects of varying its conﬁguration and how this can aﬀect the results obtained.},
	language = {en},
	urldate = {2021-11-11},
	booktitle = {Testing {Software} and {Systems}},
	publisher = {Springer International Publishing},
	author = {Huerta-Guevara, Osvaldo and Ayala-Rivera, Vanessa and Murphy, Liam and Portillo-Dominguez, A. Omar},
	editor = {Gaston, Christophe and Kosmatov, Nikolai and Le Gall, Pascale},
	year = {2019},
	doi = {10.1007/978-3-030-31280-0_13},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {215--233},
	file = {Huerta-Guevara et al. - 2019 - Towards an Efficient Performance Testing Through D.pdf:/home/tobi/programms/Zotero/storage/33H3YJGC/Huerta-Guevara et al. - 2019 - Towards an Efficient Performance Testing Through D.pdf:application/pdf},
}

@article{huang_adaptive_2019,
	title = {Adaptive resource prefetching with spatial–temporal and topic information for educational cloud storage systems},
	volume = {181},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705119302540},
	doi = {10.1016/j.knosys.2019.05.034},
	abstract = {Prefetching proactively resources at datanodes within distribution networks plays a key role in improving the efficiency of data access for e-learning, which requires assistance from semantic knowledge on educational applications and resource popularity. To capture such information, we should exploit the characteristics of education end-users’ requests with high spatial–temporal locality. This paper aims to develop resource popularity modeling techniques for enhancing the performance of educational resource prefetching. Specifically, a novel topic model, built on an accelerated spectral clustering and an ontology concept similarity, is proposed to support resource access based on semantic features, including topic relevance and spatial–temporal locality. Using the proposed model, an adaptive prefetching inference approach is presented to associate possible popular resources in the future data requests. Also, an efficient prefetching management mechanism incorporating with replica techniques is suggested to design resource cloud storage systems for geo-distributed educational applications. Experiments over a simulation setting and a real-world case study with seven million users across China are carried out. Results demonstrate that the proposed method performs favorably compared to the state-of-the-art approaches.},
	language = {en},
	urldate = {2021-11-11},
	journal = {Knowledge-Based Systems},
	author = {Huang, Qionghao and Huang, Changqin and Huang, Jin and Fujita, Hamido},
	month = oct,
	year = {2019},
	pages = {104791},
	file = {Huang et al. - 2019 - Adaptive resource prefetching with spatial–tempora.pdf:/home/tobi/programms/Zotero/storage/4BM9BUIY/Huang et al. - 2019 - Adaptive resource prefetching with spatial–tempora.pdf:application/pdf},
}

@inproceedings{jha_smartdbo_2019,
	address = {San Francisco CA USA},
	title = {{SmartDBO}: {Smart} {Docker} {Benchmarking} {Orchestrator} for {Web}-application},
	isbn = {978-1-4503-6674-8},
	shorttitle = {{SmartDBO}},
	url = {https://dl.acm.org/doi/10.1145/3308558.3314137},
	doi = {10.1145/3308558.3314137},
	abstract = {Containerized web-applications have gained popularity recently due to the advantages provided by the containers including lightweight, packaged, fast start up and shut down and easy scalability. As there are more than 267 cloud providers, finding a flexible deployment option for containerized web-applications is very difficult as each cloud offers numerous deployment infrastructure. Benchmarking is one of the eminent options to evaluate the provisioned resources before product-level deployment. However, benchmarking the massive infrastructure resources provisioned by various cloud providers is a time consuming, tedious and costly process and is not practical to accomplish manually.},
	language = {en},
	urldate = {2021-11-11},
	booktitle = {The {World} {Wide} {Web} {Conference}},
	publisher = {ACM},
	author = {Jha, Devki Nandan and Nee, Michael and Wen, Zhenyu and Zomaya, Albert and Ranjan, Rajiv},
	month = may,
	year = {2019},
	pages = {3555--3559},
	file = {Jha et al. - 2019 - SmartDBO Smart Docker Benchmarking Orchestrator f.pdf:/home/tobi/programms/Zotero/storage/BG6EPYY9/Jha et al. - 2019 - SmartDBO Smart Docker Benchmarking Orchestrator f.pdf:application/pdf},
}

@inproceedings{song_comparison_2019,
	title = {Comparison of {Mobile} and {Fixed} {Device} {Workloads} in an {Academic} {Web} {Server}},
	doi = {10.1109/IWMN.2019.8804983},
	abstract = {Data traffic volume from mobile devices has surpassed traditional desktops in recent years. A mobile versus fixed web workload characterization is much needed because the potentially different traffic patterns on mobile devices poses a new challenge that may have rendered past studies obsolete. In this paper, we present a longitudinal, comparative analysis on the mobile and fixed workloads of a large academic web server. With almost 9 billion requests in total, this is, to the best of our knowledge, the largest workload characterization study from a mobile versus fixed viewpoint. We find the diurnal traffic pattern to be weaker on mobile devices and the inter-reference, inter-session duration to be longer for mobile requests. Some comparable results were present across the device types but in most cases, workload characteristics differed between mobile and fixed device requests. Taking into account this mobile-fixed disparity is crucial to optimizing web server performance in the future as mobile traffic grows.},
	booktitle = {2019 {IEEE} {International} {Symposium} on {Measurements} {Networking} ({M} {N})},
	author = {Song, Yo-Der and Mahanti, Aniket},
	month = jul,
	year = {2019},
	note = {ISSN: 2639-5061},
	keywords = {Web servers, Crawlers, Performance evaluation, Mobile handsets, Web sites},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/R3TLMJ2I/8804983.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/8ZIM9RNW/Song and Mahanti - 2019 - Comparison of Mobile and Fixed Device Workloads in.pdf:application/pdf},
}

@article{curiel_workload_2018,
	title = {Workload {Generators} for {Web}-{Based} {Systems}: {Characteristics}, {Current} {Status}, and {Challenges}},
	volume = {20},
	issn = {1553-877X},
	shorttitle = {Workload {Generators} for {Web}-{Based} {Systems}},
	doi = {10.1109/COMST.2018.2798641},
	abstract = {The growth and evolution of the World Wide Web (WWW) has been rapid over the last ten years and this has been caused mainly by factors such as the social Web and mobile technology. This growth, which presupposes the satisfaction of millions of users accessing Web applications with an adequate quality of service, requires continuous changes in the infrastructure to improve user experience or to handle new demands. Therefore, studies of Web-based systems aimed at comparing different hardware infrastructures, detecting system bottlenecks, provisioning hardware resources, making capacity planning tests, or software testability, are a matter of huge interest. However, the new trends in the WWW have brought new types of user demands and interactions that produce complex workload patterns. These patterns must be exhaustively studied and considered when designing helpful workload generators able to produce representative traces of the current reality. This survey is aimed at providing a useful guide for researchers of the Web, social networking, and other Internet related issues, regarding the main points and concerns about workload generation for Web-based systems. This paper reviews the predominant characteristics and attributes that define Web workloads, including the special cases of other types of Web applications (e.g., blogs, online social network platforms, and video-sharing services). It also identifies the main challenges for the next generation of Web workload generators, and explores current approaches and solutions suggested in recent works.},
	number = {2},
	journal = {IEEE Communications Surveys Tutorials},
	author = {Curiel, Mariela and Pont, Ana},
	year = {2018},
	note = {Conference Name: IEEE Communications Surveys Tutorials},
	keywords = {Web servers, Generators, performance evaluation, Analytical models, online social networks, Social network services, trace generation, Tutorials, Web, Web pages, Workload generators, workload models},
	pages = {1526--1546},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/QMQW7YD8/8270366.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/9DPHIPHL/Curiel and Pont - 2018 - Workload Generators for Web-Based Systems Charact.pdf:application/pdf},
}

@article{brady_how_2016,
	title = {How to {Emulate} {Web} {Traffic} {Using} {Standard} {Load} {Testing} {Tools}},
	url = {http://arxiv.org/abs/1607.05356},
	abstract = {Conventional load-testing tools are based on a fifty-year old time-share computer paradigm where a finite number of users submit requests and respond in a synchronized fashion. Conversely, modern web traffic is essentially asynchronous and driven by an unknown number of users. This difference presents a conundrum for testing the performance of modern web applications. Even when the difference is recognized, performance engineers often introduce modifications to their test scripts based on folklore or hearsay published in various Internet fora, much of which can lead to wrong results. We present a coherent methodology, based on two fundamental principles, for emulating web traffic using a standard load-test environment.},
	urldate = {2021-11-11},
	journal = {arXiv:1607.05356 [cs]},
	author = {Brady, James F. and Gunther, Neil J.},
	month = sep,
	year = {2016},
	note = {arXiv: 1607.05356},
	keywords = {Computer Science - Networking and Internet Architecture, C.4, Computer Science - Performance, D.2, D.4.8},
	file = {arXiv.org Snapshot:/home/tobi/programms/Zotero/storage/MCANWFYQ/1607.html:text/html;arXiv Fulltext PDF:/home/tobi/programms/Zotero/storage/TBVPZJQB/Brady and Gunther - 2016 - How to Emulate Web Traffic Using Standard Load Tes.pdf:application/pdf},
}

@article{demaine_cache-oblivious_nodate,
	title = {Cache-{Oblivious} {Algorithms} and {Data} {Structures}},
	abstract = {A recent direction in the design of cache-eﬃcient and diskeﬃcient algorithms and data structures is the notion of cache obliviousness, introduced by Frigo, Leiserson, Prokop, and Ramachandran in 1999. Cache-oblivious algorithms perform well on a multilevel memory hierarchy without knowing any parameters of the hierarchy, only knowing the existence of a hierarchy. Equivalently, a single cache-oblivious algorithm is eﬃcient on all memory hierarchies simultaneously. While such results might seem impossible, a recent body of work has developed cache-oblivious algorithms and data structures that perform as well or nearly as well as standard external-memory structures which require knowledge of the cache/memory size and block transfer size. Here we describe several of these results with the intent of elucidating the techniques behind their design. Perhaps the most exciting of these results are the data structures, which form general building blocks immediately leading to several algorithmic results.},
	language = {en},
	author = {Demaine, Erik D},
	pages = {29},
	file = {Demaine - Cache-Oblivious Algorithms and Data Structures.pdf:/home/tobi/programms/Zotero/storage/XLJ58XX5/Demaine - Cache-Oblivious Algorithms and Data Structures.pdf:application/pdf},
}

@misc{noauthor_web_nodate,
	title = {Web {Server} {Access} {Logs}},
	url = {https://kaggle.com/eliasdabbas/web-server-access-logs},
	abstract = {A sample of web server logs file},
	language = {en},
	urldate = {2021-11-10},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/22VG64N6/web-server-access-logs.html:text/html},
}

@techreport{singh_prefetching_2021,
	title = {Prefetching of {Web} {Objects} {For} {Effective} {Retrieval} {Process} {Through} {Data} {Mining} {Techniques}},
	url = {https://www.researchsquare.com/article/rs-266666/v1},
	abstract = {With the exponential increase of the internet’s user base, performance enhancing network architectures and algorithms has manifested themselves as a requisite. Algorithms for Prefetching and Caching of Web Objects have been observed to effectively minimize user perceived latency. These algorithms are made use of in architectures limited to a particular user. We can further improve the performance of these algorithms by making use of techniques like data mining. We propose an innovative idea of implementing Prefetching and Caching algorithms in a Clustered Network. This will enable all users in a particular cluster to make use of pre-fetched and cached web objects from all other users. The result of simulations indicates a reduction in web latency, internet traffic, and bandwidth consumed.},
	urldate = {2021-11-10},
	author = {Singh, T. S. Bhagavath and Chitra, S.},
	month = nov,
	year = {2021},
	doi = {10.21203/rs.3.rs-266666/v1},
	note = {ISSN: 2693-5015
Type: article},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/5PRXVQST/Singh and Chitra - 2021 - Prefetching of Web Objects For Effective Retrieval.pdf:application/pdf},
}

@techreport{singh_prefetching_2021-1,
	title = {Prefetching of {Web} {Objects} {For} {Effective} {Retrieval} {Process} {Through} {Data} {Mining} {Techniques}},
	url = {https://www.researchsquare.com/article/rs-266666/v1},
	abstract = {With the exponential increase of the internet’s user base, performance enhancing network architectures and algorithms has manifested themselves as a requisite. Algorithms for Prefetching and Caching of Web Objects have been observed to effectively minimize user perceived latency. These algorithms are made use of in architectures limited to a particular user. We can further improve the performance of these algorithms by making use of techniques like data mining. We propose an innovative idea of implementing Prefetching and Caching algorithms in a Clustered Network. This will enable all users in a particular cluster to make use of pre-fetched and cached web objects from all other users. The result of simulations indicates a reduction in web latency, internet traffic, and bandwidth consumed.},
	urldate = {2021-11-10},
	author = {Singh, T. S. Bhagavath and Chitra, S.},
	month = nov,
	year = {2021},
	doi = {10.21203/rs.3.rs-266666/v1},
	note = {ISSN: 2693-5015
Type: article},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/HL2Q9RGH/Singh and Chitra - 2021 - Prefetching of Web Objects For Effective Retrieval.pdf:application/pdf},
}

@inproceedings{yao_popularity_2019,
	title = {Popularity {Prediction} {Caching} {Using} {Hidden} {Markov} {Model} for {Vehicular} {Content} {Centric} {Networks}},
	doi = {10.1109/MDM.2019.00115},
	abstract = {Vehicular Content Centric Network (VCCN) is proposed to cope with mobility and intermittent connectivity issues of vehicular ad hoc networks by enabling the Content Centric Network (CCN) model in vehicular networks. The ubiquitous in-network caching of VCCN allows nodes to cache contents frequently accessed data items, improving the hit ratio of content retrieval and reducing the data access delay. Furthermore, it can significantly mitigate bandwidth pressure. Therefore, it is crucial to cache more popular contents at various caching nodes. In this paper, we propose a novel cache replacement scheme named Popularity-based Content Caching (PopCC), which incorporates the future popularity of contents into our decision making. We adopt Hidden Markov Model (HMM) to predict the content popularity based on the inherent characters of the received interests, request ratio, request frequency and content priority. To evaluate the performance of our proposed scheme PopCC, we compare it with some state-of-the-art schemes in terms of cache hit, average access delay, average hop count and average storage usage. Simulations demonstrate that the proposed scheme possesses a better performance.},
	booktitle = {2019 20th {IEEE} {International} {Conference} on {Mobile} {Data} {Management} ({MDM})},
	author = {Yao, Lin and Wang, Yuqi and Xia, Qiufen and Xu, Rui},
	month = jun,
	year = {2019},
	note = {ISSN: 2375-0324},
	keywords = {Bandwidth, Hidden Markov models, Delays, Hidden Markov Mode, Popularity Prediction, Time-frequency analysis, Training, VCCN, Vehicular ad hoc networks},
	pages = {533--538},
	file = {IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/4KXPT84R/Yao et al. - 2019 - Popularity Prediction Caching Using Hidden Markov .pdf:application/pdf},
}

@article{zaker_online_2021,
	title = {Online {Shopping} {Store} - {Web} {Server} {Logs}},
	url = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/3QBYB5},
	doi = {10.7910/DVN/3QBYB5},
	abstract = {Nginx server access log for an online shopping store},
	language = {en},
	urldate = {2021-11-10},
	author = {Zaker, Farzin},
	month = may,
	year = {2021},
	note = {Publisher: Harvard Dataverse
Type: dataset},
}

@article{chodak_http-level_2020,
	title = {{HTTP}-level e-commerce data based on server access logs for an online store},
	volume = {183},
	issn = {1389-1286},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128620312263},
	doi = {10.1016/j.comnet.2020.107589},
	abstract = {Web server logs have been extensively used as a source of data on the characteristics of Web traffic and users’ navigational patterns. In particular, Web bot detection and online purchase prediction using methods from artificial intelligence (AI) are currently key areas of research. However, in reality, it is hard to obtain logs from actual online stores and there is no common dataset that can be used across different studies. Moreover, there is a lack of studies exploring Web traffic over a longer period of time, due to the unavailability of long-term data from server logs. The need to develop reliable models of Web traffic, Web user navigation, and e-customer behaviour calls for an up-to-date, large-volume e-commerce dataset on Web traffic. Similarly, AI problems require a sufficient amount of solid, real-life data to train and validate new models and methods. Thus, to meet a demand of a publicly available long-term e-commerce dataset, we collected access log data describing the operation of an online store over a six-month period. Using a program written in the C\# language, data were aggregated, transformed, and anonymized. As a result, we release this EClog dataset in CSV format, which covers 183 days of HTTP-level e-commerce traffic. The data will be beneficial for research in many areas, including computer science, data science, management, and sociology.},
	language = {en},
	urldate = {2021-11-10},
	journal = {Computer Networks},
	author = {Chodak, Grzegorz and Suchacka, Grażyna and Chawla, Yash},
	month = dec,
	year = {2020},
	keywords = {Web server, Access log, Electronic commerce, HTTP traffic, Online store, Web traffic},
	pages = {107589},
	file = {ScienceDirect Full Text PDF:/home/tobi/programms/Zotero/storage/BZHH9J6R/Chodak et al. - 2020 - HTTP-level e-commerce data based on server access .pdf:application/pdf},
}

@article{sadeghi_deep_2019,
	title = {Deep {Reinforcement} {Learning} for {Adaptive} {Caching} in {Hierarchical} {Content} {Delivery} {Networks}},
	volume = {5},
	issn = {2332-7731},
	doi = {10.1109/TCCN.2019.2936193},
	abstract = {Caching is envisioned to play a critical role in next-generation content delivery infrastructure, cellular networks, and Internet architectures. By smartly storing the most popular contents at the storage-enabled network entities during off-peak demand instances, caching can benefit both network infrastructure as well as end users, during on-peak periods. In this context, distributing the limited storage capacity across network entities calls for decentralized caching schemes. Many practical caching systems involve a parent caching node connected to multiple leaf nodes to serve user file requests. To model the two-way interactive influence between caching decisions at the parent and leaf nodes, a reinforcement learning (RL) framework is put forth. To handle the large continuous state space, a scalable deep RL approach is pursued. The novel approach relies on a hyper-deep Q-network to learn the Q-function, and thus the optimal caching policy, in an online fashion. Reinforcing the parent node with ability to learn-and-adapt to unknown policies of leaf nodes as well as spatio-temporal dynamic evolution of file requests, results in remarkable caching performance, as corroborated through numerical tests.},
	number = {4},
	journal = {IEEE Transactions on Cognitive Communications and Networking},
	author = {Sadeghi, Alireza and Wang, Gang and Giannakis, Georgios B.},
	month = dec,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Cognitive Communications and Networking},
	keywords = {Caching, Cellular networks, Content distribution networks, deep Q-network, deep RL, function approximation, Markov processes, Network topology, Next generation networking, next-generation networks, Reinforcement learning, Vehicle dynamics},
	pages = {1024--1033},
	file = {IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/B67M9IKF/Sadeghi et al. - 2019 - Deep Reinforcement Learning for Adaptive Caching i.pdf:application/pdf},
}

@article{sadeghi_optimal_2018,
	title = {Optimal and {Scalable} {Caching} for {5G} {Using} {Reinforcement} {Learning} of {Space}-time {Popularities}},
	volume = {12},
	issn = {1932-4553, 1941-0484},
	url = {http://arxiv.org/abs/1708.06698},
	doi = {10.1109/JSTSP.2017.2787979},
	abstract = {Small basestations (SBs) equipped with caching units have potential to handle the unprecedented demand growth in heterogeneous networks. Through low-rate, backhaul connections with the backbone, SBs can prefetch popular files during off-peak traffic hours, and service them to the edge at peak periods. To intelligently prefetch, each SB must learn what and when to cache, while taking into account SB memory limitations, the massive number of available contents, the unknown popularity profiles, as well as the space-time popularity dynamics of user file requests. In this work, local and global Markov processes model user requests, and a reinforcement learning (RL) framework is put forth for finding the optimal caching policy when the transition probabilities involved are unknown. Joint consideration of global and local popularity demands along with cache-refreshing costs allow for a simple, yet practical asynchronous caching approach. The novel RL-based caching relies on a Q-learning algorithm to implement the optimal policy in an online fashion, thus enabling the cache control unit at the SB to learn, track, and possibly adapt to the underlying dynamics. To endow the algorithm with scalability, a linear function approximation of the proposed Q-learning scheme is introduced, offering faster convergence as well as reduced complexity and memory requirements. Numerical tests corroborate the merits of the proposed approach in various realistic settings.},
	number = {1},
	urldate = {2021-11-09},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Sadeghi, Alireza and Sheikholeslami, Fatemeh and Giannakis, Georgios B.},
	month = feb,
	year = {2018},
	note = {arXiv: 1708.06698},
	keywords = {Computer Science - Networking and Internet Architecture},
	pages = {180--190},
	file = {arXiv.org Snapshot:/home/tobi/programms/Zotero/storage/A4MKQMAZ/1708.html:text/html;arXiv Fulltext PDF:/home/tobi/programms/Zotero/storage/U7UBZWVV/Sadeghi et al. - 2018 - Optimal and Scalable Caching for 5G Using Reinforc.pdf:application/pdf},
}

@article{zhang_autosight_2020,
	title = {{AutoSight}: {Distributed} {Edge} {Caching} in {Short} {Video} {Network}},
	volume = {34},
	issn = {1558-156X},
	shorttitle = {{AutoSight}},
	doi = {10.1109/MNET.001.1900345},
	abstract = {In recent years there has been a rapid increase of short video traffic in CDN. While the video contributors change from large video studios to distributed ordinary end users, edge computing naturally matches the cache requirements from short video network. But distributed edge caching exposes some unique characteristics: non-stationary user access pattern and temporal and spatial video popularity pattern, which severely challenge the edge caching performance. While the QoE in traditional CDN has been much improved, prior solutions become invalid in solving the above challenges. In this article, we present AutoSight, a distributed edge caching system for short video network, which significantly boosts cache performance. AutoSight consists of two main components, solving the above two challenges respectively: the CoStore predictor, which solves the non-stationary and unpredictability of local access pattern, by analyzing the complex video correlations; and a caching engine Viewfinder, which solves the temporal and spatial video popularity problem by automatically adjusting future horizon according to video life span. All these inspirations and experiments are based on the real traces of more than 28 million videos with 100 million accesses from 488 servers located in 33 cities. Experiment results show that AutoSight brings significant boosts on distributed edge caching in short video network.},
	number = {3},
	journal = {IEEE Network},
	author = {Zhang, Yuchao and Li, Pengmiao and Zhang, Zhili and Bai, Bo and Zhang, Gong and Wang, Wendong and Lian, Bo and Xu, Ke},
	month = may,
	year = {2020},
	note = {Conference Name: IEEE Network},
	keywords = {Servers, Streaming media, Correlation, Companies, Edge computing, Engines, Quality of experience},
	pages = {194--199},
	file = {IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/TF2YJDW6/Zhang et al. - 2020 - AutoSight Distributed Edge Caching in Short Video.pdf:application/pdf},
}

@article{narayanan_making_2019,
	title = {Making content caching policies 'smart' using the deepcache framework},
	volume = {48},
	issn = {0146-4833},
	url = {https://dl.acm.org/doi/10.1145/3310165.3310174},
	doi = {10.1145/3310165.3310174},
	abstract = {In this paper, we present D���C���� a novel Framework for content caching, which can signi�cantly boost cache performance. Our Framework is based on powerful deep recurrent neural network models. It comprises of two main components: i) Object Characteristics Predictor, which builds upon deep LSTM Encoder-Decoder model to predict the future characteristics of an object (such as object popularity) – to the best of our knowledge, we are the �rst to propose LSTM Encoder-Decoder model for content caching; ii) a caching policy component, which accounts for predicted information of objects to make smart caching decisions. In our thorough experiments, we show that applying D���C���� Framework to existing cache policies, such as LRU and k-LRU, signi�cantly boosts the number of cache hits.},
	language = {en},
	number = {5},
	urldate = {2021-11-08},
	journal = {ACM SIGCOMM Computer Communication Review},
	author = {Narayanan, Arvind and Verma, Saurabh and Ramadan, Eman and Babaie, Pariya and Zhang, Zhi-Li},
	month = jan,
	year = {2019},
	pages = {64--69},
	file = {Narayanan et al. - 2019 - Making content caching policies 'smart' using the .pdf:/home/tobi/programms/Zotero/storage/6ALNFBXQ/Narayanan et al. - 2019 - Making content caching policies 'smart' using the .pdf:application/pdf},
}

@incollection{kaliszky_predicting_1999,
	address = {Vienna},
	title = {Predicting {Users}’ {Requests} on the {WWW}},
	volume = {407},
	isbn = {978-3-211-83151-9 978-3-7091-2490-1},
	url = {http://link.springer.com/10.1007/978-3-7091-2490-1_27},
	abstract = {We describe several Markov models derived from the behaviour patterns of many users, which predict which documents a user is likely to request next. We then present comparative results of the predictive accuracy of the different models, and, based on these results, build hybrid models which combine the individual models in different ways. These hybrid models generally have a greater predictive accuracy than the individual models. The best models will be incorporated in a system for pre-sending WWW documents.},
	language = {en},
	urldate = {2021-11-08},
	booktitle = {{UM99} {User} {Modeling}},
	publisher = {Springer Vienna},
	author = {Zukerman, I. and Albrecht, D. W. and Nicholson, A. E.},
	editor = {Kaliszky, Sandor and Sayir, Mahir and Schneider, Wilhelm and Bianchi, Giovanni and Tasso, Carlo and Kay, Judy},
	year = {1999},
	doi = {10.1007/978-3-7091-2490-1_27},
	note = {Series Title: CISM International Centre for Mechanical Sciences},
	pages = {275--284},
	file = {Zukerman et al. - 1999 - Predicting Users’ Requests on the WWW.pdf:/home/tobi/programms/Zotero/storage/2STNB5Z3/Zukerman et al. - 1999 - Predicting Users’ Requests on the WWW.pdf:application/pdf},
}

@inproceedings{bestavros_using_1995,
	address = {New York, NY, USA},
	series = {{CIKM} '95},
	title = {Using speculation to reduce server load and service time on the {WWW}},
	isbn = {978-0-89791-812-1},
	url = {https://doi.org/10.1145/221270.221653},
	doi = {10.1145/221270.221653},
	urldate = {2021-11-08},
	booktitle = {Proceedings of the fourth international conference on {Information} and knowledge management},
	publisher = {Association for Computing Machinery},
	author = {Bestavros, Azer},
	month = dec,
	year = {1995},
	pages = {403--410},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/DFN2QG5A/Bestavros - 1995 - Using speculation to reduce server load and servic.pdf:application/pdf},
}

@inproceedings{scouarnec_cache_2014,
	title = {Cache {Policies} for {Cloud}-{Based} {Systems}: {To} {Keep} or {Not} to {Keep}},
	shorttitle = {Cache {Policies} for {Cloud}-{Based} {Systems}},
	doi = {10.1109/CLOUD.2014.11},
	abstract = {In this paper, we study cache policies for cloud-based caching. Cloud-based caching uses cloud storage services such as Amazon S3 as a cache for data items that would have been recomputed otherwise. Cloud-based caching departs from classical caching: cloud resources are potentially infinite and only paid when used, while classical caching relies on a fixed storage capacity and its main monetary cost comes from the initial investment. To deal with this new context, we design and evaluate a new caching policy that minimizes the cost of a cloud-based system. The policy takes into account the frequency of consumption of an item and the cloud cost model. We show that this policy is easier to operate, that it scales with the demand and that it outperforms classical policies managing a fixed capacity.},
	booktitle = {2014 {IEEE} 7th {International} {Conference} on {Cloud} {Computing}},
	author = {Scouarnec, Nicolas Le and Neumann, Christoph and Straub, Gilles},
	month = jun,
	year = {2014},
	note = {ISSN: 2159-6190},
	keywords = {Cloud computing, Streaming media, cloud, Analytical models, cache policy, Computational modeling, cost minimization, elasticity, Motion pictures, Video sequences, YouTube},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/T4HU8N2S/6973717.html:text/html;IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/DZN4PFLE/Scouarnec et al. - 2014 - Cache Policies for Cloud-Based Systems To Keep or.pdf:application/pdf},
}

@article{wu_improving_nodate,
	title = {Improving {Web} {Server} {Performance} with {Predictive} {Caching}},
	abstract = {Even with rapid advances in the technology of processors, memory, storage and networks, the growth in web-based information and the increased use of web-based applications continue to place demands on the Internet. Performance of web servers continues to present challenges. Delays in access to web-based information, i.e., access latency, continues to be a serious problem, even with higher bandwidth networks. Web caching and prefetching are well knows strategies for improving the performance of web servers. In this paper we present a predictive caching strategy aimed at improving web server performance and analyze its effectiveness. Results of trace-driven simulation suggest that the approach can improve server performance.},
	language = {en},
	author = {Wu, Chenggang and Bauer, Michael},
	pages = {6},
	file = {Wu and Bauer - Improving Web Server Performance with Predictive C.pdf:/home/tobi/programms/Zotero/storage/ZRBHRQ64/Wu and Bauer - Improving Web Server Performance with Predictive C.pdf:application/pdf},
}

@article{balamash_overview_2004,
	title = {An overview of web caching replacement algorithms},
	volume = {6},
	issn = {1553-877X},
	doi = {10.1109/COMST.2004.5342239},
	abstract = {The increasing demand for World Wide Web (WWW) services has made document caching a necessity to decrease download times and reduce Internet traffic. To make effective use of caching, an informative decision has to be made as to which documents are to be evicted from the cache in case of cache saturation. This is particularly important in a wireless network, where the size of the client cache at the mobile terminal (MT) is small. Several types of caching are used over the Internet, including client caching, server caching, and more recently, proxy caching. In this article we review some of the well known proxy-caching policies for the Web. We describe these policies, show how they operate, and discuss the main traffic properties they incorporate in their design. We argue that a good caching policy adapts itself to changes in Web workload characteristics. We make a qualitative comparison between these policies after classifying them according to the traffic properties they consider in their designs. Furthermore, we compare a selected subset of these policies using trace-driven simulations.},
	number = {2},
	journal = {IEEE Communications Surveys Tutorials},
	author = {Balamash, Abdullah and Krunz, Marwan},
	year = {2004},
	note = {Conference Name: IEEE Communications Surveys Tutorials},
	keywords = {Web server, Web sites, Costs, Frequency, Measurement, Network servers, Telecommunication traffic, Web and internet services, Wireless networks, World Wide Web},
	pages = {44--56},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/DHUWHD47/5342239.html:text/html},
}

@article{balamash_overview_2004-1,
	title = {An overview of web caching replacement algorithms},
	volume = {6},
	issn = {1553-877X},
	doi = {10.1109/COMST.2004.5342239},
	abstract = {The increasing demand for World Wide Web (WWW) services has made document caching a necessity to decrease download times and reduce Internet traffic. To make effective use of caching, an informative decision has to be made as to which documents are to be evicted from the cache in case of cache saturation. This is particularly important in a wireless network, where the size of the client cache at the mobile terminal (MT) is small. Several types of caching are used over the Internet, including client caching, server caching, and more recently, proxy caching. In this article we review some of the well known proxy-caching policies for the Web. We describe these policies, show how they operate, and discuss the main traffic properties they incorporate in their design. We argue that a good caching policy adapts itself to changes in Web workload characteristics. We make a qualitative comparison between these policies after classifying them according to the traffic properties they consider in their designs. Furthermore, we compare a selected subset of these policies using trace-driven simulations.},
	number = {2},
	journal = {IEEE Communications Surveys Tutorials},
	author = {Balamash, Abdullah and Krunz, Marwan},
	year = {2004},
	note = {Conference Name: IEEE Communications Surveys Tutorials},
	keywords = {Web server, Web sites, Costs, Frequency, Measurement, Network servers, Telecommunication traffic, Web and internet services, Wireless networks, World Wide Web},
	pages = {44--56},
}

@inproceedings{pu_shuffling_2019-1,
	title = {Shuffling, {Fast} and {Slow}: {Scalable} {Analytics} on {Serverless} {Infrastructure}},
	isbn = {978-1-931971-49-2},
	shorttitle = {Shuffling, {Fast} and {Slow}},
	url = {https://www.usenix.org/conference/nsdi19/presentation/pu},
	language = {en},
	urldate = {2021-11-13},
	author = {Pu, Qifan and Venkataraman, Shivaram and Stoica, Ion},
	year = {2019},
	pages = {193--206},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/MY9G9MXU/Pu et al. - 2019 - Shuffling, Fast and Slow Scalable Analytics on Se.pdf:application/pdf;Snapshot:/home/tobi/programms/Zotero/storage/5DJPRGNQ/pu.html:text/html},
}

@article{demaine_cache-oblivious_nodate-1,
	title = {Cache-{Oblivious} {Algorithms} and {Data} {Structures}},
	abstract = {A recent direction in the design of cache-eﬃcient and diskeﬃcient algorithms and data structures is the notion of cache obliviousness, introduced by Frigo, Leiserson, Prokop, and Ramachandran in 1999. Cache-oblivious algorithms perform well on a multilevel memory hierarchy without knowing any parameters of the hierarchy, only knowing the existence of a hierarchy. Equivalently, a single cache-oblivious algorithm is eﬃcient on all memory hierarchies simultaneously. While such results might seem impossible, a recent body of work has developed cache-oblivious algorithms and data structures that perform as well or nearly as well as standard external-memory structures which require knowledge of the cache/memory size and block transfer size. Here we describe several of these results with the intent of elucidating the techniques behind their design. Perhaps the most exciting of these results are the data structures, which form general building blocks immediately leading to several algorithmic results.},
	language = {en},
	author = {Demaine, Erik D},
	pages = {29},
	file = {Demaine - Cache-Oblivious Algorithms and Data Structures.pdf:/home/tobi/programms/Zotero/storage/XKDQRAQK/Demaine - Cache-Oblivious Algorithms and Data Structures.pdf:application/pdf},
}

@inproceedings{ban_online_2007,
	address = {New York, NY, USA},
	series = {{WIDM} '07},
	title = {An online {PPM} prediction model for web prefetching},
	isbn = {978-1-59593-829-9},
	url = {https://doi.org/10.1145/1316902.1316917},
	doi = {10.1145/1316902.1316917},
	abstract = {Web prefetching is a primary means to reduce user access latency. An important amount of work can be found by the use of PPM (Prediction by Partial Match) for modeling and predicting user request patterns in the open literature. However, in general, existing PPM models are constructed off-line. It is highly desirable to perform the online update of the PPM model incrementally because user request patterns may change over time. We present an online PPM model to capture the changing patterns and fit the memory. This model is implemented based on a noncompact suffix tree. Our model only keeps the most recent W requests using a sliding window. To further improve the prefetching performance, we make use of maximum entropy principle to model for the outgoing probability distributions of nodes. Our prediction model combines entropy, prediction accuracy rate and the longest match rule. A performance evaluation is presented using real web logs. Trace-driven simulation results show our PPM prediction model can provide significant improvements over previously proposed models.},
	urldate = {2021-11-22},
	booktitle = {Proceedings of the 9th annual {ACM} international workshop on {Web} information and data management},
	publisher = {Association for Computing Machinery},
	author = {Ban, Zhijie and Gu, Zhimin and Jin, Yu},
	month = nov,
	year = {2007},
	keywords = {entropy, noncompact suffix tree, PPM, web prefetching},
	pages = {89--96},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/IT5MYVYD/Ban et al. - 2007 - An online PPM prediction model for web prefetching.pdf:application/pdf},
}

@article{ali_survey_2011,
	title = {A survey of web caching and prefetching},
	abstract = {Abstract Web caching and prefetching are the most popular techniques that play a key role in improving the Web performance by keeping web objects that are likely to be visited in the near future closer to the client. Web caching can work independently or integrated with the web prefetching. The Web caching and prefetching can complement each other since the web caching exploits the temporal locality for predicting revisiting requested objects, while the web prefetching utilizes the spatial locality for predicting next related web objects of the requested Web objects. This paper reviews principles and some existing web caching and prefetching approaches. The conventional and intelligent web caching techniques are investigated and discussed. Moreover, Web prefetching techniques are summarized and classified with comparison limitations of these approaches. This paper also presents and discusses some studies that take into consideration impact of integrating both web caching and web prefetching together.},
	journal = {Int. J. Adv. Soft Comput. Appl},
	author = {Ali, Waleed and Shamsuddin, Siti Mariyam and Samad, Abdul and {Ismail}},
	year = {2011},
	pages = {18--44},
	file = {Citeseer - Snapshot:/home/tobi/programms/Zotero/storage/IECFQBPG/download.html:text/html;Citeseer - Full Text PDF:/home/tobi/programms/Zotero/storage/KTCBCY2H/Ali et al. - 2011 - A survey of web caching and prefetching.pdf:application/pdf},
}

@inproceedings{de_la_ossa_referrer_2010,
	address = {New York, NY, USA},
	series = {{SAC} '10},
	title = {Referrer graph: a low-cost web prediction algorithm},
	isbn = {978-1-60558-639-7},
	shorttitle = {Referrer graph},
	url = {https://doi.org/10.1145/1774088.1774260},
	doi = {10.1145/1774088.1774260},
	abstract = {This paper presents the Referrer Graph (RG) web prediction algorithm as a low-cost solution to predict next web user accesses. RG is aimed at being used in a real web system with prefetching capabilities without degrading its performance. The algorithm learns from user accesses and builds a Markov model. These kinds kind of algorithms use the sequence of the user accesses to make predictions. Unlike previous Markov model based proposals, the RG algorithm differentiates dependencies in objects of the same page from objects of different pages by using the object URI and referrer in each request. This permits us to build a simple data structure that is easier to handle and, consequently, with a lower computational cost in comparison with other algorithms. The RG algorithm has been evaluated and compared with the best prediction algorithms proposed in the open literature, and the results show that it achieves similar precision values and page latency savings but requiring much less computational and memory resources.},
	urldate = {2021-11-22},
	booktitle = {Proceedings of the 2010 {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {de la Ossa, B. and Pont, A. and Sahuquillo, J. and Gil, J. A.},
	month = mar,
	year = {2010},
	keywords = {web prefetching, latency reduction, web prediction},
	pages = {831--838},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/TLI3SJ7F/de la Ossa et al. - 2010 - Referrer graph a low-cost web prediction algorith.pdf:application/pdf},
}

@article{abdalla_intelligent_nodate,
	title = {Intelligent {Web} {Objects} {Prediction} {Approach} in {Web} {Proxy} {Cache} {Using} {Supervised} {Machine} {Learning} and {Feature} {Selection}},
	abstract = {Web proxy cache is used to enhance the performance of network by keeping popular web objects in cache of proxy server for closer access. Intelligent approaches aim at improving the performance of conventional strategies. Mostly focus was on improving prediction mechanism, to guess the ideal objects that will be revisited in future; cache them and combine the result with the conventional algorithm. This research proposes an improved prediction method using automated method to select the influence features that produce accurate prediction results before combining with conventional algorithm. The method use supervised machine learning based on Naïve Bayes (NB) and Decision Tree (C4.5). It applies wrapper feature selection to specify influence features with optimal subset to improve the predictive power. Additionally two more features are extracted to know user’s interest to make a smart and a wise decision for caching. The results showed that reduction for the number of features has a good impact on reducing computation time. Moreover, optimal subset selection achieves high performance and enhances accuracy.},
	language = {en},
	author = {Abdalla, Amira and Sulaiman, Sarina and Ali, Waleed},
	pages = {19},
	file = {Abdalla et al. - Intelligent Web Objects Prediction Approach in Web.pdf:/home/tobi/programms/Zotero/storage/7ZUNYT4P/Abdalla et al. - Intelligent Web Objects Prediction Approach in Web.pdf:application/pdf},
}

@article{kurian_markov_nodate,
	title = {A {MARKOV} {MODEL} {FOR} {WEB} {REQUEST} {PREDICTION}},
	language = {en},
	author = {Kurian, Habel},
	pages = {58},
	file = {Kurian - A MARKOV MODEL FOR WEB REQUEST PREDICTION.pdf:/home/tobi/programms/Zotero/storage/ITJNGIE4/Kurian - A MARKOV MODEL FOR WEB REQUEST PREDICTION.pdf:application/pdf},
}

@techreport{kurian_markov_2008,
	type = {Report},
	title = {A {Markov} model for web request prediction},
	url = {https://krex.k-state.edu/dspace/handle/2097/919},
	abstract = {Increasing web content and Internet traffic is making web prediction models popular.  A web prediction model helps to predict user requests ahead of time, making web servers more responsive. It caches these pages at the server side or pre-sends the response to the client to reduce web latency.  Several prediction techniques have been tried in the past; Markov based prediction models being the most popular ones.  Among these, the All-K[superscript]th -order Markov model has been found to be most effective. In this project, a Markov tree is designed, which is a fourth order model but behaves like an All-K[superscript]th-order Markov model because of its ability to recognize different order models according to the height of the tree. It has dual characteristics of good applicability and predictive accuracy. A Markov tree gives a complete description on the frequency with which a particular state occurs, and the number of times a path to a particular state is used, to access its child nodes. Further, the model can be pruned to eliminate states that have very little contribution towards the accuracy of the model. 
 
In this work, an evolutionary model is designed that makes use of a fitness function. The fitness function is a weighted sum of precision and the extent of coverage that the model offers. This helps to generate a model with reduced complexity. Results indicate that this model performs consistently with good predictive accuracy among different log files. The evolutionary approach helps to train the model to make predictions commensurate to current web browsing patterns.},
	language = {en\_US},
	urldate = {2021-11-19},
	institution = {Kansas State University},
	author = {Kurian, Habel},
	year = {2008},
	note = {Accepted: 2008-08-13T13:42:11Z},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/32RNKPUP/Kurian - 2008 - A Markov model for web request prediction.pdf:application/pdf;Snapshot:/home/tobi/programms/Zotero/storage/FIQFZB7R/919.html:text/html},
}

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2021-11-19},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv: 1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/tobi/programms/Zotero/storage/B7I8GX83/1706.html:text/html;arXiv Fulltext PDF:/home/tobi/programms/Zotero/storage/8JZ3P4JT/Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf},
}

@inproceedings{zhong_su_whatnext_2000,
	address = {Hong Kong, China},
	title = {{WhatNext}: a prediction system for {Web} requests using n-gram sequence models},
	volume = {1},
	isbn = {978-0-7695-0577-0},
	shorttitle = {{WhatNext}},
	url = {http://ieeexplore.ieee.org/document/882395/},
	doi = {10.1109/WISE.2000.882395},
	abstract = {As an increasing number of users access information on the web, there is a great opportunity to learn from the server logs to learn about the users’ probable actions in the future. In this paper, we present an n-gram based model to utilize path profiles of users from very large data sets to predict the users’ future requests. Since this is a prediction system, we cannot measure the recall in a traditional sense. We, therefore, present the notion of applicability to give a measure of the ability to predict the next document. Our model is based on a simple extension of existing pointbased models for such predictions, but our results show for n-gram based prediction when n is greater than three, we can increase precision by 20\% or more for two realistic web logs. Also we present an efficient method that can compress our model to 30\% of its original size so that the model can be loaded in main memory. Our result can potentially be applied to a wide range of applications on the web, including pre-sending, pre-fetching, enhancement of recommendation systems as well as web caching policies. Our tests are based on three realistic web logs. Our algorithm is implemented in a prediction system called WhatNext, which shows a marked improvement in precision and applicability over previous approaches.},
	language = {en},
	urldate = {2021-11-19},
	booktitle = {Proceedings of the {First} {International} {Conference} on {Web} {Information} {Systems} {Engineering}},
	publisher = {IEEE Comput. Soc},
	author = {{Zhong Su} and {Qiang Yang} and {Ye Lu} and {Hongjiang Zhang}},
	year = {2000},
	pages = {214--221},
	file = {Zhong Su et al. - 2000 - WhatNext a prediction system for Web requests usi.pdf:/home/tobi/programms/Zotero/storage/8BAL2XY9/Zhong Su et al. - 2000 - WhatNext a prediction system for Web requests usi.pdf:application/pdf},
}

@inproceedings{glasbergen_chronocache_2020,
	address = {Portland OR USA},
	title = {{ChronoCache}: {Predictive} and {Adaptive} {Mid}-{Tier} {Query} {Result} {Caching}},
	isbn = {978-1-4503-6735-6},
	shorttitle = {{ChronoCache}},
	url = {https://dl.acm.org/doi/10.1145/3318464.3380593},
	doi = {10.1145/3318464.3380593},
	abstract = {The performance of data-driven, web-scale client applications is sensitive to access latency. To address this concern, enterprises strive to cache data on edge nodes that are closer to users, thereby avoiding expensive round-trips to remote data centers. However, these geo-distributed approaches are limited to caching static data. In this paper we present ChronoCache, a mid-tier caching system that exploits the presence of geo-distributed edge nodes to cache database query results closer to users. ChronoCache transparently learns and leverages client application access patterns to predictively combine query requests and cache their results ahead of time, thereby reducing costly round-trips to the remote database. We show that ChronoCache reduces query response times by up to 2/3 over prior approaches on multiple representative benchmark workloads.},
	language = {en},
	urldate = {2021-11-15},
	booktitle = {Proceedings of the 2020 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Glasbergen, Brad and Langendoen, Kyle and Abebe, Michael and Daudjee, Khuzaima},
	month = jun,
	year = {2020},
	pages = {2391--2406},
	file = {Glasbergen et al. - 2020 - ChronoCache Predictive and Adaptive Mid-Tier Quer.pdf:/home/tobi/programms/Zotero/storage/F2LBWP52/Glasbergen et al. - 2020 - ChronoCache Predictive and Adaptive Mid-Tier Quer.pdf:application/pdf},
}

@inproceedings{gunasekaran_minimizing_2020,
	address = {Delft Netherlands},
	title = {Minimizing {Cost} and {Maximizing} {Performance} for {Cloud} {Platforms}},
	isbn = {978-1-4503-8200-7},
	url = {https://dl.acm.org/doi/10.1145/3429351.3431747},
	doi = {10.1145/3429351.3431747},
	abstract = {We are witnessing the rapid growth of cloud computing with the proliferation of tenants adopting cloud for elasticity, availability, and flexibility for a plethora of applications. To efficiently cater for different tenant requirements, cloud providers have steadily evolved to offer a myriad of resource and service types which inherently complicates the cloud adoption process. On the other hand, the perpetuating growth of cloud tenants in turn impel providers to expand datacenters to cope with the tenant demand. The objective of this proposal is to maximize the performance and minimize the cost for both tenants and cloud providers, by providing efficient means of managing resource allocations for their applications. Towards this, the proposal comprises of three intertwined tasks. First, we start from a tenant perspective, with the first two tasks aimed at investigating the primary reasons for performance-cost inefficiency. Second, from a provider perspective, the third task investigates the primary reasons for performance-energy inefficiency in datacenters. All the three tasks can collectively improve the performance and cost efficiency of emerging applications in next generation cloud platforms.},
	language = {en},
	urldate = {2021-11-15},
	booktitle = {Proceedings of the 21st {International} {Middleware} {Conference} {Doctoral} {Symposium}},
	publisher = {ACM},
	author = {Gunasekaran, Jashwant Raj},
	month = dec,
	year = {2020},
	pages = {29--34},
	file = {Gunasekaran - 2020 - Minimizing Cost and Maximizing Performance for Clo.pdf:/home/tobi/programms/Zotero/storage/DG6FLRXK/Gunasekaran - 2020 - Minimizing Cost and Maximizing Performance for Clo.pdf:application/pdf},
}

@inproceedings{mosberger_httperf_1998,
	title = {httperf - {A} {Tool} for {Measuring} {Web} {Server} {Performance}},
	abstract = {This paper describes httperf, a tool for measuring web server performance. It provides a flexible facility for generating various HTTP workloads and for measuring server performance. The focus of httperf is not on implementing one particular benchmark but on providing a robust, high-performance tool that facilitates the construction of both micro- and macro-level benchmarks. The three distinguishing characteristics of httperf are its robustness, which includes the ability to generate and sustain server overload, support for the HTTP/1.1 protocol, and its extensibility to new workload generators and performance measurements. In addition to reporting on the design and implementation of httperf this paper also discusses some of the experiences and insights gained while realizing this tool.},
	booktitle = {In {First} {Workshop} on {Internet} {Server} {Performance}},
	publisher = {ACM},
	author = {Mosberger, David and Jin, Tai},
	year = {1998},
	pages = {59--67},
	file = {Citeseer - Full Text PDF:/home/tobi/programms/Zotero/storage/LGGHEIVQ/Mosberger and Jin - 1998 - httperf - A Tool for Measuring Web Server Performa.pdf:application/pdf;Citeseer - Snapshot:/home/tobi/programms/Zotero/storage/LBUJDZTK/summary.html:text/html},
}

@inproceedings{cecchet_benchlab_2011,
	title = {{BenchLab}: {An} {Open} {Testbed} for {Realistic} {Benchmarking} of {Web} {Applications}},
	shorttitle = {{BenchLab}},
	url = {https://www.usenix.org/conference/webapps11/benchlab-open-testbed-realistic-benchmarking-web-applications},
	language = {en},
	urldate = {2021-11-15},
	author = {Cecchet, Emmanuel and Udayabhanu, Veena and Wood, Timothy and Shenoy, Prashant},
	year = {2011},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/FG52XGBS/benchlab-open-testbed-realistic-benchmarking-web-applications.html:text/html;Full Text PDF:/home/tobi/programms/Zotero/storage/NJGAA5V2/Cecchet et al. - 2011 - BenchLab An Open Testbed for Realistic Benchmarki.pdf:application/pdf},
}

@misc{noauthor_using_nodate,
	title = {Using {JMeter} to {Performance} {Test} {Web} {Services2}},
	url = {https://www.oracle.com/technical-resources/articles/enterprise-architecture/jmeter-performance-testing-part2.html},
	urldate = {2021-11-15},
	file = {Using JMeter to Performance Test Web Services2:/home/tobi/programms/Zotero/storage/DL45JSDB/jmeter-performance-testing-part2.html:text/html},
}

@inproceedings{bodik_characterizing_2010-1,
	address = {Indianapolis, Indiana, USA},
	title = {Characterizing, modeling, and generating workload spikes for stateful services},
	isbn = {978-1-4503-0036-0},
	url = {http://portal.acm.org/citation.cfm?doid=1807128.1807166},
	doi = {10.1145/1807128.1807166},
	abstract = {Evaluating the resiliency of stateful Internet services to signiﬁcant workload spikes and data hotspots requires realistic workload traces that are usually very diﬃcult to obtain. A popular approach is to create a workload model and generate synthetic workload, however, there exists no characterization and model of stateful spikes. In this paper we analyze ﬁve workload and data spikes and ﬁnd that they vary signiﬁcantly in many important aspects such as steepness, magnitude, duration, and spatial locality. We propose and validate a model of stateful spikes that allows us to synthesize volume and data spikes and could thus be used by both cloud computing users and providers to stress-test their infrastructure.},
	language = {en},
	urldate = {2022-01-22},
	booktitle = {Proceedings of the 1st {ACM} symposium on {Cloud} computing - {SoCC} '10},
	publisher = {ACM Press},
	author = {Bodik, Peter and Fox, Armando and Franklin, Michael J. and Jordan, Michael I. and Patterson, David A.},
	year = {2010},
	pages = {241},
	file = {Bodik et al. - 2010 - Characterizing, modeling, and generating workload .pdf:/home/tobi/programms/Zotero/storage/A24CDIW7/Bodik et al. - 2010 - Characterizing, modeling, and generating workload .pdf:application/pdf},
}

@article{heeger_poisson_nodate,
	title = {Poisson {Model} of {Spike} {Generation}},
	language = {en},
	author = {Heeger, Professor David},
	pages = {13},
	file = {Heeger - Poisson Model of Spike Generation.pdf:/home/tobi/programms/Zotero/storage/ZXU2UICL/Heeger - Poisson Model of Spike Generation.pdf:application/pdf},
}

@article{sreekanti_cloudburst_2020,
	title = {Cloudburst: {Stateful} {Functions}-as-a-{Service}},
	volume = {13},
	issn = {2150-8097},
	shorttitle = {Cloudburst},
	url = {http://arxiv.org/abs/2001.04592},
	doi = {10.14778/3407790.3407836},
	abstract = {Function-as-a-Service (FaaS) platforms and "serverless" cloud computing are becoming increasingly popular. Current FaaS offerings are targeted at stateless functions that do minimal I/O and communication. We argue that the benefits of serverless computing can be extended to a broader range of applications and algorithms. We present the design and implementation of Cloudburst, a stateful FaaS platform that provides familiar Python programming with low-latency mutable state and communication, while maintaining the autoscaling benefits of serverless computing. Cloudburst accomplishes this by leveraging Anna, an autoscaling key-value store, for state sharing and overlay routing combined with mutable caches co-located with function executors for data locality. Performant cache consistency emerges as a key challenge in this architecture. To this end, Cloudburst provides a combination of lattice-encapsulated state and new definitions and protocols for distributed session consistency. Empirical results on benchmarks and diverse applications show that Cloudburst makes stateful functions practical, reducing the state-management overheads of current FaaS platforms by orders of magnitude while also improving the state of the art in serverless consistency.},
	number = {12},
	urldate = {2022-01-28},
	journal = {Proceedings of the VLDB Endowment},
	author = {Sreekanti, Vikram and Wu, Chenggang and Lin, Xiayue Charles and Schleier-Smith, Johann and Faleiro, Jose M. and Gonzalez, Joseph E. and Hellerstein, Joseph M. and Tumanov, Alexey},
	month = aug,
	year = {2020},
	note = {arXiv: 2001.04592},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	pages = {2438--2452},
	file = {arXiv Fulltext PDF:/home/tobi/programms/Zotero/storage/ECV2ET63/Sreekanti et al. - 2020 - Cloudburst Stateful Functions-as-a-Service.pdf:application/pdf;arXiv.org Snapshot:/home/tobi/programms/Zotero/storage/MIMZUTHJ/2001.html:text/html},
}

@article{nishtala_scaling_nodate,
	title = {Scaling {Memcache} at {Facebook}},
	abstract = {Memcached is a well known, simple, inmemory caching solution. This paper describes how Facebook leverages memcached as a building block to construct and scale a distributed key-value store that supports the world’s largest social network. Our system handles billions of requests per second and holds trillions of items to deliver a rich experience for over a billion users around the world.},
	language = {en},
	author = {Nishtala, Rajesh and Fugal, Hans and Grimm, Steven and Kwiatkowski, Marc and Lee, Herman and Li, Harry C and McElroy, Ryan and Paleczny, Mike and Peek, Daniel and Saab, Paul and Stafford, David and Tung, Tony and Venkataramani, Venkateshwaran},
	pages = {14},
	file = {Nishtala et al. - Scaling Memcache at Facebook.pdf:/home/tobi/programms/Zotero/storage/QLSHKVSA/Nishtala et al. - Scaling Memcache at Facebook.pdf:application/pdf},
}

@book{chen_towards_2016,
	title = {Towards {Scalable} and {Reliable} {In}-{Memory} {Storage} {System}: {A} {Case} {Study} with {Redis}},
	shorttitle = {Towards {Scalable} and {Reliable} {In}-{Memory} {Storage} {System}},
	abstract = {In recent years, in-memory key-value storage systems have become more and more popular in solving real-time and interactive tasks. Compared with disks, memories have much higher throughput and lower latency which enables them to process data requests with much higher performance. However, since memories have much smaller capacity than disks, how to expand the capacity of in-memory storage system while maintain its high performance become a crucial problem. At the same time, since data in memories are non-persistent, the data may be lost when the system is down. In this paper, we make a case study with Redis, which is one popular in-memory key-value storage system. We find that although the latest release of Redis support clustering so that data can be stored in distributed nodes to support a larger storage capacity, its performance is limited by its decentralized design that clients usually need two connections to get their request served. To make the system more scalable, we propose a Clientside Key-to-Node Caching method that can help direct request to the right service node. Experimental results show that by applying this technique, it can significantly improve the system's performance by near 2 times. We also find that although Redis supports data replication on slave nodes to ensure data safety, it still gets a chance of losing a part of the data due to a weak consistency between master and slave nodes that its defective order of data replication and request reply may lead to losing data without notifying the client. To make it more reliable, we propose a Master-slave Semi Synchronization method which utilizes TCP protocol to ensure the order of data replication and request reply so that when a client receives an "OK" message, the corresponding data must have been replicated. With a significant improvement in data reliability, its performance overhead is limited within 5\%.},
	author = {Chen, Shanshan and Tang, Xiaoxin and Wang, Hongwei and Zhao, Han and Guo, Minyi},
	month = aug,
	year = {2016},
	doi = {10.1109/TrustCom.2016.0255},
	note = {Pages: 1667},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/EMXKUYL9/Chen et al. - 2016 - Towards Scalable and Reliable In-Memory Storage Sy.pdf:application/pdf},
}

@article{kaur_-memory_2018,
	title = {In-{Memory} {Data} processing using {Redis} {Database}},
	volume = {180},
	issn = {09758887},
	url = {http://www.ijcaonline.org/archives/volume180/number25/spal-2018-ijca-916589.pdf},
	doi = {10.5120/ijca2018916589},
	abstract = {In present, in-memory data processing is becoming more popular due to examine a huge amount of information in shorter duration of time. Previously all servers utilize their own particular memory which is time consuming. To resolve this problem by using distributed cache, servers using cache memory for storing and retrieving data frequently. In present Big data processing, in-memory enumerate has become famous due to increase capacity and high throughput of main memory. Both relational and NoSQL databases are inmemory database that provides different mechanism for data storage and retrieval. In this paper, they make use of an inmemory key-value data storage system is Redis which works on a large data. Also, Redis server makes use of cache memory for increasing scalability and high throughput of main memory. Redis database helps in getting data from applications more frequently which improves the system performance as compared to relational database.},
	language = {en},
	number = {25},
	urldate = {2022-01-31},
	journal = {International Journal of Computer Applications},
	author = {Kaur, Gurpreet and Kaur, Jatinder},
	month = mar,
	year = {2018},
	pages = {26--31},
	file = {Kaur and Kaur - 2018 - In-Memory Data processing using Redis Database.pdf:/home/tobi/programms/Zotero/storage/YJK2CXHG/Kaur and Kaur - 2018 - In-Memory Data processing using Redis Database.pdf:application/pdf},
}

@inproceedings{puangsaijai_comparative_2017,
	title = {A comparative study of relational database and key-value database for big data applications},
	doi = {10.1109/IEECON.2017.8075813},
	abstract = {Nowadays, Demands of web scale are in increasing and growing rapidly. Mobile applications, web technologies, social media always generates unstructured data that had lead to the advent of various NoSQL databases. Therefore, Big data applications are necessary to have an efficient technology to collect these data. However, a relational database is the traditional database that always uses in many applications and still has more valuable to play a significant role in the current information system. The main characteristics of NoSQL databases are schema-free, no relationship, no need to join as a relational database. The business organization expects that NoSQL database has better performance than a relational database. In This paper, we aim to compare the performance of Redis, which is a key-value database, one kind of NoSQL database, and MariaDB, which is a popular relational database. We designed a set of experiments with a large amount of data and compared the efficiency of the insert, update, delete and select transactions from various aspects on the same dataset. We measure the processing time of each transaction to evaluate the comparison. The results have shown that Redis has better runtime performance for insert, delete, update transaction under a specific condition or complex queries. MariaDB still is good for some conditions especially when we have a small data. Our study can help to choose a database that will be suitable for the real world applications because relational databases and NoSQL databases have different strengths and weakness.},
	booktitle = {2017 {International} {Electrical} {Engineering} {Congress} ({iEECON})},
	author = {Puangsaijai, Wittawat and Puntheeranurak, Sutheera},
	month = mar,
	year = {2017},
	keywords = {Servers, Big data applications, Big Data applications, Electrical engineering, Key-value database, MariaDB, NoSQL database, NoSQL databases, Redis, Relational databases, Remuneration},
	pages = {1--4},
	file = {IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/2IV9UNCC/Puangsaijai and Puntheeranurak - 2017 - A comparative study of relational database and key.pdf:application/pdf;IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/CZLTLXQD/8075813.html:text/html},
}

@inproceedings{adya_fast_2019,
	title = {Fast key-value stores: {An} idea whose time has come and gone},
	shorttitle = {Fast key-value stores},
	booktitle = {{HotOS} {XVII}},
	author = {Adya, Atul and Myers, Daniel and Qin, Henry and Grandl, Robert},
	year = {2019},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/7M4XEDBJ/Adya et al. - 2019 - Fast key-value stores An idea whose time has come.pdf:application/pdf},
}

@article{noauthor_performance_nodate,
	title = {Performance at {Scale} with {Amazon} {ElastiCache}},
	language = {en},
	pages = {51},
	file = {Performance at Scale with Amazon ElastiCache.pdf:/home/tobi/programms/Zotero/storage/P4NPX7N4/Performance at Scale with Amazon ElastiCache.pdf:application/pdf},
}

@inproceedings{lubis_multi-thread_2015,
	title = {Multi-thread performance on a single thread in-memory database},
	doi = {10.1109/ICITEED.2015.7409012},
	abstract = {Industries have now leveraged commodity hardware on their big data products. When it comes to big-data, large scale tasks are executed with a huge amount of data being processed and optionally stored in persistent storage. One of leading innovation in alternative NoSQL and big data which enables low cost commodity hardware plays role is Redis, an in-memory database technology. Instead of disk, memory used in Redis is mainly to avoid latency during I/O processes. Big data processes require tons of I/O process on storage. This makes in-memory database run faster than conventional disk-optimized database. This research is an attempt to expose latency and improve performance by experimenting multi-thread approach during short message (SMS) delivery in single-thread Redis environment in combination with Rapidpro, a mass SMS management platform.},
	booktitle = {2015 7th {International} {Conference} on {Information} {Technology} and {Electrical} {Engineering} ({ICITEE})},
	author = {Lubis, Ramot and Sagala, Albert},
	month = oct,
	year = {2015},
	keywords = {Databases, Web servers, Redis, Benchmark testing, Big data, in-memory database, Instruction sets, Memory management, Message systems, multi-thread, network latency, Short Message Service (SMS)},
	pages = {571--575},
	file = {IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/HVA8HWEU/Lubis and Sagala - 2015 - Multi-thread performance on a single thread in-mem.pdf:application/pdf;IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/EAST28QY/7409012.html:text/html},
}

@book{wheeler_spring_2013,
	address = {Shelter Island, NY},
	title = {Spring in practice: covers {Spring} 3},
	isbn = {978-1-935182-05-4},
	shorttitle = {Spring in practice},
	language = {en},
	publisher = {Manning},
	author = {Wheeler, Willie and White, Joshua},
	year = {2013},
	file = {Wheeler and White - 2013 - Spring in practice covers Spring 3.pdf:/home/tobi/programms/Zotero/storage/F75UYU52/Wheeler and White - 2013 - Spring in practice covers Spring 3.pdf:application/pdf},
}

@misc{noauthor_redis_nodate,
	title = {Redis in {Action} {\textbar} {Guide} books},
	url = {https://dl.acm.org/doi/10.5555/2505464},
	urldate = {2022-01-31},
	file = {Redis in Action | Guide books:/home/tobi/programms/Zotero/storage/873KELQZ/2505464.html:text/html},
}

@misc{noauthor_elasticache_nodate,
	title = {{ElastiCache} or {Self}-{Hosted} {Redis} on {EC2}: {Which} is the {One} {For} {You}? - {DZone} {Cloud}},
	shorttitle = {{ElastiCache} or {Self}-{Hosted} {Redis} on {EC2}},
	url = {https://dzone.com/articles/elasticache-or-self-hosted-redis-on-ec2-which-is-t},
	abstract = {A comparison between self-managed Redis or ElastiCache on the basis of cost, specific use case scenarios, features, and support for other applications.},
	language = {en},
	urldate = {2022-01-31},
	journal = {dzone.com},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/IRTBIDWB/elasticache-or-self-hosted-redis-on-ec2-which-is-t.html:text/html},
}

@misc{noauthor_turbocharge_2019,
	title = {Turbocharge {Amazon} {S3} with {Amazon} {ElastiCache} for {Redis}},
	url = {https://aws.amazon.com/blogs/storage/turbocharge-amazon-s3-with-amazon-elasticache-for-redis/},
	abstract = {Authored by Michael Labib, Principal Architect, AWS Solutions Architecture with contribution from Sabrinath Rao, Amazon S3 product manager Amazon S3 is the persistent store for applications such as data lakes, media catalogs, and website-related content. These applications often have latency requirements of 10 ms or less, with frequent object requests on 1–10\% of the total stored […]},
	language = {en-US},
	urldate = {2022-01-31},
	journal = {Amazon Web Services},
	month = mar,
	year = {2019},
	note = {Section: Advanced (300)},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/DNQR2SYW/turbocharge-amazon-s3-with-amazon-elasticache-for-redis.html:text/html},
}

@article{zhang_-memory_2015,
	title = {In-{Memory} {Big} {Data} {Management} and {Processing}: {A} {Survey}},
	volume = {27},
	issn = {1558-2191},
	shorttitle = {In-{Memory} {Big} {Data} {Management} and {Processing}},
	doi = {10.1109/TKDE.2015.2427795},
	abstract = {Growing main memory capacity has fueled the development of in-memory big data management and processing. By eliminating disk I/O bottleneck, it is now possible to support interactive data analytics. However, in-memory systems are much more sensitive to other sources of overhead that do not matter in traditional I/O-bounded disk-based systems. Some issues such as fault-tolerance and consistency are also more challenging to handle in in-memory environment. We are witnessing a revolution in the design of database systems that exploits main memory as its data storage layer. Many of these researches have focused along several dimensions: modern CPU and memory hierarchy utilization, time/space efficiency, parallelism, and concurrency control. In this survey, we aim to provide a thorough review of a wide range of in-memory data management and processing proposals and systems, including both data storage systems and data processing frameworks. We also give a comprehensive presentation of important technology in memory management, and some key factors that need to be considered in order to achieve efficient in-memory data management and processing.},
	number = {7},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Zhang, Hao and Chen, Gang and Ooi, Beng Chin and Tan, Kian-Lee and Zhang, Meihui},
	month = jul,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {Memory management, distributed databases, DRAM, Indexes, Optimization, Parallel processing, primary memory, Primary memory, query processing, Random access memory, Registers, relational databases},
	pages = {1920--1948},
	file = {IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/XB6UJ52L/Zhang et al. - 2015 - In-Memory Big Data Management and Processing A Su.pdf:application/pdf},
}

@misc{noauthor_redeo_nodate,
	title = {redeo package - github.com/mason-leap-lab/redeo - pkg.go.dev},
	url = {https://pkg.go.dev/github.com/mason-leap-lab/redeo?utm_source=godoc},
	urldate = {2022-01-31},
	file = {redeo package - github.com/mason-leap-lab/redeo - pkg.go.dev:/home/tobi/programms/Zotero/storage/754DUG3E/redeo.html:text/html},
}

@misc{noauthor_redeo_nodate-1,
	title = {redeo package - github.com/mason-leap-lab/redeo - pkg.go.dev},
	url = {https://pkg.go.dev/github.com/mason-leap-lab/redeo?utm_source=godoc},
	urldate = {2022-01-31},
}

@misc{noauthor_gin_2022,
	title = {Gin {Web} {Framework}},
	copyright = {MIT},
	url = {https://github.com/gin-gonic/gin},
	abstract = {Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance -- up to 40 times faster. If you need smashing performance, get yourself some Gin.},
	urldate = {2022-01-31},
	publisher = {Gin-Gonic},
	month = jan,
	year = {2022},
	note = {original-date: 2014-06-16T23:57:25Z},
	keywords = {framework, gin, go, middleware, performance, router, server},
}

@misc{schmidt_httprouter_2022,
	title = {{HttpRouter}},
	copyright = {BSD-3-Clause},
	url = {https://github.com/julienschmidt/httprouter},
	abstract = {A high performance HTTP request router that scales well},
	urldate = {2022-01-31},
	author = {Schmidt, Julien},
	month = jan,
	year = {2022},
	note = {original-date: 2013-12-05T15:10:55Z},
	keywords = {go, router, golang, http, httprouter, mux},
}

@misc{noauthor_redis_nodate-1,
	title = {redis package - github.com/go-redis/redis/v8 - pkg.go.dev},
	url = {https://pkg.go.dev/github.com/go-redis/redis/v8},
	urldate = {2022-02-01},
	file = {redis package - github.com/go-redis/redis/v8 - pkg.go.dev:/home/tobi/programms/Zotero/storage/FE54GFD8/v8.html:text/html},
}

@misc{noauthor_secure_nodate,
	title = {Secure and resizable cloud compute – {Amazon} {EC2} – {Amazon} {Web} {Services}},
	url = {https://aws.amazon.com/ec2/},
	abstract = {Amazon EC2 provides secure, resizable compute in the cloud, offering the broadest choice of processor, storage, networking, OS, and purchase model.},
	language = {en-US},
	urldate = {2022-02-01},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/A8LT7MY8/ec2.html:text/html},
}

@article{noauthor_security_nodate,
	title = {Security {Overview} of {AWS} {Lambda} - {AWS} {Whitepaper}},
	language = {en},
	pages = {26},
	file = {Security Overview of AWS Lambda - AWS Whitepaper.pdf:/home/tobi/programms/Zotero/storage/8QANPS3A/Security Overview of AWS Lambda - AWS Whitepaper.pdf:application/pdf},
}

@misc{noauthor_operating_2021,
	title = {Operating {Lambda}: {Performance} optimization – {Part} 1},
	shorttitle = {Operating {Lambda}},
	url = {https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/},
	abstract = {This post is the first in a 3-part series on performance optimization in Lambda. It explains how the Lambda execution environment works and why cold starts occur.},
	language = {en-US},
	urldate = {2022-02-02},
	journal = {Amazon Web Services},
	month = apr,
	year = {2021},
	note = {Section: AWS Lambda},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/RCGJTG74/operating-lambda-performance-optimization-part-1.html:text/html},
}

@article{mohamed_relational_2014,
	title = {Relational {Vs}. {NoSQL} databases: {A} survey},
	volume = {03},
	shorttitle = {Relational {Vs}. {NoSQL} databases},
	abstract = {The huge growth in the Internet market and the emerging of the new web technologies and the trend toward what is called web 2.0 and recently web 3.0 come with a new challenges, new applications and new concepts such as NoSQL databases which is recently becomes a very popular as an alternative to the relational databases specially in dealing with large data which is one of the most common features of web today, providing high availability and scalability to the distributed systems which need fast access time and can’t tolerate any down time during failures and have been used heavily by the big enterprises and web companies such as Facebook, amazon and Google. Every new technology faced many challenges like Security vulnerabilities. This paper addresses the concepts of NoSQL, the movement, motivations and needs behind it, and reviews the types of NoSQL databases and the issues concerning to these databases mainly areas of application and the security issues compared with traditional relational databases.},
	journal = {International Journal of Computer and Information Technology (IJCIT)},
	author = {Mohamed, Mohamed and Altrafi, Obay and Ismail, Mohammed},
	month = may,
	year = {2014},
	pages = {598},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/S8DJZLL4/Mohamed et al. - 2014 - Relational Vs. NoSQL databases A survey.pdf:application/pdf},
}

@article{atikoglu_workload_2012,
	title = {Workload analysis of a large-scale key-value store},
	volume = {40},
	issn = {0163-5999},
	url = {https://doi.org/10.1145/2318857.2254766},
	doi = {10.1145/2318857.2254766},
	abstract = {Key-value stores are a vital component in many scale-out enterprises, including social networks, online retail, and risk analysis. Accordingly, they are receiving increased attention from the research community in an effort to improve their performance, scalability, reliability, cost, and power consumption. To be effective, such efforts require a detailed understanding of realistic key-value workloads. And yet little is known about these workloads outside of the companies that operate them. This paper aims to address this gap. To this end, we have collected detailed traces from Facebook's Memcached deployment, arguably the world's largest. The traces capture over 284 billion requests from five different Memcached use cases over several days. We analyze the workloads from multiple angles, including: request composition, size, and rate; cache efficacy; temporal patterns; and application use cases. We also propose a simple model of the most representative trace to enable the generation of more realistic synthetic workloads by the community. Our analysis details many characteristics of the caching workload. It also reveals a number of surprises: a GET/SET ratio of 30:1 that is higher than assumed in the literature; some applications of Memcached behave more like persistent storage than a cache; strong locality metrics, such as keys accessed many millions of times a day, do not always suffice for a high hit rate; and there is still room for efficiency and hit rate improvements in Memcached's implementation. Toward the last point, we make several suggestions that address the exposed deficiencies.},
	number = {1},
	urldate = {2022-02-04},
	journal = {ACM SIGMETRICS Performance Evaluation Review},
	author = {Atikoglu, Berk and Xu, Yuehai and Frachtenberg, Eitan and Jiang, Song and Paleczny, Mike},
	month = jun,
	year = {2012},
	keywords = {key-value store, memcached, workload analysis, workload modeling},
	pages = {53--64},
	file = {Full Text:/home/tobi/programms/Zotero/storage/Y5SBXCPE/Atikoglu et al. - 2012 - Workload analysis of a large-scale key-value store.pdf:application/pdf},
}

@inproceedings{mathew_analysis_2015,
	title = {Analysis of data management and query handling in social networks using {NoSQL} databases},
	doi = {10.1109/ICACCI.2015.7275708},
	abstract = {In the past few decades, traditional RDBMS(Relational Database Management Systems) was a predominant technology used for storing and retrieving structured data in web and business applications since 1980. However, relational databases have started squandering its importance due to strict schema reliance and costly infrastructure. This has collectively led to the problem in upgrade hardware-software challenges and relationships between objects. Another major issue of failure is the brobdingnagian hike of BigData. A new database model called NoSQL, plays a vital role in BigData analytics. The main focus of this paper is on four different types of NoSQL databases owned by social networking sites like Facebook, LinkedIn, Twitter, MySpace, Foursquare, Flickr and Friendfeed. Main features of these four types of NoSQL databases, like scalability of the data model, concurrency control, consistency in storage, availability during partitioning, durability, transactions, implementation language, query support possibilities and programming characteristics are compared and analyzed. These features are compared for the sub categories of the four NoSQL databases, for swift querying from social networking sites. In the detailed analysis presented, the features like data storage and fast retrieval phase of query processing are given primary importance. We also present a comparison of the time taken during insert and read operations of social network data of Facebook associating friends, intimate friends, family and groups like hometown and workplace. The results are compared and most suitable database from NoSQL Graph database subcategories for insert and read operations in Facebook are identified.},
	booktitle = {2015 {International} {Conference} on {Advances} in {Computing}, {Communications} and {Informatics} ({ICACCI})},
	author = {Mathew, Anita Brigit and Madhu Kumar, S. D.},
	month = aug,
	year = {2015},
	keywords = {Databases, Analytical models, NoSQL databases, Column Family Stores, Data models, Document Stores, Facebook, Graph Databases, Key Value Stores, Memory, MySpace, Social Networks(SN's), Twitter},
	pages = {800--806},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/7G6GG64C/7275708.html:text/html},
}

@misc{noauthor_redis_nodate-2,
	title = {Redis {Essentials}},
	url = {https://redisessentials.com/},
	urldate = {2022-02-06},
	file = {Redis Essentials:/home/tobi/programms/Zotero/storage/S4C5GPTT/redisessentials.com.html:text/html},
}

@book{silva_redis_2015,
	title = {Redis {Essentials}},
	isbn = {978-1-78439-608-4},
	abstract = {Harness the power of Redis to integrate and manage your projects efficientlyAbout This BookLearn how to use Redis's data types efficiently to manage large data setsScale Redis to multiple servers with Twemproxy, Redis Sentinel, and Redis ClusterA fast-paced guide, full of real-world examples to help you get the best out of the features offered by RedisWho This Book Is ForIf you are a competent developer with experience of working with data structure servers and want to boost your project's performance by learning about features of Redis, then this book is for you.What You Will LearnBuild analytics applications using Bitmaps and HyperloglogsEnhance scalability with Twemproxy, Redis Sentinel, and Redis ClusterBuild a Time Series implementation in Node.js and RedisCreate your own Redis commands by extending Redis with LuaGet to know security techniques to protect your data (SSL encryption, firewall rules, basic authorization)Persist data to disk and learn the trade-offs of AOF and RDBUnderstand how to use Node.js, PHP, Python, and Ruby clients for RedisAvoid common pitfalls when designing your next solutionIn DetailRedis is the most popular in-memory key-value data store. It's very lightweight and its data types give it an edge over the other competitors. If you need an in-memory database or a high-performance cache system that is simple to use and highly scalable, Redis is what you need.Redis Essentials is a fast-paced guide that teaches the fundamentals on data types, explains how to manage data through commands, and shares experiences from big players in the industry.We start off by explaining the basics of Redis followed by the various data types such as Strings, hashes, lists, and more. Next, Common pitfalls for various scenarios are described, followed by solutions to ensure you do not fall into common traps.After this, major differences between client implementations in PHP, Python, and Ruby are presented. Next, you will learn how to extend Redis with Lua, get to know security techniques such as basic authorization, firewall rules, and SSL encryption, and discover how to use Twemproxy, Redis Sentinel, and Redis Cluster to scale infrastructures horizontally. At the end of this book, you will be able to utilize all the essential features of Redis to optimize your project's performance.Style and approachA practical guide that offers the foundation upon which you can begin to understand the capabilities of Redis using a step-by-step approach. This book is full of real-world problems and in-depth knowledge of the concepts and features of Redis, with plenty of examples.},
	language = {en},
	publisher = {Packt Publishing Ltd},
	author = {Silva, Maxwell Dayvson Da and Tavares, Hugo Lopes},
	month = sep,
	year = {2015},
	note = {Google-Books-ID: 08WGCgAAQBAJ},
	keywords = {Computers / Data Modeling \& Design, Computers / Databases / Servers, Computers / Programming Languages / JavaScript, Computers / System Administration / Storage \& Retrieval},
}

@misc{noauthor_comparing_nodate,
	title = {Comparing {Memcached} and {Redis} - {Amazon} {ElastiCache} for {Redis}},
	url = {https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/SelectEngine.html},
	urldate = {2022-02-07},
	file = {Comparing Memcached and Redis - Amazon ElastiCache for Redis:/home/tobi/programms/Zotero/storage/523LXIU4/SelectEngine.html:text/html},
}

@article{noauthor_amazon_nodate,
	title = {Amazon {Simple} {Storage} {Service} {Developer} {Guide}},
	language = {en},
	pages = {553},
	file = {Amazon Simple Storage Service Developer Guide.pdf:/home/tobi/programms/Zotero/storage/KY4V7ADD/Amazon Simple Storage Service Developer Guide.pdf:application/pdf},
}

@inproceedings{zhang_redis_2018,
	title = {Redis++: {A} {High} {Performance} {In}-{Memory} {Database} {Based} on {Segmented} {Memory} {Management} and {Two}-{Level} {Hash} {Index}},
	shorttitle = {Redis++},
	doi = {10.1109/BDCloud.2018.00125},
	abstract = {Redis is an open source in-memory data structure store, used as a database, cache and message broker. However, there are two problems that will degrade its performance. One is the memory fragmentation problem, another is cache miss problem. For the purpose, this paper presents a high-performance in-memory database Redis++. In the memory management mechanism, Redis++ will allocate and deallocate a fixed-size memory segment from the system. The data in each memory segment are stored continuously, and the memory segment is reclaimed based on the profit evaluation model. Secondly, a two-level hash index structure is designed, the structure uses two-level index to complete only one cache mapping per query. In addition, instruction-level parallelism is implemented using the single instruction multiple data instruction set, which speeds up the query efficiency of the secondary index. The experiments prove the effect of Redis++ on memory utilization, response latency and throughput.},
	booktitle = {2018 {IEEE} {Intl} {Conf} on {Parallel} {Distributed} {Processing} with {Applications}, {Ubiquitous} {Computing} {Communications}, {Big} {Data} {Cloud} {Computing}, {Social} {Computing} {Networking}, {Sustainable} {Computing} {Communications} ({ISPA}/{IUCC}/{BDCloud}/{SocialCom}/{SustainCom})},
	author = {Zhang, Peng and Xing, Lichao and Yang, Ninggou and Tan, Guolin and Liu, Qingyun and Zhang, Chuang},
	month = dec,
	year = {2018},
	keywords = {Memory management, Indexes, Random access memory, Data structures, in memory database, memory segment, profit evaluation model, two-level hash index, Resource management, Slabs},
	pages = {840--847},
	file = {IEEE Xplore Full Text PDF:/home/tobi/programms/Zotero/storage/FN47DI8Z/Zhang et al. - 2018 - Redis++ A High Performance In-Memory Database Bas.pdf:application/pdf;IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/J2QQY7TX/8672254.html:text/html},
}

@article{xu_bluecache_2016,
	title = {Bluecache: a scalable distributed flash-based key-value store},
	volume = {10},
	issn = {2150-8097},
	shorttitle = {Bluecache},
	url = {https://doi.org/10.14778/3025111.3025113},
	doi = {10.14778/3025111.3025113},
	abstract = {A key-value store (KVS), such as memcached and Redis, is widely used as a caching layer to augment the slower persistent backend storage in data centers. DRAM-based KVS provides fast key-value access, but its scalability is limited by the cost, power and space needed by the machine cluster to support a large amount of DRAM. This paper offers a 10X to 100X cheaper solution based on flash storage and hardware accelerators. In BlueCache key-value pairs are stored in flash storage and all KVS operations, including the flash controller are directly implemented in hardware. Furthermore, BlueCache includes a fast interconnect between flash controllers to provide a scalable solution. We show that BlueCache has 4.18X higher throughput and consumes 25X less power than a flash-backed KVS software implementation on x86 servers. We further show that BlueCache can outperform DRAM-based KVS when the latter has more than 7.4\% misses for a read-intensive aplication. BlueCache is an attractive solution for both rack-level appliances and data-center-scale key-value cache.},
	number = {4},
	urldate = {2022-02-09},
	journal = {Proceedings of the VLDB Endowment},
	author = {Xu, Shuotao and Lee, Sungjin and Jun, Sang-Woo and Liu, Ming and Hicks, Jamey and Arvind},
	month = nov,
	year = {2016},
	pages = {301--312},
}

@article{li_full-stack_2016,
	title = {Full-{Stack} {Architecting} to {Achieve} a {Billion}-{Requests}-{Per}-{Second} {Throughput} on a {Single} {Key}-{Value} {Store} {Server} {Platform}},
	volume = {34},
	issn = {0734-2071},
	url = {https://doi.org/10.1145/2897393},
	doi = {10.1145/2897393},
	abstract = {Distributed in-memory key-value stores (KVSs), such as memcached, have become a critical data serving layer in modern Internet-oriented data center infrastructure. Their performance and efficiency directly affect the QoS of web services and the efficiency of data centers. Traditionally, these systems have had significant overheads from inefficient network processing, OS kernel involvement, and concurrency control. Two recent research thrusts have focused on improving key-value performance. Hardware-centric research has started to explore specialized platforms including FPGAs for KVSs; results demonstrated an order of magnitude increase in throughput and energy efficiency over stock memcached. Software-centric research revisited the KVS application to address fundamental software bottlenecks and to exploit the full potential of modern commodity hardware; these efforts also showed orders of magnitude improvement over stock memcached. We aim at architecting high-performance and efficient KVS platforms, and start with a rigorous architectural characterization across system stacks over a collection of representative KVS implementations. Our detailed full-system characterization not only identifies the critical hardware/software ingredients for high-performance KVS systems but also leads to guided optimizations atop a recent design to achieve a record-setting throughput of 120 million requests per second (MRPS) (167MRPS with client-side batching) on a single commodity server. Our system delivers the best performance and energy efficiency (RPS/watt) demonstrated to date over existing KVSs including the best-published FPGA-based and GPU-based claims. We craft a set of design principles for future platform architectures, and via detailed simulations demonstrate the capability of achieving a billion RPS with a single server constructed following our principles.},
	number = {2},
	urldate = {2022-02-09},
	journal = {ACM Transactions on Computer Systems},
	author = {Li, Sheng and Lim, Hyeontaek and Lee, Victor W. and Ahn, Jung Ho and Kalia, Anuj and Kaminsky, Michael and Andersen, David G. and O, Seongil and Lee, Sukhan and Dubey, Pradeep},
	month = apr,
	year = {2016},
	keywords = {cloud and network, energy efficiency, Key-value stores, many core, storage performance},
	pages = {5:1--5:30},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/7F5EHY4S/Li et al. - 2016 - Full-Stack Architecting to Achieve a Billion-Reque.pdf:application/pdf},
}

@article{zhang_mega-kv_2015,
	title = {Mega-{KV}: a case for {GPUs} to maximize the throughput of in-memory key-value stores},
	volume = {8},
	issn = {2150-8097},
	shorttitle = {Mega-{KV}},
	url = {https://doi.org/10.14778/2809974.2809984},
	doi = {10.14778/2809974.2809984},
	abstract = {In-memory key-value stores play a critical role in data processing to provide high throughput and low latency data accesses. In-memory key-value stores have several unique properties that include (1) data intensive operations demanding high memory bandwidth for fast data accesses, (2) high data parallelism and simple computing operations demanding many slim parallel computing units, and (3) a large working set. As data volume continues to increase, our experiments show that conventional and general-purpose multicore systems are increasingly mismatched to the special properties of key-value stores because they do not provide massive data parallelism and high memory bandwidth; the powerful but the limited number of computing cores do not satisfy the demand of the unique data processing task; and the cache hierarchy may not well benefit to the large working set. In this paper, we make a strong case for GPUs to serve as special-purpose devices to greatly accelerate the operations of in-memory key-value stores. Specifically, we present the design and implementation of Mega-KV, a GPU-based in-memory key-value store system that achieves high performance and high throughput. Effectively utilizing the high memory bandwidth and latency hiding capability of GPUs, Mega-KV provides fast data accesses and significantly boosts overall performance. Running on a commodity PC installed with two CPUs and two GPUs, Mega-KV can process up to 160+ million key-value operations per second, which is 1.4-2.8 times as fast as the state-of-the-art key-value store system on a conventional CPU-based platform.},
	number = {11},
	urldate = {2022-02-09},
	journal = {Proceedings of the VLDB Endowment},
	author = {Zhang, Kai and Wang, Kaibo and Yuan, Yuan and Guo, Lei and Lee, Rubao and Zhang, Xiaodong},
	month = jul,
	year = {2015},
	pages = {1226--1237},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/LMZ5E6HN/Zhang et al. - 2015 - Mega-KV a case for GPUs to maximize the throughpu.pdf:application/pdf},
}

@inproceedings{huang_closing_2018,
	title = {Closing the {Performance} {Gap} {Between} {Volatile} and {Persistent} \{{Key}-{Value}\} {Stores} {Using} \{{Cross}-{Referencing}\} {Logs}},
	isbn = {978-1-939133-01-4},
	url = {https://www.usenix.org/conference/atc18/presentation/huang},
	language = {en},
	urldate = {2022-02-09},
	author = {Huang, Yihe and Pavlovic, Matej and Marathe, Virendra and Seltzer, Margo and Harris, Tim and Byan, Steve},
	year = {2018},
	pages = {967--979},
	file = {Full Text PDF:/home/tobi/programms/Zotero/storage/Y5PGGTIA/Huang et al. - 2018 - Closing the Performance Gap Between Volatile and P.pdf:application/pdf;Snapshot:/home/tobi/programms/Zotero/storage/6JB5DNKM/huang.html:text/html},
}

@inproceedings{lim_mica_2014,
	title = {{MICA}: {A} {Holistic} {Approach} to {Fast} {In}-{Memory} {Key}-{Value} {Storage}},
	shorttitle = {{MICA}},
	abstract = {MICA optimizes for multi-core architectures by enabling parallel access to partitioned data, and for efficient parallel data access, MICA maps client requests directly to specific CPU cores at the server NIC level by using client-supplied information and adopts a light-weight networking stack that bypasses the kernel. MICA is a scalable in-memory key-value store that handles 65.6 to 76.9 million key-value operations per second using a single general-purpose multi-core system. MICA is over 4-13.5x faster than current state-of-the-art systems, while providing consistently high throughput over a variety of mixed read and write workloads. 
 
MICA takes a holistic approach that encompasses all aspects of request handling, including parallel data access, network request handling, and data structure design, but makes unconventional choices in each of the three domains. First, MICA optimizes for multi-core architectures by enabling parallel access to partitioned data. Second, for efficient parallel data access, MICA maps client requests directly to specific CPU cores at the server NIC level by using client-supplied information and adopts a light-weight networking stack that bypasses the kernel. Finally, MICA's new data structures--circular logs, lossy concurrent hash indexes, and bulk chaining--handle both read-and write-intensive workloads at low overhead.},
	booktitle = {{NSDI}},
	author = {Lim, Hyeontaek and Han, Dongsu and Andersen, D. and Kaminsky, M.},
	year = {2014},
}

@inproceedings{zhang_unikv_2020,
	title = {{UniKV}: {Toward} {High}-{Performance} and {Scalable} {KV} {Storage} in {Mixed} {Workloads} via {Unified} {Indexing}},
	shorttitle = {{UniKV}},
	doi = {10.1109/ICDE48307.2020.00034},
	abstract = {Persistent key-value (KV) stores are mainly designed based on the Log-Structured Merge-tree (LSM-tree), which suffer from large read and write amplifications, especially when KV stores grow in size. Existing design optimizations for LSM-tree-based KV stores often make certain trade-offs and fail to simultaneously improve both the read and write performance on large KV stores without sacrificing scan performance. We design UniKV, which unifies the key design ideas of hash indexing and the LSM-tree in a single system. Specifically, UniKV leverages data locality to differentiate the indexing management of KV pairs. It also develops multiple techniques to tackle the issues caused by unifying the indexing techniques, so as to simultaneously improve the performance in reads, writes, and scans. Experiments show that UniKV significantly outperforms several state-of-the-art KV stores (e.g., LevelDB, RocksDB, HyperLevelDB, and PebblesDB) in overall throughput under read-write mixed workloads.},
	booktitle = {2020 {IEEE} 36th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	author = {Zhang, Qiang and Li, Yongkun and Lee, Patrick P. C. and Xu, Yinlong and Cui, Qiu and Tang, Liu},
	month = apr,
	year = {2020},
	note = {ISSN: 2375-026X},
	keywords = {Throughput, Compaction, Indexing, Merging, Scalability, Sorting},
	pages = {313--324},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/CUD7CGUN/9101876.html:text/html},
}

@inproceedings{lepers_kvell_2019,
	address = {New York, NY, USA},
	series = {{SOSP} '19},
	title = {{KVell}: the design and implementation of a fast persistent key-value store},
	isbn = {978-1-4503-6873-5},
	shorttitle = {{KVell}},
	url = {https://doi.org/10.1145/3341301.3359628},
	doi = {10.1145/3341301.3359628},
	abstract = {Modern block-addressable NVMe SSDs provide much higher bandwidth and similar performance for random and sequential access. Persistent key-value stores (KVs) designed for earlier storage devices, using either Log-Structured Merge (LSM) or B trees, do not take full advantage of these new devices. Logic to avoid random accesses, expensive operations for keeping data sorted on disk, and synchronization bottlenecks make these KVs CPU-bound on NVMe SSDs. We present a new persistent KV design. Unlike earlier designs, no attempt is made at sequential access, and data is not sorted when stored on disk. A shared-nothing philosophy is adopted to avoid synchronization overhead. Together with batching of device accesses, these design decisions make for read and write performance close to device bandwidth. Finally, maintaining an inexpensive partial sort in memory produces adequate scan performance. We implement this design in KVell, the first persistent KV able to utilize modern NVMe SSDs at maximum bandwidth. We compare KVell against available state-of-the-art LSM and B tree KVs, both with synthetic benchmarks and production workloads. KVell achieves throughput at least 2x that of its closest competitor on read-dominated workloads, and 5x on write-dominated workloads. For workloads that contain mostly scans, KVell performs comparably or better than its competitors. KVell provides maximum latencies an order of magnitude lower than the best of its competitors, even on scan-based workloads.},
	urldate = {2022-02-10},
	booktitle = {Proceedings of the 27th {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {Association for Computing Machinery},
	author = {Lepers, Baptiste and Balmau, Oana and Gupta, Karan and Zwaenepoel, Willy},
	month = oct,
	year = {2019},
	keywords = {performance, key-value store, B+ tree, log-structured merge tree (LSM), NVMe, persistence, SSD},
	pages = {447--461},
}

@article{didona_size-aware_2018,
	title = {Size-aware {Sharding} {For} {Improving} {Tail} {Latencies} in {In}-memory {Key}-value {Stores}},
	url = {http://arxiv.org/abs/1802.00696},
	abstract = {This paper introduces the concept of size-aware sharding to improve tail latencies for in-memory key-value stores, and describes its implementation in the Minos key-value store. Tail latencies are crucial in distributed applications with high fan-out ratios, because overall response time is determined by the slowest response. Size-aware sharding distributes requests for keys to cores according to the size of the item associated with the key. In particular, requests for small and large items are sent to disjoint subsets of cores. Size-aware sharding improves tail latencies by avoiding head-of-line blocking, in which a request for a small item gets queued behind a request for a large item. Alternative size-unaware approaches to sharding, such as keyhash-based sharding, request dispatching and stealing do not avoid head-of-line blocking, and therefore exhibit worse tail latencies. The challenge in implementing size-aware sharding is to maintain high throughput by avoiding the cost of software dispatching and by achieving load balancing between different cores. Minos uses hardware dispatch for all requests for small items, which form the very large majority of all requests. It achieves load balancing by adapting the number of cores handling requests for small and large items to their relative presence in the workload. We compare Minos to three state-of-the-art designs of in-memory KV stores. Compared to its closest competitor, Minos achieves a 99th percentile latency that is up to two orders of magnitude lower. Put differently, for a given value for the 99th percentile latency equal to 10 times the mean service time, Minos achieves a throughput that is up to 7.4 times higher.},
	urldate = {2022-02-10},
	journal = {arXiv:1802.00696 [cs]},
	author = {Didona, Diego and Zwaenepoel, Willy},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.00696},
	keywords = {Computer Science - Operating Systems, Computer Science - Databases},
	file = {arXiv Fulltext PDF:/home/tobi/programms/Zotero/storage/D454NFEM/Didona and Zwaenepoel - 2018 - Size-aware Sharding For Improving Tail Latencies i.pdf:application/pdf;arXiv.org Snapshot:/home/tobi/programms/Zotero/storage/EUYUVZZP/1802.html:text/html},
}

@misc{noauthor_cloud_nodate,
	title = {Cloud {Products}},
	url = {https://aws.amazon.com/products/},
	language = {en-US},
	urldate = {2022-02-23},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/J2NCFISJ/products.html:text/html},
}

@misc{noauthor_cloud_nodate-1,
	title = {Cloud {Object} {Storage} – {Amazon} {S3} – {Amazon} {Web} {Services}},
	url = {https://aws.amazon.com/s3/},
	abstract = {Amazon S3 is cloud object storage with industry-leading scalability, data availability, security, and performance. S3 is ideal for data lakes, mobile applications, backup and restore, archival, IoT devices, ML, AI, and analytics.},
	language = {en-US},
	urldate = {2022-02-23},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/XQRN5ME4/s3.html:text/html},
}

@misc{noauthor_secure_nodate-1,
	title = {Secure and resizable cloud compute – {Amazon} {EC2} – {Amazon} {Web} {Services}},
	url = {https://aws.amazon.com/ec2/},
	abstract = {Amazon EC2 provides secure, resizable compute in the cloud, offering the broadest choice of processor, storage, networking, OS, and purchase model.},
	language = {en-US},
	urldate = {2022-02-23},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/WVJTC99G/ec2.html:text/html},
}

@misc{noauthor_instance_nodate,
	title = {Instance lifecycle - {Amazon} {Elastic} {Compute} {Cloud}},
	url = {https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html},
	urldate = {2022-02-23},
	file = {Instance lifecycle - Amazon Elastic Compute Cloud:/home/tobi/programms/Zotero/storage/QC7KU3EU/ec2-instance-lifecycle.html:text/html},
}

@misc{noauthor_amazon_nodate-1,
	title = {Amazon {ElastiCache} – {Managed} {Caching} {Service} – {Amazon} {Web} {Services}},
	url = {https://aws.amazon.com/elasticache/},
	abstract = {Amazon ElastiCache is a managed caching service for Redis and Memcached. ElastiCache makes it easy to achieve high performance and massive scale with in-memory caching.},
	language = {en-US},
	urldate = {2022-02-23},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/8WV4C924/elasticache.html:text/html},
}

@misc{noauthor_serverless_nodate,
	title = {Serverless {Computing} - {AWS} {Lambda} - {Amazon} {Web} {Services}},
	url = {https://aws.amazon.com/lambda/},
	abstract = {AWS Lambda is a serverless compute service for running code without having to provision or manage servers. You pay only for the compute time you consume.},
	language = {en-US},
	urldate = {2022-02-23},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/M92PNGBN/lambda.html:text/html},
}

@inproceedings{saraswat_cloud_2020,
	title = {Cloud {Computing}: {Analysis} of {Top} 5 {CSPs} in {SaaS}, {PaaS} and {IaaS} {Platforms}},
	shorttitle = {Cloud {Computing}},
	doi = {10.1109/SMART50582.2020.9337157},
	abstract = {The Cloud computing refers to manipulating, configuring and accessing the applications as utilities over the internet. It involves online data computation, storation, infrastructure and application, and hence it is highly essential to make a smart decision, when and how computing, storage and network resources be distributed and allocated to users to utilize, manage and consume them. In this paper first architecture of cloud computing, characteristics of service models and services provided by CSPs are discussed, than after analyzed growth rate and market share of top five CSPs in cloud service models, i.e Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS).},
	booktitle = {2020 9th {International} {Conference} {System} {Modeling} and {Advancement} in {Research} {Trends} ({SMART})},
	author = {Saraswat, Manish and Tripathi, R.C.},
	month = dec,
	year = {2020},
	keywords = {Cloud computing, cloud computing, Analytical models, Companies, Computational modeling, cloud architecture, cloud models, cloud services model-IaaS, PaaS, SaaS, Software as a service, Systems modeling, Web services},
	pages = {300--305},
	file = {IEEE Xplore Abstract Record:/home/tobi/programms/Zotero/storage/IQLTKZJQ/9337157.html:text/html},
}

@misc{noauthor_aws_nodate,
	title = {{AWS} {Elastic} {Beanstalk} – {Deploy} {Web} {Applications}},
	url = {https://aws.amazon.com/elasticbeanstalk/},
	abstract = {Deploy \& manage web applications in the AWS cloud. Upload your application, and Elastic Beanstalk handles capacity provisioning, app health monitoring \& more.},
	language = {en-US},
	urldate = {2022-02-23},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/7654TEV3/elasticbeanstalk.html:text/html},
}

@misc{noauthor_redis_nodate-3,
	title = {Redis},
	url = {https://redis.io/},
	urldate = {2022-02-23},
	file = {Redis:/home/tobi/programms/Zotero/storage/49I7T7LC/redis.io.html:text/html},
}

@misc{noauthor_cloud_nodate-2,
	title = {Cloud {Computing} {Services} {\textbar} {Microsoft} {Azure}},
	url = {https://azure.microsoft.com/en-us/},
	abstract = {Invent with purpose, realize cost savings, and make your organization more efficient with Microsoft Azure’s open and flexible cloud computing platform.},
	language = {en},
	urldate = {2022-02-24},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/A87CWXYM/en-us.html:text/html},
}

@misc{noauthor_cloud_nodate-3,
	title = {Cloud {Computing} {Services}},
	url = {https://cloud.google.com/},
	abstract = {Meet your business challenges head on with cloud computing services from Google, including data management, hybrid \&amp; multi-cloud, and AI \&amp; ML.},
	language = {en},
	urldate = {2022-02-24},
	journal = {Google Cloud},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/LBNJVN35/cloud.google.com.html:text/html},
}

@misc{noauthor_cloud_nodate-4,
	title = {Cloud {Services} - {Amazon} {Web} {Services} ({AWS})},
	url = {https://aws.amazon.com/},
	abstract = {Amazon Web Services offers reliable, scalable, and inexpensive cloud computing services. Free to join, pay only for what you use.},
	language = {en-US},
	urldate = {2022-02-24},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/HIHI5ECG/aws.amazon.com.html:text/html},
}

@misc{noauthor_memorystore_nodate,
	title = {Memorystore: in-memory data store},
	shorttitle = {Memorystore},
	url = {https://cloud.google.com/memorystore},
	abstract = {A fully managed in-memory data store service for Redis and Memcached. Build application caches that provide sub-millisecond data access.},
	language = {en},
	urldate = {2022-02-26},
	journal = {Google Cloud},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/X9F4ZF59/memorystore.html:text/html},
}

@misc{noauthor_azure_nodate,
	title = {Azure {Cache} for {Redis} {\textbar} {Microsoft} {Azure}},
	url = {https://azure.microsoft.com/en-us/services/cache/},
	abstract = {Power fast, scalable applications with Azure Cache for Redis, cache databases as a service with fully managed, open-source-compatible in-memory data storing service.},
	language = {en},
	urldate = {2022-02-26},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/3UDAIHFQ/cache.html:text/html},
}

@misc{noauthor_amazon_2017,
	title = {Amazon {DynamoDB} {Accelerator} ({DAX}) - {In}-{Memory} {Caching} for {Read}-{Intensive} {Workloads}},
	url = {https://aws.amazon.com/blogs/aws/amazon-dynamodb-accelerator-dax-in-memory-caching-for-read-intensive-workloads/},
	abstract = {I’m fairly sure that you already know about Amazon DynamoDB. As you probably know, it is a managed NoSQL database that scales to accommodate as much table space, read capacity, and write capacity as you need. With response times measured in single-digit milliseconds, our customers are using DynamoDB for many types of applications including adtech, […]},
	language = {en-US},
	urldate = {2022-02-27},
	journal = {Amazon Web Services},
	month = apr,
	year = {2017},
	note = {Section: Amazon DynamoDB},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/MAJ6IT7M/amazon-dynamodb-accelerator-dax-in-memory-caching-for-read-intensive-workloads.html:text/html},
}

@misc{noauthor_fast_nodate,
	title = {Fast {NoSQL} {Key}-{Value} {Database} – {Amazon} {DynamoDB} – {Amazon} {Web} {Services}},
	url = {https://aws.amazon.com/dynamodb/},
	abstract = {Amazon DynamoDB is a fully managed, serverless, key-value NoSQL database that runs high-performance applications at any scale, with built-in security, continuous backups, and automated multi-region replication.},
	language = {en-US},
	urldate = {2022-02-27},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/X2DGRMZR/dynamodb.html:text/html},
}

@misc{noauthor_amazon_nodate-2,
	title = {Amazon {Simple} {Storage} {Service} {Documentation}},
	url = {https://docs.aws.amazon.com/s3/index.html},
	urldate = {2022-02-27},
	file = {Amazon Simple Storage Service Documentation:/home/tobi/programms/Zotero/storage/32L3GARL/index.html:text/html},
}

@misc{noauthor_amazon_nodate-3,
	title = {Amazon {MemoryDB} for {Redis} – {Redis}-{Compatible} {In}-{Memory} {Database} – {Amazon} {Web} {Services}},
	url = {https://aws.amazon.com/memorydb/},
	abstract = {Amazon MemoryDB for Redis is a Redis-compatible, durable, in-memory database service that delivers ultra-fast performance.},
	language = {en-US},
	urldate = {2022-02-28},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/EEH7YFSV/memorydb.html:text/html},
}

@book{garcia-molina_database_2008,
	address = {USA},
	edition = {2},
	title = {Database {Systems}: {The} {Complete} {Book}},
	isbn = {978-0-13-187325-4},
	shorttitle = {Database {Systems}},
	abstract = {This introduction to database systems offers a comprehensive approach, focusing on database design, database use, and implementation of database applications and database management systems. KEY TOPICS: The first half of the book provides in-depth coverage of databases from the point of view of the database designer, user, and application programmer. It covers the latest database standards SQL:1999, SQL/PSM, SQL/CLI, JDBC, ODL, and XML, with broader coverage of SQL than most other texts. The second half of the book covers databases from the point of view of the DBMS implementor, focusing on storage structures, query processing, and transaction management. The book covers the main techniques in these areas with broader coverage of query optimization than most other texts, along with advanced topics including multidimensional and bitmap indexes, distributed transactions, and information integration techniques. Ideal for professionals and students interested in database systems. A basic understanding of algebraic expressions and laws, logic, basic data structure, OOP concepts, and programming environments is implied.},
	publisher = {Prentice Hall Press},
	author = {Garcia-Molina, Hector and Ullman, Jeffrey D. and Widom, Jennifer},
	year = {2008},
}

@book{sadalage_nosql_2012,
	edition = {1st},
	title = {{NoSQL} {Distilled}: {A} {Brief} {Guide} to the {Emerging} {World} of {Polyglot} {Persistence}},
	isbn = {978-0-321-82662-6},
	shorttitle = {{NoSQL} {Distilled}},
	abstract = {The need to handle increasingly larger data volumes is one factor driving the adoption of a new class of nonrelational NoSQL databases. Advocates of NoSQL databases claim they can be used to build systems that are more performant, scale better, and are easier to program. NoSQL Distilled is a concise but thorough introduction to this rapidly emerging technology. Pramod J. Sadalage and Martin Fowler explain how NoSQL databases work and the ways that they may be a superior alternative to a traditional RDBMS. The authors provide a fast-paced guide to the concepts you need to know in order to evaluate whether NoSQL databases are right for your needs and, if so, which technologies you should explore further. The first part of the book concentrates on core concepts, including schemaless data models, aggregates, new distribution models, the CAP theorem, and map-reduce. In the second part, the authors explore architectural and design issues associated with implementing NoSQL. They also present realistic use cases that demonstrate NoSQL databases at work and feature representative examples using Riak, MongoDB, Cassandra, and Neo4j. In addition, by drawing on Pramod Sadalages pioneering work, NoSQL Distilled shows how to implement evolutionary design with schema migration: an essential technique for applying NoSQL databases. The book concludes by describing how NoSQL is ushering in a new age of Polyglot Persistence, where multiple data-storage worlds coexist, and architects can choose the technology best optimized for each type of data access.},
	publisher = {Addison-Wesley Professional},
	author = {Sadalage, Pramod J. and Fowler, Martin},
	year = {2012},
}

@misc{noauthor_introducing_2021,
	title = {Introducing {Amazon} {MemoryDB} for {Redis} – {A} {Redis}-{Compatible}, {Durable}, {In}-{Memory} {Database} {Service}},
	url = {https://aws.amazon.com/blogs/aws/introducing-amazon-memorydb-for-redis-a-redis-compatible-durable-in-memory-database-service/},
	abstract = {Interactive applications need to process requests and respond very quickly, and this requirement extends to all the components of their architecture. That is even more important when you adopt microservices and your architecture is composed of many small independent services that communicate with each other. For this reason, database performance is critical to the success […]},
	language = {en-US},
	urldate = {2022-03-02},
	journal = {Amazon Web Services},
	month = aug,
	year = {2021},
	note = {Section: Amazon MemoryDB for Redis},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/6WMUGZE7/introducing-amazon-memorydb-for-redis-a-redis-compatible-durable-in-memory-database-service.html:text/html},
}

@misc{noauthor_auto_nodate,
	title = {Auto {Scaling} {ElastiCache} for {Redis} clusters - {Amazon} {ElastiCache} for {Redis}},
	url = {https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoScaling.html},
	urldate = {2022-03-02},
	file = {Auto Scaling ElastiCache for Redis clusters - Amazon ElastiCache for Redis:/home/tobi/programms/Zotero/storage/WEGX6KBB/AutoScaling.html:text/html},
}

@misc{noauthor_operating_2021-1,
	title = {Operating {Lambda}: {Performance} optimization – {Part} 1},
	shorttitle = {Operating {Lambda}},
	url = {https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/},
	abstract = {This post is the first in a 3-part series on performance optimization in Lambda. It explains how the Lambda execution environment works and why cold starts occur.},
	language = {en-US},
	urldate = {2022-03-02},
	journal = {Amazon Web Services},
	month = apr,
	year = {2021},
	note = {Section: AWS Lambda},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/CS5RDJC5/operating-lambda-performance-optimization-part-1.html:text/html},
}

@misc{noauthor_basic_nodate,
	title = {Basic {Concepts} of the {Poisson} {Process}},
	url = {https://www.probabilitycourse.com/chapter11/11_1_2_basic_concepts_of_the_poisson_process.php},
	urldate = {2022-03-02},
	file = {Basic Concepts of the Poisson Process:/home/tobi/programms/Zotero/storage/5E8Z2PD3/11_1_2_basic_concepts_of_the_poisson_process.html:text/html},
}

@misc{hsieh_spin_2020,
	title = {Spin {Up} {Redis} with {AWS} {EC2}},
	url = {https://medium.com/@calvin.hsieh/spin-up-redis-with-aws-ec2-e71911c55d61},
	abstract = {Ever need to setup Redis yourself? Want to save cost by hosting Redis yourself instead of using ElastiCache? This post demonstrates how to…},
	language = {en},
	urldate = {2022-03-04},
	journal = {Medium},
	author = {Hsieh, Calvin},
	month = feb,
	year = {2020},
	file = {Snapshot:/home/tobi/programms/Zotero/storage/2XJE4TJ9/spin-up-redis-with-aws-ec2-e71911c55d61.html:text/html},
}
